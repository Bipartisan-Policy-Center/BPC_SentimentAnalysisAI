READ ME FIRST, PLEASE! 
What is this document? 
BASIC   the Behavioural Insights Toolkit & Ethical Guidelines has been developed by the OECD in partnership with Dr Pelle Guldborg Hansen of Roskilde University, Denmark. 
BASIC provides an overarching framework for applying behavioural insights to public policy from the beginning to the end of the policy cycle. It is developed as a repository of best practices, proof of concepts and methodological standards for behavioural insights practitioners and policymakers who have become interested in applying behavioural insights to public policy. Crucially, BASIC offers an approach to problem scoping that can be of relevance for any policymaker and practitioner when addressing a policy problem, be it behavioural or systemic (see stage 1   Behaviour). 
The overview offers the rationale, applicability and key tenets of BASIC. The remainder walks practitioners through the five BASIC sequential stages with examples, and presents detailed ethical guidelines to be considered at each stage. 
This version benefitted from feedback provided by the participants in the Western Cape Government   OECD Behavioural Insights Conference held in Cape Town on 27-28 September 2018.  
Why are you sending it to me? 
Because we want to have your written feedback by 14 December 2018 so that we can make it a tool that meets the needs of practitioners across the world.  
Feedback should be sent to Filippo.Cavassini@oecd.org and James.Drummond@oecd.org.  
How can I help? 
Please provide feedback on BASIC s: 
. Usability: can you use BASIC for your work environment and policy area easily? Why? Or why not? 

. Relevancy: does BASIC cover the key issues/questions/challenges you face when addressing a policy problem? What is missing? Are there any additions or subtractions that would make it more relevant for your work? 

. Applicability: would you be able to apply BASIC to the design of a policy/intervention/regulation? If so, how? If not, what part(s) of BASIC make its application more difficult or not useful and why? 


You may wish to consider these questions generally based on your experience, or apply BASIC to a policy question you are currently working on as a  real world  test for BASIC. 
And what happens afterwards? 
We have shared BASIC with a number of policy communities and practitioners. We will collect feedback, revise the toolkit and release it as an OECD publication.  
 


 
 Table of contents  
BASIC OVERVIEW ............................................................................................................................. 4 
Why a behavioural insights toolkit and ethical framework? ................................................................ 5 
What is BASIC? ................................................................................................................................... 6 
When to use BASIC? ........................................................................................................................... 7 
How to use BASIC? ............................................................................................................................. 9 
THE BASIC STAGES: Where to start when working with BI ...................................................... 12 
Exploring the political, institutional and policy context .................................................................... 12 
Want to set up team? Then consider  .............................................................................................. 13 
Determining the policy level of the project ....................................................................................... 14 
Checklist for scoping a behavioural insights project ......................................................................... 15 
Stage 1: BEHAVIOUR - Identifying and defining the problem.......................................................... 17 
Key steps to scoping a problem ......................................................................................................... 18 
Ethical considerations ........................................................................................................................ 26 
Stage 2: ANALYSIS   Understanding why people act as they do ...................................................... 28 
ABCD   a framework for understanding why people act as they do................................................. 28 
Using ABCD to analyse behavioural problems ................................................................................. 31 
Ethical guidelines for understanding why people act as they do (ANALYSIS) ................................... 37 
Stage 3: STRATEGIES   Effective strategies for behaviour change .................................................. 39 
Methods for applying BI in Public Policy ......................................................................................... 39 
Using the ABCD Framework to match analyses with strategies ....................................................... 40 
Ethical guidelines for designing BI strategies for behaviour change (STRATEGIES) ......................... 62 
Stage 4: INTERVENTION   Testing policy interventions ................................................................... 65 
General features and concepts of the experimental approach ............................................................ 65 
Learning  what works  from experiments .......................................................................................... 71 
The main steps for carrying out a BI-experiment .............................................................................. 75 
Ethical guidelines for testing behaviourally-informed policies (INTERVENTION) ............................ 77 
Stage 5: CHANGE   Implementing behavioural insights .................................................................. 80 
Revisiting the political context and project level ............................................................................... 80 
Important considerations for implementation and creating broader impact ...................................... 82 
Ethical guidelines for implementing behaviourally-informed policy (CHANGE) .............................. 86 
References ............................................................................................................................................ 87 
 
Tables 
Table 1. Determining the level of the project ........................................................................................ 15 
Table 2. Behavioural insights project scoping checklist ....................................................................... 16 
Table 3. Priority filter questionnaire ..................................................................................................... 21 
Table 4. Ethical guidelines for Stage 1: BEHAVIOUR ........................................................................... 27 

Table 5. Ethical guidelines for Stage 2: ANALYSIS ............................................................................ 38 
Table 6. Ethical guidelines for Stage 3: STRATEGY ............................................................................. 64 
Table 7. Ethical guidelines for Stage 4: INTERVENTION ...................................................................... 78 
Table 8. Ethical guidelines for Stage 5: CHANGE.................................................................................. 86 
 
Figures 
Figure 1. The policy cycle ....................................................................................................................... 8 
Figure 2. The BASIC framework ............................................................................................................ 9 
Figure 3. Thinking Aid: Considering the level of the project ............................................................... 18 
Figure 4. Behavioural reduction tool: Decomposing policy issues into behavioural problems ............ 19 
Figure 5. Tool: Priority filters ............................................................................................................... 20 
Figure 6. Is the behaviour studied a behavioural problem? ................................................................... 22 
Figure 7. Behavioural pattern descriptions ............................................................................................ 22 
Figure 8. Tool: Behavioural flowcharts ................................................................................................. 24 
Figure 9. Tool: Selection filter .............................................................................................................. 24 
Figure 10. The ABCD framework ......................................................................................................... 31 
Figure 11. Aerial photo of Lake Shore Drive in Chicago ..................................................................... 49 
Figure 12. Intuitively-coded prescription forms .................................................................................... 49 
Figure 13. Prospect theory ..................................................................................................................... 53 
Figure 14. Arranging choices   which do you prefer? .......................................................................... 54 
Figure 15. Making it easy ...................................................................................................................... 57 
Figure 16. Basic RCT design................................................................................................................. 66 
Figure 17. 2x2 factorial design .............................................................................................................. 69 
Figure 18. Fractional factorial design .................................................................................................... 70 
 
Boxes 
Box 1. Some key BI frameworks ............................................................................................................ 4 
Box 2. What is behavioural insights? ...................................................................................................... 6 
Box 3. Critical steps for using the ABCD Framework .......................................................................... 31 
Box 4. Examples of state of mind, timing and placement ..................................................................... 41 
Box 5. Examples of how to seize attention ........................................................................................... 43 
Box 6. Case study: Making the best use of people s attention - Hand hygiene at a Danish hospital .... 44 
Box 7. Two cases of planning for inattention with default ................................................................... 45 
Box 8. Examples of guiding search ....................................................................................................... 47 
Box 9. Examples of making it intuitive ................................................................................................. 48 
Box 10. Examples of supporting judgment ........................................................................................... 50 
Box 11. Examples of making it attractive ............................................................................................. 52 
Box 12. Examples of framing prospects ................................................................................................ 54 
Box 13. Examples of making it social ................................................................................................... 55 
Box 14. Examples of working with friction .......................................................................................... 58 
Box 15. Examples of providing plans and feedback ............................................................................. 60 
Box 16. Examples of creating commitments ......................................................................................... 61 
Box 17. Threats to internal validity ....................................................................................................... 67 
Box 18. Power analysis ......................................................................................................................... 73 
Box 19. Real world situations conducive to randomised experiments .................................................. 75 
Box 20. Examples of monitoring behaviourally-informed policy solutions ......................................... 84 
Box 21. Examples of maintaining the policy initiative ......................................................................... 85 
 

BASIC OVERVIEW 
1. This guide presents BASIC - A Toolkit and Ethical guidelines for Applying Behavioural Insights in Public Policy. BASIC is a simple set of five sequential stages for applying behavioural insights (BI) to public policy   a new paradigm that has received increasing attention during the last decade.  

2. BI stands in contrast to traditional public policy paradigms, which have tended to rely on models for understanding human behaviour that do not factor in the limits of the way individuals and groups process information and make decisions. These models are based on the assumption that people should be understood and approached as if their behaviour was fully rational and deliberative. The result can be policies, which are less effective as they reflect assumed rather than actual behaviours. 

3. BI provides an alternative paradigm that uses lessons derived from the behavioural and social sciences, including decision making, psychology, cognitive science, neuroscience, organisational and group behaviour, to better understand why people act as they do and create more effective public policies. These insights take into consideration the limits and systematic biases affecting human attention, epistemic, decision-making and self-regulatory, capacities. 

4. BASIC provides a tool for factoring in these insights when designing and implementing public policies. To a large extent, the best practices, proof of concepts and methodological standards related to behaviourally-informed public policy making have already been described in various reports and frameworks (see Box 1). However, a full framework equipping practitioners with tools, methods and ethical guidelines from the beginning to the end of a public policy cycle has been missing (OECD, 2017[1]). BASIC intends to fill this gap. 


Box 1. Some key BI frameworks 
. MINDSPACE (The Behavioural Insights Team, 2010[2]): Provided an early checklist for thinking about how nine well-evidenced behavioural insights may inform public policy development, design and delivery; 

. Test, Learn, and Adapt (The Behavioural Insights Team, 2013[3]): Gave an accessible introduction to the basics of using randomised controlled trials in policy evaluation;  

. EAST framework (The Behavioural Insights Team, 2014[4]): Provided a simple framework considering how behavioural insights may help design policies based on leveraging convenience, social aspects of decision making and the attractiveness and timeliness of polices;  

. World Development Report Mind, Society, and Behavior (The World Bank, 2015[5]): Gave a comprehensive overview of how the BI perspective on human decision making is of relevance to development policy 

. Define, Diagnose, Design, Test (ideas42, 2017[6]): Provided a practical framework for thinking through a problem and identifying behaviourally-informed solutions. 


 


. Assess, Aim, Action, Amend (BEAR, 2018[7]): Presented a playbook developed for applying BI in organisations outlining four steps for applying BI. 


 


 
Why a behavioural insights toolkit and ethical framework? 
5. BI is increasingly being applied to address problems faced by governments and public bodies at all levels and across the world (see Box 2). As BI becomes more widely applied, governments face challenges in  how to  apply BI in public policy as well as ensuring that the science is applied responsibly: 

. How can policy and behavioural insights practitioners work more effectively and systematically with applying behavioural insights in public policy?  

. How can policy and behavioural insights practitioners work to apply behavioural insights in a responsible way so as to maximise the protection of citizens from the potential threat of the misapplication or even misuse of behavioural insights?  


Box 2. What is behavioural insights? 
Behavioural insights (BI) is an approach to policymaking that builds on lessons derived from the behavioural and social sciences, including decision making, psychology, cognitive science, neuroscience, organisational and group behaviour (OECD, 2017[1]). Behaviourally-informed public policy is distinguished from traditional public policy making by (1) taking an inductive approach that is driven by experimentation and piloting, and (2) use of psychological theoretical underpinnings. BI then challenges established assumptions of what is thought to be rational behaviour of citizens and businesses and use these findings to inform policies and regulation.  
BI goes beyond the insights provided by the academic discipline of behavioural economics, as the latter is limited to studying the effects of psychological, social, cognitive, and emotional factors on the economic decisions of individuals and institutions. 
BI was born out of the 2008 Financial Crisis, which created serious challenges for government   budget resources became limited while citizen s trust in their public institutions eroded. In addition, stemming in part from poor understanding and lack of clarity of certain financial products, the Crisis highlighted the importance of taking into consideration cognitive biases when regulating markets and sectors. BI provided an approach for governments to address these shortcomings with fewer resources, while facing greater citizen demand. 
Over the following decade, BI has become an increasingly established concept in the public policy vocabulary. It was originally coined by the UK Behavioural Insights Team (UKBIT), which was created in the wake of the popular book Nudge: Improving Decisions about Health, Wealth, and Happiness (Thaler and Sunstein, 2008[8]). UKBIT used BI to refer to an evidence based approach to integrating insights and methodologies from the behavioural sciences in the policy cycle in order to provide better and more effective regulation (Halpern, 2015[9]).  
 


What is BASIC? 
6. BASIC provides a basis for thinking about these two questions through an overarching framework for applying BI to public policy from the beginning to the end of the policy cycle.  

7. The BASIC process begins with taking time to consider the context, with specific attention to understanding the political, institutional and policy setting where the potential initiative is expected to take place. These include considerations related to: 

. Political context, and the extent to which political leaders are aware of the use of BI and have been briefed on the actual and potential applications; 

. Institutional context, including co-ordination with key departments and institutions that could contribute to and benefit from a behaviourally-informed initiative; 

. Policy context, with a particular attention to ongoing policy initiatives and the extent to which a behaviourally-informed approach can inform existing policies. 


8. Equally important is to consider the key tenets of an evidence-based approach to policy making, including consideration of: 

. Defining the problem; 

. Pinpointing the policy objective that the initiative could help achieve; 

. Identifying the data and information needed to define the problem and design a solution; 

. Lining up possible interventions/insights; 

. Considering the potential impacts of the intervention. 

9. BASIC is built on five stages that guide the application of behavioural insights to any given policy issue: 

1. Behaviour, deals with the initial stage of applying BI at the beginning of the policy cycle so as to target crucial behavioural problems versus systemic issues;; 

2. Analysis, deals with the analysis of the target behaviours as viewed through the lens of BI; 

3. Strategies, that provides guidelines for the practitioner to identify, conceptualise, and design behaviourally informed strategies based on behavioural analyses that results from stage 1 and 2; 

4. Intervention, that presents core methods for systematically designing and evaluating the efficacy and reception of behavioural interventions; 

5. Change, that provides practitioners with tools for 1) checking whether the initial assumptions and contextual factors have evolved before rolling out a BI-informed intervention; 2) producing plans for implementation, scale, monitoring, evaluation, maintenance and dissemination of applications. 


When to use BASIC? 
10. (OECD, 2017[1]) shows the results of a survey of over 150 cases applying behavioural insights to public policy, the majority of which have been towards the end of the policy cycle, i.e. at the stages of implementation and enforcement/compliance (Figure 1). This supports the widespread idea that BI enters only after the policy issue has been identified and analysed. It is perceived to do so by suggesting behavioural tweaks and strategies, such as providing more salient information or providing users with the  right  default option to promote certain behaviours or even behavioural change. Finally, the BI methodology of experimentation and trialling can help governments improve the way they evaluate policy outcomes.  


Figure 1. The policy cycle 
 

Source: (OECD, 2017[1]); (Bridgman and Davis, 2004[10])  
11. This perception of BI as entering at the end of the policy cycle may indeed be partially self-inflicted by BI practitioners. (Sanders, Snijders and Hallsworth, 2018[11]), celebrating the 10-year anniversary of UKBIT, noted this perception and warned of the danger that  behavioural science is seen to offer merely technocratic tweaks  (i.e. letters, emails, text-messages) and focused primarily on results (i.e. the notorious abundance of bar-graphs in BI publications), rather than a more systemic change to the policy-making process. Thus, it should come as no surprise that BI is often perceived as analogous to public communication, a discipline that only enters to do its magic after the policy issue has been identified and analysed by other means and methodologies. A contributing reason might also be the very human pre-occupation with solutions rather than analysis.  

12. However, a deeper look at the BI approach and theoretical underpinnings demonstrate clearly that BI has a lot to offer in the ex ante appraisal and ex post evaluation stages of the policy cycle (OECD, 2017[1]) (OECD, 2018[12]). The BI approach requires a significant amount of time and effort placed in the early stages considering and defining the problem at stake, and identifying the behavioural barriers that can potentially undermine the effectiveness of policy solutions under consideration. BI is also a powerful tool for collecting data through testing and experimentation to understand what works, and what does not, from a user perspective when evaluating implementation. In this sense, BI can be applied throughout the policy cycle in pursuit of better:  

. Analysis: To better understand the behaviours of citizens by viewing these through the lens of behavioural insights. 

. Strategy: To use behavioural insights as active components in strategies aimed at influencing the behaviour of citizens. 


. Intervention: to use methods from the behavioural sciences to test and further develop public policy interventions. 

13. It should not be overlooked that more effective use of BI in the policy cycle depends on a close and systematic integration of all three bullets above. Tackling  wicked problems  and contributing to more systemic policy making change in the public administration requires BI to be applied throughout the policy cycle to better understand and identify relevant BEHAVIOURS, conduct better ANALYSIS, design better STRATEGIES, and test INTERVENTIONS to drive CHANGE improving public policies. It is BASIC, really (Figure 2). 


Figure 2. The BASIC framework 
 

Source: Hansen (2018) for the OECD 
How to use BASIC? 
14. The BASIC framework is built  for practitioners, by practitioners.  This framework is built partly on a synthesis of existing approaches, frameworks, tools and guidelines already widely used in the BI community and partly tools which have been specially developed by iNudgeyou   The Applied Behavioural Science Group during a decade of work with applying BI to public policy around the world.  

15. BASIC gives practitioners a step-by-step method for working through a policy problem with a behaviourally-informed approach. Two important caveats: 

1. Context matters throughout the stages: BASIC highlights the importance of working through the political, institutional and policy context. These contextual elements should be considered as practitioners work their way through all stages of the framework. 


2. Practitioners need to think carefully about where and when to use BASIC: Not all applications will, or should, progress through all five stages. Nor would all policy interventions require a behaviourally-informed approach. BASIC includes a process to scope the policy problem and identify those driven by psychological and cognitive biases, which are amenable to a behaviourally informed intervention, versus systemic issues (i.e. financial or physical constraints) that require an alternative intervention. The Behaviour stage also offers a problem-scoping methodology that can be useful for any policymaker when thinking through a problem, be it behavioural or systemic. 

16. Effective use of the BASIC framework depends on a close and systematic integration of Analysis, Strategy and Intervention. Simply writing a letter to jobseekers saying,  9 out of 10 people on the job market have work, you belong to the minority group that doesn t  is not likely to be effective in bringing people back to work. The practitioner must be equipped with a proper understanding of the behavioural problems faced by the unemployed, the policy issue at hand, and the wider selection of policy instruments available. Accordingly, BI needs to be integrated in the policy cycle from the outset, as discussed above.  

17. The ordering of tools and guidelines in a framework helps to highlight the way in which BI can be used throughout the policy cycle, a component often missing in the applied behavioural insights literature. These tools stress the interdependency between the various stages of the policy cycle: from how the behavioural reduction of a policy issue directs what behaviours to focus on, to how the analysis of such behaviours then influences the choice of behavioural strategies to be tested. These tests then should be designed to provide the proper basis for behaviourally-informed policy initiatives.  

18. Ethical considerations are highlighted at each stage, which need to be addressed as the practitioner works through the framework. These include considering whether possible behaviour changes are actually aligned with the interest of citizens, to giving consideration to the appropriateness of certain behavioural strategies relative to the problems addressed and securing privacy and equal treatment of citizens when designing field-tests. 


 
  
 
To recap BASIC why and what  
Why BASIC? 
BI is increasingly being applied to address problems faced by governments and public bodies at all levels and across the world. As BI becomes more widely applied, governments face especially two challenges in  how to  apply BI: 
. How can public bodies work more effectively and systematically with applying BI in public policy?  

. How can public bodies ensure that they work responsibly with applying BI in public policy? 


 
What is BASIC?  
BASIC provides a basis for thinking about these two questions through an overarching framework for applying behavioural insights to public policy from the beginning to the end of the policy cycle. BASIC consists of five stages that guide the application of behavioural insights to a given policy issue that contains a behavioural component: 
(1) BEHAVIOUR, deals with the initial stage of applying BI at the beginning of the policy cycle so as to target crucial behavioural problems; 

(2) ANALYSIS, deals with the analysis of the target behaviours as viewed through the lens of BI; 

(3) STRATEGIES, provides guidelines for selecting and adapting behaviourally informed strategies based the Behavioural Analysis resulting from stage 1 and 2; 

(4) INTERVENTION, presents core methods for systematically designing and evaluating the efficacy and reception of behavioural interventions; 

(5) CHANGE, provides practitioners with tools for 1) checking whether the initial assumptions and contextual factors have evolved before rolling out a BI-informed intervention; 2) producing plans for implementation, scale, monitoring, evaluation, maintenance and dissemination of applications.  


 


THE BASIC STAGES: Where to start when working with BI 
Roadmap 
This section explains what practitioners need to consider before entering the five BASIC stages, including:  
1. Exploring the political, institutional and policy context 

2. What to consider when setting up a team 

3. Determining the policy level of the work 

4. Checklist for scoping a BI project 


While this preparation work is essential for a successful behavioural public policy project, all of these concepts should be kept in mind and reconsidered as you move through the five BASIC stages. 
 


19. Applying BI will always be constrained by resources in terms of time, money or institutional leverage. This is often in ways that BI practitioners coming from outside of public policy might not be used to. Simultaneously, working with BI also poses some special challenges and requirements to practitioners only familiar with public policy, which may tax resources and relations, if not planned for. Thus, it is crucial for policy practitioners to consider the potential scope and level of a behavioural insights project even before beginning to work on the policy issue. Equally important is to take into consideration those contextual issues   political, institutional, policy related   that need to be factored in before designing and implementing any policy intervention.  


Exploring the political, institutional and policy context 
20. BI uses an empirical approach that differs from traditional policy interventions. The use of a range of methodologies that might be unfamiliar to traditional policy specialists, including, amongst other, extensive data analysis, observational studies, laboratory experiments, field-testing of prototypes, and extensive randomised controlled trials, creating a new set of challenges. 

21. It is crucial for practitioners to address some special considerations relative to the scope and level of a behavioural insights project even before beginning to work on the policy initiative. Equally important is to take into consideration those contextual issues   political, institutional, and policy related   that need to be factored in before designing and implementing any policy intervention.  

22. Some of these challenges may be addressed or mitigated by identifying, in advance, the kinds of problems and requirements a given BI project is likely to stir up as well as specific human resources needed to deal with these. In this way, the practitioner will be in a better position to manage cross-institutional expectations in relation to the project, identify what tools may realistically be applied and consider what human resources to involve at various stages of the project. 


23. Equally important is the consideration of the political, institutional and policy context where the intervention will take place. This include considerations related to: 

. Political leadership: are political leaders aware of the use of BI and have they been briefed on what BI can or cannot do? 

. Institutional set-up: where does the expected policy intervention fit within the administrative and government structure? Have the relevant institutions been mapped? Have opportunities and needs for co-ordination been considered and planned? 

. Policy space: what are the linkages with existing policies and interventions? Are there potential gaps and overlaps? If so, how can they be addressed? 

24. The important take-away is that the practitioner should devote time and thought into negotiating expectations to address challenges specific to BI applications. In addition, time and attention should be paid to the broader political, institutional and policy challenges that need to be addressed when considering a policy problem.  


Want to set up team? Then consider  
25. Applying behavioural insights is also about people doing the job and working together to design and implement a behaviourally-informed policy initiative. Whether centralised or decentralised, whether public or private, whether permanent or project-based, the success of the BI approach rests upon a team. There seems to be a set of features characterising the success for getting BI teams off the ground and making meaningful contributions. These characteristics are: 

1. Experienced leadership: a team should ideally be led by someone who has both first-hand experience with public policy and administration as well as behavioural science, including actual experience with running real world experiments. 

2. Diverse expertise: a team will need to encompass or be able to draw upon a variety of expertise, including intimate knowledge of policy processes and standard policy instruments, applied BI, cognitive and social psychology, behavioural economics, experimental design, and statistics. Thus, a critical mass of four to six full-time practitioners with diverse educational backgrounds is usually needed. In some cases, institutional constraints may only allow for a team that also relies on neighbouring disciplines. While this may strengthen the team, one should also be wary of the weaknesses that may result from differing ontologies, and methodologies. 

3. Mind-set, social skills and diversity: As applying BI requires practitioners to work extensively in the field and be willing to negotiate key aspects of their work, a special mind-set, extensive social skills and diversity is crucial. Practitioners should be clear that developing, designing and delivering public policy is not a desk-job, but involves working closely and respectfully together with, and as part of, front-line public service as well as with policy practitioners higher up the hierarchy and collaborators outside the public sector. As a team will also work across a variety of educational and social backgrounds to serve citizens living their lives outside the public sector   it is crucial that the team is diverse on this account and has actual working experience, inside as well as outside the public sector. 


4. Advisory board, network participation and collaboration: As BI is a steadily evolving and international field that involves high levels of domain-specific as well as cross-disciplinary knowledge it is highly recommended that the team establish an advisory body consisting of government officials, academics, and experts, to provide support, insights and direction. Also, it is crucial that the team orients itself and actively participates in national as well as international knowledge-sharing networks and events. Finally, the team should perceive itself as neither necessary nor sufficient, when carrying out projects. Instead it should welcome heavy involvement and collaboration with external partners and pay credits and honours where these are due. 

5. Secure a two to three-year commitment: Applying BI to develop Behavioural Public Policy is an empirical effort. It takes time to conduct proper behavioural analysis of the behavioural issues underlying policy problems, develop strategies, design, set up and run experiments, as well as implement on a larger scale. In addition, the inductive process involved is inherently fallible and thus calls for a sense of security that allows for failed experiments and protects the team from external pressure to take short cuts. For that reason, the team should ideally be granted a two to three-year commitment that allows it to develop the necessary infra-structure and institutional network, identify issues to work on, and develop, design and deliver advice on behavioural strategies for public policy. 


Determining the policy level of the project 
26. A crucial question to ask from the outset is  at what policy level is the project anchored?  Not only does this define its scope, resources and constraints, it also helps clarify potential positive and negative features that will influence the project.  

27. A way of approaching this question is by identifying at which of the following three levels a given BI project is anchored (see Table 1). Determining the level of the project will help the practitioner to identify in advance some crucial features, positive and negative, which will tend to shape the project. This will allow for developing suitable strategies and precautionary measures, relative to the necessary management of expectations and resources amongst all parties involved.  In addition, the scoping of the problem and type of intervention also helps identify the level of maturity in the use and application of BI. 


Table 1. Determining the level of the project 
 
Level of the project 
 Expectation for the intervention 
 
Institutional-level projects aim to apply behavioural insights to a wider institutionalised domain to provide an understanding of how this approach may help to transform public policy development and/or delivery.  
 
 Explore the  institutional fit  of behavioural insights, so to speak, by (1) providing knowledge about the institutional potential and relevant processes and methods involved when working with BI, (2) carrying out interventions that may serve as proof-of-concept, and (3) identifying the possible institutional obstacles that working with BI presents to the particular institution and its domain. 
 
Strategic-level projects aim to apply behavioural insights to one or more issues from a defined list of existing policy problems that challenge a particular institutional domain or sector. 
 
 Deliver viable and effective policy insights and solutions which are cost-effective compared to alternative policy measures by (1) extending existing knowledge about BI and building capacity for this within the institution, (2) applying the lessons learned from former institutional projects to strategic level problems to test for their robustness, and (3) providing scalable long-term solutions to one or more existing policy issues. 
 
Behavioural-level projects aim to apply behavioural insights directly to a specific behavioural problem in the institutional domain or sector. 
 Policy-makers, stakeholders and collaborators usually assume that the tools and methods for applying BI in public policy design and delivery are more or less fully developed. Thus, behavioural level projects are expected to fully integrate into the everyday decisions and processes of institutional work. The success criteria of projects at this level will usually be: (1) Smooth integration of process, (2)  problem solved , not  lesson learned , and (3) easily communicable results. 
 


Source: Hansen (2018) for the OECD 
28. In addition to identifying the project level, the practitioner should also facilitate a discussion on the scope of the project to manage and make expectations transparent from the beginning and identify the potential point of entry in the policy cycle where this intervention should occur.  


Checklist for scoping a behavioural insights project 
29. To avoid unpleasant surprises, the practitioner should sit down with everyone involved in the project and clearly communicate the special features that a behavioural insights project may come to involve dependent on the level of the project. Table 2 has some discussion points that you may have with your team that serve as a checklist to consider whether or not behavioural insights is appropriate for your project by starting scoping the problem. The discussion points can also be used to communicate with the other stakeholders what to expect when getting involved in this policy initiative.  


Table 2. Behavioural insights project scoping checklist 
Run through the following points with your team to scope the problem and communicate with stakeholders 
Completion check 
 Discussion point 
 
 
 Behavioural Insights does not apply to all problems. Given the surge in interest in behavioural insights, policy-makers may have unrealistically high expectations about its potential. However, behavioural insights cannot be applied to any kind of policy issue and it is rarely, if ever, able to solve behavioural problems completely and on its own. 
 
 
 
 Behavioural Insights is not about raising  general public awareness . In public policy raising  general public awareness  is often implicitly seen as the main-road to influencing behaviour. Behavioural insights, on the other hand, usually focuses on generating measurable changes in concrete behaviours, without necessarily resulting in measurable changes in general perceptions.  
 
 
 
 Developing Behavioural Insights is not necessarily  cheap . While applying the results from behavioural insights may be cost-effective, the development of these is not necessarily cheap. Groundwork needs to be carried out before coming up with ideas for what strategies to test.  
 
 
 
 Applying Behavioural Insights requires expertise. It is common to think that anyone can be an intuitive expert on behaviour, but that in itself is a bias since behavioural insights are often counter-intuitive. The practitioner should clarify what expertise is present in the project and why, as well as what working with applied BI means and how such projects tend to draw on the present expertise throughout a project.  
 
 
 
 Be critical of existing data and perceptions. Establish a critical, though not sceptical, attitude towards existing data and perceptions from the outset as a norm to guide the work of the team. Such material will often have been produced using standard methodologies, which do not necessarily align with the theoretical underpinnings of behavioural insights and may thus potentially undermine its application. 
 
 
 
 Secure permissions and agree on due credits from the outset. Make sure that the team is granted permission to oversee all stages of the project as well as receive due credits. Also, secure the team shared user-rights of results so that these are publicly available for scientific publication, public dissemination and journalists   this should, of course, also include null and negative results. 
 
 


Source: Hansen (2018) for the OECD 
  
Stage 1: BEHAVIOUR - Identifying and defining the problem 
 
Roadmap 
BEHAVIOUR refers to the initial stage of a behavioural insights project where practitioners will follow four steps that use thinking aids and decision-making tools to:  
1. Decompose the policy problem into its behavioural components; 

2. Prioritise what behaviours to assess as potential objects for behavioural insights; 

3. Describe potential behaviours in more detail as part of decision-making problems and processes; 

4. Identify behaviours with the best potential for a behavioural approach.  


Check before moving on to Stage 2: ANALYSIS 
The end of BEHAVIOUR provides a salient milestone. The team involved should consider bringing all stakeholders (advisory board, ethical review board, policymakers, etc.) together to ensure continued buy-in and support. Further, the team should also consider bringing in additional stakeholders into the project based on their relevancy relative to the identified target behaviour(s). Should it turn out that unforeseen problems show up during these meetings that prevent targeting the intended behaviour(s), the team may return to the step of the priority filter to work with those behaviours that failed to qualify in the first attempt. 
 


30. (OECD, 2017[1]) observes that BI has largely been applied to areas in policy implementation and enforcement/compliance. It also notes the potential for BI to be applied to earlier stages in the policy cycle, and there are signs around the world of this already happening. However, few tools and guidelines exist for how to integrate BI at these early stages. In particular, there is a lack of knowledge about how BI translates policy challenges into behavioural problems, as well as what thinking-aids and decision-making tools that can be used to effectively evaluate when to apply BI instead of other available policy instruments. 

31. Stage 1 aims to provide these aids and tools by focusing on decomposing the policy problem. This stage begins by determining the level of the project (policy, strategic, or behavioural), and then applying tools and aids to focus the policy problem into key behaviour(s) that will feed into Stage 2 of the BASIC approach.   

32. This is a fundamental but often overlooked stage that focuses on determining a policy problem before planning an intervention (be it behavioural or more traditional). Through its experimental/inductive approach, BI forces practitioners to think harder and more systematically about the problem to address before deciding on how to address it. 

33. This stage is about scoping problems. That is, it is not aimed at explaining behaviour or identifying strategies for behaviour change   these are the other stages of BASIC. The aim is to identify, define, evaluate and select those behavioural problems contained within a wider policy challenge that are particularly suitable for a BI approach. This stage also involves a series of ethical considerations that practitioners should consider, which are presented at the end of the section. 


34. Before you begin, you will want to gather the following necessary information to help feed into the tools and aids (remember: context matters!): 

. Problem definition: what is the problem? What is behavioural and what is not? 

. Key objective: what is the policy objective that the intervention could help achieve? Is a behavioural intervention sufficient? What other tools are needed? 

. Data: what data and information are needed? What methodology could be potentially used? 

. Options: what are possible solutions and at what level (institutional, systemic, and individual) can these solutions be implemented? 

. Impact: what are the potential impacts? Can they be measured and assessed including by using behavioural insights? 


Key steps to scoping a problem  
1. Decomposing the policy problem through behavioural reductions 
Figure 3. Thinking Aid: Considering the level of the project 
Goal 
 Visual aid 
 Decision-making tool 
 
1.A. Scoping the project based on the institutional level of the project and the special characteristics of Behavioural Insights 
  

 Use consideration points to define the various levels of the project from high-level policy, down to strategic and behavioural levels and manage expectations relative to the behavioural insights project. 
 


Source: Hansen (2018) for the OECD 
35. Through the application of a series of thinking aids and decision-making tools practitioners can identify, conceptualise, evaluate and select those behavioural problems contained within a wider policy issue that are particularly suitable for a behavioural insights approach. These tools can also help the practitioner to think more broadly about a problem and help any policymaker, BI-focused or otherwise, better understand the issue at stake before rushing to solutions. 

36. This stage would also require differentiating between a behavioural and a systemic problem. Policymakers are sometimes confused about the difference between behavioural and systemic constraints. They shouldn t be. 

37. Decomposing behavioural problems can be complex and require a systematic approach including by using some of the tools presented in Stage 1. Nevertheless, for an initial scoping of the problem, policymakers should ask themselves: 

. Is the constraint that impedes a certain action economic, physical, or material? For example, if the objective is to encourage greater consumption of fruit and vegetables, the costs of these products or their availability would be a systemic constraint (and therefore non-behavioural). 

. Is the constraint that impedes a certain action induced by psychological or cognitive factors? The attention paid by the consumer to fruits and vegetables can be a result of desirability or their placement in the supermarket aisle. For instance, 


pre-cut versus whole vegetables determines our cognitive capabilities to choose them (and therefore makes the problem behavioural). 

38. Decomposing the problem puts a strong emphasis on data collection, evidence and precautionary measures in defining what behaviour may be influenced by behavioural insights, leaving the exploration of why this behaviour occurs to the subsequent stage of analysis. 

39. Now that you have determined the level of the project, you can apply the behavioural reduction tool to decompose the policy problem into concrete behaviours. 


Figure 4. Behavioural reduction tool: Decomposing policy issues into behavioural problems 
After deciding the project level, create the appropriate behavioural reduction structure 
Goal 
 Visual aid 
 Decision-making tool 
 
1. B. Identifying constituent behaviours within wider policy issues to which behavioural insights might potentially be applied. 
  

 Create a behavioural reduction structure to decompose policy problems, first into strategic domains and then into their constituent behaviours. 
 
 
Sample behavioural reduction structure 
 
 

 
 


Source: Hansen (2018) for the OECD 
40. Whether speaking of big reforms or operational tinkering, public policy development and delivery is ideally driven by planned efforts. BI is well suited to this ideal as it aims to deliver slow, incremental, evidence-based and  gentle  (i.e. not purely  command and control ) regulation. However, the empirical drive of BI means that it ultimately applies at the operational levels of public policy development and delivery, not to the big ideas.  

41. This creates an obvious challenge: how can high-level policy planning be connected with the operational-level design and delivery of policy? On the one hand, at the early stages of the policy cycle, issues are usually formulated too vaguely and broadly for identifying what concrete behaviour changes to target at the operational level to effectively help resolve the policy issue (Soman, 2015[13]). On the other hand, tinkerers working at the 


operational level will often find it difficult to assess whether the behaviours targeted are actually the most pertinent ones for addressing the larger issue at stake. 

42. A Behavioural Reduction can help bridge the gap between the policy and the operational levels. It is a simple tool whereby the practitioner constructs a hierarchical branching tree model to map how a general policy issue connects to concrete behaviours. In its most simple form, the reduction is carried out in three steps that aim to decompose the policy problem into its many behavioural components. In this way, the behavioural reduction allows for identifying the concrete behaviours tied to the policy problem to which BI may be applied. This should be as concrete as possible. The practitioner can follow this process by:  

1. Plotting the general policy area or challenge at the top of a whiteboard. This is referred to as the Policy Level of the Behavioural Reduction.  

2. Pinning the relevant strategic domains within which the policy issue arises. This level is referred to as  the Strategic Level  of the behavioural reduction.  

3. Pinning each of the strategic domains into the concrete behavioural problems. The items at this level of the reduction should be concrete decisions, behaviours and procedures. Hence, this level of the behavioural reduction is also referred to as the Behavioural Level (for illustration, see above). 


2. Prioritising behaviours to be included your BI project 
Figure 5. Tool: Priority filters 
Having built your behavioural reduction structure, prioritise which behaviours are suitable for intervention 
Goal 
 Visual aid 
 Decision-making tool 
 
2. Evaluating and prioritising these behaviours relative to how suitable they are for a BI approach. 
  

 Apply priority filters to prioritise which of these behaviours are behavioural problems suitable for an effective application of BI based on core features. 
 


Source: Hansen (2018) for the OECD 
43. Whether as a result of a Behavioural Reduction or not, the first stage of a BI project will usually present the practitioner and her team with a wider set of initial behavioural problems to which BI might potentially be applied (sometimes also called a  gross list ). Thus, the practitioner will need some sort of decision tool to develop a short list of those behavioural problems that are most likely to provide for a successful project, also called a  net list .  

44. The  priority filter  is such decision-tool. The priority filter is an instance of what in the BI literature is referred to as a weighted additive decision rule, where choosers assign importance weights to each attribute of a choice option and then compute an overall score for each alternative by summing up the product of the importance weight and the score of that alternative (Payne, Bettman and Johnson, 1993[14]). The assumption of the priority filter is that the success of a BI project crucially depends on a series of practical as well as empirical features. 


45. Table 3 presents a priority filter formulated in terms of a questionnaire. Each question tries to identify the presence or absence of crucial features by means of Likert scale evaluation. In addition, based on the specific project each feature should be attributed a weight, before adding the score for each problem considered. It is important that such weights are formulated prior to scoring problems, and possibly concealed to respondents, so as to avoid motivated fiddling with these. Finally, one also needs to apply some decision rule for shortlisting problems based on the result, e.g. deciding only to continue with the three problems that get the highest score. 


Table 3. Priority filter questionnaire 
Fill out one questionnaire per behaviour using a Likert scale: (1) = definitely not, (2) = probably not, (3) = uncertain, (4) = probably, (5) = definitely. 
Problem behaviour identified: 
 
Question 
 Score 
 
1. 1. Does the behaviour appear to be a behavioural problem?  
That is, does the behaviour occur despite people having good reasons to act otherwise as judged by themselves? 
 1         2          3          4          5 
 
2.  Are the reasons for a change in behaviour well documented?  
That is, is the evidence that supports question (1) produced by methodologies compatible with the psychological theories underpinning BI? 
 1         2          3          4          5 
 
3.  Has similar problems been addressed with Behavioural Insights?  
That is, can you identify studies or projects where BI have been applied to a similar problem? 
 1         2          3          4          5 
 
4.  Is a change in the behaviour an institutional priority?  
That is, would a group of policymakers in the domain intuitively evaluate changing the behaviour as an institutional priority? 
 1         2          3          4          5 
 
5.  Could changing the behaviour serve as a  proof of concept ?  
That is, would a success in changing the behaviour serve as a proof-of-concept in addressing a wider set of policy issues? 
 1         2          3          4          5 
 
6.  Is targeting the particular behaviour uncontroversial?  
That is, will policy-makers, citizens and relevant societal organisations agree that it is legitimate to try to change the behaviour with BI?  
 1         2          3          4          5 
 
7.  Are relevant stakeholders motivated and ready to engage?   
That is, would relevant stakeholders have the time and willingness to engage in a project concerning the behaviour if you asked for their collaboration? 
 1         2          3          4          5 
 
8.  Are the relevant arenas accessible for the BI project?  
That is, are the arenas in which the problem unfolds accessible to the behavioural insights team relative to ownership and/or privacy issues? 
 1         2          3          4          5 
 
9. Is the relevant data accessible?  
Will it be relatively easy to get hold of existing data or record behavioural data in light of practical and/or ethical issues? 
 1         2          3          4          5 
 
 
 FINAL SCORE: 
 


Source: Hansen (2018) for the OECD 
46. Another way of prioritising behaviours is to discover situations where people fail to do what they intended to do or would have preferred to do  on second thought . Such failures are also referred to as behavioural problems.  Deciding whether a behaviour constitutes a behavioural problem may be a complex issue. Nevertheless, for an initial assessment of whether this is the case, and what aspects of the problem considered may be regarded as behavioural, practitioners may apply a decision-tree (Figure 6) 


Figure 6. Is the behaviour studied a behavioural problem? 
 

Source: Hansen (2018) for the OECD 
3. Describing potential behaviours using behavioural maps 
Figure 7. Behavioural pattern descriptions 
Goal 
 Visual aid 
 Decision-making tool 
 
3. A. Conceptualising prioritised behavioural problems as decision points in such a way that the lens and analytical tools of BI can readily be applied. 
  

 Use behavioural pattern descriptions to describe highly prioritised behavioural patterns in behavioural terms so as to allow for the application of concepts and methods from the behavioural sciences. 
 


Source: Hansen (2018) for the OECD 
47. The concept of behaviour is so familiar to most people, including practitioners, that one may easily forget that the process of applying BI is not the same as developing a better understanding of the everyday behaviours we see. Rather, applying BI relates to a scientific conceptualisation of behaviour, i.e. to behaviour as seen through the lens of the theories and methods underpinning the BI paradigm. Thus, the next step is for the practitioner to ensure up front that the behaviours studied are defined in accordance with these theories and methods. 

48. Something to notice when working with a BI project is that the focus is not on that of particular behaviours tied to particular individuals or groups, but rather behavioural tendencies, i.e. behavioural patterns, as these unfolds in a given context. This also implies that the field is different from, for instance, sociological and communication science, where one often starts by defining target groups for an intervention in demographic terms. A BI project usually derives the target group from a behavioural pattern. This is not to say that demographic groups based on gender, age, income, etc. may not be used as defining traits of groups as well.  

49. In addition, a behavioural pattern cannot be directly observed. Thus, identifying a pattern is a constructive act, in which a model of the mind connects empirical observations   that is, it is  a theoretical conceptualisation . To apply BI then, the practitioner needs to define the relevant behavioural patterns underlying the behavioural problems selected by the priority filter. 

50. Anyone trained in decision theory will recognise the process of conceptualising decisions where  decision trees  are abundant. Different from decision trees, conceptualising potential target behaviours involves more than just a generic agent and options, but also the defining context and desired distribution of choices. The steps (illustrated in Figure 7) are as follows: 

1. Define a generic agent (the  who ) 

2. Provide the generic agent with a  set of available choice options (the  what ) 

3. Provide context to the set of options where the behavioural pattern unfolds (the  when-and-where ) 

4. Develop a descriptive frequency distribution over the choice options, describing how much the target behaviour over the non-preferred behaviour is experienced in percentage terms 

51. At times one may encounter a behavioural problem that is part of a process or chain of actions. In such cases, one may draft a  behavioural flowchart  (see Figure 8). A flowchart is a well-known tool in data science and related disciplines. Flowcharts use a defined set of arrows and shapes to represent activities and relationships in a process. The goal of the diagram is to show how the steps in a process fit together by breaking down a process into individual activities and illustrating the relationships between these activities, as well as the flow of the process. 


Figure 8. Tool: Behavioural flowcharts 
Helps conceptualise behavioural problems to identify crucial decision points 
Challenge 
 Visual aid 
 Decision-making tool 
 
3. B. Conceptualising behavioural problems as processes in such a way that crucial decision points may be identified. (Then return to 3.A.) 
  

 Use behavioural flowcharts to describe how a process unfolds and how people make choices throughout this. 
 
 
Symbols used when constructing behavioural flowcharts 
 
 

 
 


 Source: Hansen (2018) for the OECD 
52. A behavioural flowchart provides a detailed description of how a process actually unfolds as well as attaches behavioural measures of how people make choices throughout the process.  This allows for quantitative comparative analysis of decision points in the flowchart aimed at identifying the most crucial decisions to focus on.. The simplicity of behavioural flowcharts also make them useful tools for understanding and sharing processes in teams as well as analysing these in an effort to identify, besides crucial decision points, potential loose ends and friction points that inhibits the efficiency and reliability of the process. 


4. Identify behaviours with the best potential for a behavioural approach  
Figure 9. Tool: Selection filter 
Challenge 
 Visual aid 
 Decision-making tool 
 
4. Finally, select what behavioural problems to target for further analysis. 
  

 Apply selection filters to finally select what behavioural problems to target for further analysis. 
 


Source: Hansen (2018) for the OECD 
53. At this point, a  net list  of potential behavioural problems has been identified to target potential behaviours for a BI project. The next, and final, step of this stage is to select the problem(s) that exhibits the best possible conditions for behaviour change with a sizeable impact through the application of BI. In assessing this, three heuristic questions (i.e.  rules of thumb ) to identify target behaviours are important to consider. 


(1) What do base rates combined with past policy effort indicate about how difficult it will be to change the behaviour?  
54. A low base rate (<10% conformity to the preferred behaviour) may indicate, for instance, that only a small number of people currently engage in this behavior or that very little effort has been put into changing this behaviour in the past. If the latter is the case, it might not be a behavioural problem after all and traditional strategies may be a natural first step. However, if a high amount of effort has been devoted to changing this behaviour, then practitioners should question what has been done so far and why base-rates remain low despite past effort. 

55. A similar point pertains to very high base rates of conformity with the preferred behaviour (>90%). If everyone is doing the right thing with little policy intervention, then traditional policy efforts might be a first choice. However, if a lot of effort has been put into changing this behaviour, the practitioner should investigate whether there might be special challenges or reasons why a small number of people do not conform to the behaviour enacted by others. Possibly such inquiry may lead to a revision of the target group associated with the behaviour studied and thus a reconceptualization of the behavioural problem. 

56. Finally, many practitioners interpret a medium base rate as a good indicator of the potential for behaviour change with a sizeable impact through the application of BI. A reason for this is that BI mainly applies to behaviours resulting from limited attention, informational complexity, weak preferences and minor friction, all of which are factors making us vulnerable to behavioural bias. However, the studies of bias that underpin BI rarely see extreme base rates. Thus, medium base rates better reflect the phenomena studied by the underlying science. Medium base rates may also have been overlooked by past efforts, as extreme cases attract more attention. 


(2) How will a potential behaviour change translate to impact? 
57. Another crucial question to consider when evaluating the potential of changing target behaviours is how such change will translate into individual and societal impact.  

58. The relationship between the magnitude of the behaviour change and the resulting impact varies depending on the issue at stake. To illustrate, one might aim to reduce street litter in order to reduce a city s cleaning costs. Yet, even a reduction of 50% of litter might not have any economic impact at all. This could be the case if even mildly littered streets are unacceptable to a city and its citizens. As a consequence, the municipality will have to clean the streets with the same frequency and costs despite achieving 50% reduction in litter. At the other extreme, sometimes even slight behavioural changes may generate a big impact. This is for instance the case when it comes to generating competition on complex markets. Here it may only take 5-10% of consumers actively engaging in price comparisons to drive competition with resulting benefits for all consumers. As a result, one needs to carefully analyse how each of the potential behavioural changes considered is likely to translate into impact. 


 (3) What is the frequency with which the behaviour occurs? 
59. A third and final question one needs to consider when deciding which behaviour to target is how frequently the behaviour occurs. This question goes beyond asking about the relationship between behaviour change and impact, as the behavioural pattern may be so infrequent that the expected total societal impact will be negligible. On the other hand, behaviour with apparent marginal costs or benefits per instance may be so frequent that the 


aggregate impact of even a slight behavioural change may be considerable. Also, a measure of the frequency with which a behaviour occurs will provide valuable information about how long it will approximately take to reach the required number of observations to allow for statistical analysis in the case that an intervention aimed at changing the behaviour is to be tested. 

60. Together, these three considerations may be used as heuristics (i.e.  rules of thumb ) to select which behavioural problem to target in a behavioural insights project, i.e.  the target behaviour . 


Ethical considerations 
61. A BI project will need to collect and make use of types of data, which is often not contained in the databases of governmental agencies. This includes: (1) primary behavioural data (i.e. data on or related to the real-world behaviour of citizens); (2) secondary behavioural data (i.e. data on variables related to people s attention, belief-formation, preference-construction, determination and more); (3) contextual data (i.e. data on contextual variables, including seemingly irrelevant aspects of choice architectures); and (4) data on people s reflective preferences (in so far as such exist) about what people believe they ought to do given their available options.  

62. As a result, the initial stage of a BI project raises a series of special ethical issues that needs to be considered from the outset. The BEHAVIOUR stage recommends 10 ethical guidelines that seek to establish:   

. Special considerations for the use of private-data as this will often pertain, not only to attitudes and beliefs, but also to actual behaviour of citizens. 

. Making explicit considerations about regulatory/programme/policy purpose and paradigm of the project to ensure that it is truly aimed at being welfare enhancing. 

. Proper documentation of the evidence in alignment with the behavioural paradigm of purported internalities or externalities of the behaviour that the project targets.   


Table 4. Ethical guidelines for Stage 1: BEHAVIOUR 
1. Ethics is an issue to be observed from the outset of BASIC. As a first step in BEHAVIOUR establish an ethical review board to follow the project from day one and throughout its existence with a clear eye on the following guidelines. 
 
2. BEHAVIOUR, like other explorative stages in behavioural insights projects, often involves data collection and analysis that goes beyond what is standard in government agencies. Appoint at least one member of the ethical review board to supervise ethical aspects of data collection and use. 
 
3. BEHAVIOUR is characterised by working across institutional boundaries. Make sure all team-members observe existing ethical guidelines and codes of conduct of the particular fields that the project involves as well as receive the necessary training to comply with these. 
 
4. Do not be a passive bystander. Discuss and establish procedures for how the team handles collaborating parties that fail to comply with their own ethical guidelines and codes-of-conduct, while also observing that honesty, anonymity, and whistleblowing is to be protected. 
 
5. Existing ethical guidelines and codes of conduct will not cover all aspects of a BI project. As part of BEHAVIOUR, establish a procedure from the outset for flagging activities and data collection that are not covered by these, and discussing this with the ethical review board. 
 
6. BEHAVIOUR targets behavioural problems, i.e. behaviours where people fail to achieve their preferred ends due to psychological factors. Yet, not all such behaviours fall within the legitimate confines of public policy. Make sure that the team refrains from targeting behaviours and behaviour changes that it cannot defend in public as well as in the wider Behavioural Insights community. 
 
7. While BEHAVIOUR targets behavioural problems, it does not automatically follow that behavioural insights will be applied in the service of people s own interests. Always consider the legitimacy of the public motive behind targeting a given behaviour for change by comparing this to the regulatory paradigm the team is operating within. 
 
8. BEHAVIOUR conceptualises behaviours as the aggregate patterns of groups. Yet, individuals usually hold distinct preferences. Always assess the heterogeneity of preferences in groups and consider how to protect individual rights, values and liberties when targeting behaviour change. 
 
9. A change in one behaviour often leads to changes in other behaviours. Always consider potential side effects of pursuing a given behaviour change, involve stakeholders with relevant knowledge about these and create suitable measures for monitoring potential side effects throughout all relevant stages in the project. 
 
10. Behavioural Insights is underpinned by psychological theories that take people s self-reported behaviour, beliefs and preferences to be easily influenced by the immediate context. To serve the people, rather than the context, always evaluate the existing evidence for targeting a given behaviour change through the lens of the theories that underpin Behavioural Insights. 
 


Source: Hansen (2018) for the OECD 
 
 
Stage 2: ANALYSIS   Understanding why people act as they do 
Roadmap 
Objective: In this stage, the practitioner focuses on analysing the target behaviours and related choice architectures through the lens of behavioural insights. This stage utilises the ABCD-framework for understanding why people act as they do. This section will: 
1. Introduce the ABCD methodology as the approach for analysing a target behaviour; 

2. Use the ABCD methodology to generate hypotheses for testing; 

3. Pose ethical guidelines for consideration in Stage 2: ANALYSIS. 


Check before moving on to Stage 3: STRATEGIES 
Provided that the practitioner has reached a satisfying confidence level with regards to the outcomes of this section, Stages 1 & 2 may be referred to as a  BEHAVIOURAL ANALYSIS  of the policy problem. This can then be used as a suitable foundation for identifying and conceptualising effective behavioural STRATEGIES to inform public policy (Stage 3). 
 


63. The first stage of BASIC focused on targeting behavioural problems from the outset of the policy cycle. This stage ended with the practitioner identifying one or more behavioural problems to which BI may potentially be applied.  

64. Stage 2: ANALYSIS aims to understand why people act as they do relative to the target behaviour, as seen through the lens of BI. This is particularly challenging, as insights from the behavioural sciences are often counter-intuitive. Consequently, people cannot easily report on the psychological mechanisms and resulting cognitive biases influencing their behaviour.  


ABCD   a framework for understanding why people act as they do 
65. At the heart of BASIC is an iterative systematic inquiry combined with behaviourally-informed indicators and mixed methods that seeks to solve this problem. This is the ABCD framework, which is introduced in this chapter and will be progressively developed through the next two stages. 

66. The selection of method(s) is based on what kind of information is sought, from whom and under what circumstances (Robson, 2001[15]). Different from traditional scientific research, the study of behaviours in the real world is characterised by the adoption of flexible research designs where the nature and number of methods used can change as data collection continues. Thus, there is no single or straightforward way to go about understanding why people act as they do in a BI perspective. 

67. The behavioural sciences present a wide range of methodological approaches for studying the individual, social and contextual factors that cause behaviours, and how such behaviours may be modified. Unfortunately for BI, these methods have been designed for strictly controlled conditions in laboratory settings. Hence they are not readily applicable 


to studying the behaviours of citizens, consumers, and employees acting in the real world, nor to designing better public policy. 

68. For this reason, there is a tendency for some practitioners to become attracted to applying more standard methods for studying behaviour in the real world, such as classical questionnaires, interviews, focus groups, etc.; or more fashionable methods such as design-thinking, co-collaboration and anthropological approaches. A further reason for this tendency is also that as people without training and background in the behavioural sciences become involved in BI a pressure has built up for expanding BI so as to encompass their area of expertise.  

69. However, it is important to notice that methodological eclecticism is constrained by theoretical consistency. One cannot, for instance, ask a person to explain why they do what they do, while at the same time assuming the drivers of behaviour to be largely outside the bounds of rationality. Thus, practitioners should pay close attention to what aspects of methodologies can be reconciled with the psychological theories underlying behavioural science and what cannot. Consequently the application of such standard methodologies only makes sense given that they are suitably adapted to accommodate for the insights provided by the psychological theories underpinning BI.   

70. In accommodating standard methodologies to BI probably the first and foremost principle to observe is the consequences that dual process theories have for the constructs and phenomena studied. According to BI self-reports are usually regarded as inherently unreliable as these are taken to be subject to cognitive bias and heuristics. Again and again the behavioural sciences have shown how self-reported memories, beliefs, preferences, intentions and experiences are not mental facts fetched from our inner libraries, but rather seem to be constructions assembled when the circumstances calls for them. As behavioural scientist Nick Chater (2018[16]) puts it,  the mind is flat  and the illusion of an inner library is itself a  poppycock  cognitive illusion. 

71. A result of this observation is that any standard methodology involved in a BI-project should be treated with care and always be methodologically triangulated. Qualitative interviews, self-reported answers to survey questions, and even observations should be treated as explorative experimentations tracing the truth rather than providing it. Inclusive workshops, focus groups, and expert interviews should be evaluated relative to the mental distance from the actual behaviour inquired into and are thus usually to be disfavoured relative to methods such as situ interviews, direct observational studies and first-hand experience by practitioners themselves. Also in this aspect the BI approach to public policy is new. No policy can truly be said to be behaviourally informed if the informant has not been there herself to observe through the lens of BI   from within as well as from the outside   how the target behaviour subject to the policy actually unfolds in its natural context.  

72. That said, at the heart of BASIC is the idea that through iterative systematic inquiry combined with behaviourally informed indicators and mixed methods as well as, when possible, small-scale tests, practitioners may form hypotheses based on best guesses according to the best evidence available   much like doctors devise diagnostics procedures and tests to form hypotheses about illnesses based on their systematic relationship to symptoms. While this may not always be possible   as, for instance, when observations and even small scale tests are not possible   the reason for pursuing this diagnostic approach in the analysis of behaviour is the idea that this may provide a more effective and responsible approach to the development of behaviourally informed STRATEGIES to be 


tested as part of the stage of INTERVENTION. To this end the stage of Analysis offer a framework called ABCD for structuring the diagnostic inquiry. 


ABCD   A framework for understanding why people act as they do 
73. Enter the ABCD framework, which will be developed in the next two stages. Like existing BI frameworks, such as MINDSPACE and EAST, BASIC seeks to assist practitioners in analysing behavioural problems by providing concepts from the behavioural sciences. Different from these frameworks, however, BASIC goes beyond presenting a list of selected insights. Instead it includes a structured diagnostic approach, i.e. an approach to analysing behaviour referred to as the ABCD taxonomy (see Figure 10).  

74. Through small-scale tests (when possible), practitioners may use this framework to form hypotheses based on best guesses according to the best evidence available   much like doctors devise diagnostics procedures and tests to form hypotheses about illnesses based on their systematic relationship to symptoms.  

75. When small-scale testing is not possible, pursuing the diagnostic approach elaborated below still provides a more effective and responsible approach to the development of behaviourally-informed STRATEGIES (Stage 3) to be tested as part of the stage of INTERVENTION (Stage 4). 

76. This approach is derived from the fundamental assumption of BI that behavioural problems result from systematic deviations from what is predicted by the rational model. It then systematically matches this analysis to tools and solutions presented in Stage 3: STRATEGIES. This process is presented in the Figure as: 

1. Diagnostic indicators: The inner two circles in the figure that helps the practitioner narrow behaviours into their respective section(s) of the ABCD Framework. This will be developed in the remainder of Stage 2: ANALYSIS 

2. Strategies: The second circle that gives the practitioner a starting point for solving behaviours diagnosed in the respective section(s) of the ABCD Framework. This will be further developed in STAGE 3: STRATEGIES. 

3. Insights: The outermost circle that gives the practitioner behavioural solutions that have been used in different contexts around the world as a starting point for testing possible behaviourally-informed policy initiatives. This will be further developed in STAGE 3: STRATEGIES. 


Figure 10. The ABCD framework 
 

Source: Hansen (2018) for the OECD 
Using ABCD to analyse behavioural problems 
Box 3. Critical steps for using the ABCD Framework 
For the next two stages, you will be running your target behaviour(s) through the ABCD framework to ANALYSE (Stage 2) in which domain(s) your problem lies (attention, belief-formation, choice and/or determination) so that you can identify and apply the appropriate STRATEGIES (Stage 3).  
It is implicit, but worth noting: your policy problem can lie in more than one domain, so care must be paid to considering the full framework in your analysis. The outcome of Stages 1 & 2 collectively may be referred to as a  behavioural analysis  of the policy problem.  
In particular, the critical steps are to: 
1. Select a target behaviour for ANALYSIS (see Stage 1: BEHAVIOUR)  

2. Become familiar with the behaviour studied by observing the behaviour, engaging in the behaviour, interviewing people engaging in, or otherwise involved in the behaviour; as well as by determining what data already exists and examining this. 


 


3. Use indicators like those defined by ABCD to hypothesise what behavioural aspects (attention, belief-formation, choice, determination) are likely to be involved in causing the behavioural problem.  

4. Consider all potential data that could, in principle, be recorded about the target behaviour relative to the generated hypotheses in (3) if everything was possible. 

5. Determine what further data could be recorded through behaviourally-informed methods to support or even test hypotheses in (3). 

6. Return to the field to study, record further data and if possible conduct falsifiable tests of the hypotheses about what behavioural factors may cause the behavioural problem involved in the target behaviour. 


Repeat step 2 to 6 until the team is sufficiently confident in the viability of the hypotheses given the time and cost constraints of the project. 
 


77. The framework begins with ABCD itself: Attention, Belief-formation, Choice, and Determination. The framework assumes that behaviour can be analysed and classified according to these domains, which provide reasons for rational choices and behaviour. Over the next two stages, these four high-level behavioural domains will anchor our analysis and strategy formation that leads into Stage 4: INTERVENTIONS. These domains are:  

. Attention is about what to focus on in a given context. Here the rules of rationality are quite simple. To act rationally in this domain, people should focus upon what is the most important aspect of the context in light of one s knowledge and preferences, given that people cannot focus on everything. 

. Belief formation is about making judgments provided the information that one has available. Here the rules of rationality are quite complex and have been a subject matter of philosophy and theory of science since ancient Greece. Simplified somewhat, to act rationally people should form their beliefs according to logic rules as applied to well-defined propositions as well as rationally updated beliefs in light of new information according to sound probability theory. 

. Choice is about making decisions between the available choice-options given one s preferences. How to do this rationally has traditionally been the subject matter of philosophy of choice, decision theory and microeconomics. Again simplifying, to act rationally people should make choices so as to maximise subjective expected utility.  

. Determination is about making choices and then sticking to them. Determination, including the subject matters of self-control and will power, has not been studied much relative to rationality. The reason for this is that the rules of rationality are quite simple in this domain as well. Provided that one decides to pursue certain long-term goals one should stick to the plan.  

78. Ignoring the details of academic debate, the rules of rationality as applied in these four domains are quite uncontroversial. That is, forming logically sound beliefs according to the information available, making choices that maximise subjective expected utility based on ones preferences (whatever they might be), and then sticking to those choices is advice that any reasonable person would subscribe to.  

79. Yet, advances in the behavioural sciences have revealed that people inhabiting the real and complex world, have difficulties adhering to this advice thus making us predictably 


irrational. While we readily embrace the rules of rationality as these express the highest art of reflective thinking, we tend to forget that intuitive-automatic processes provides the foundational as well as, at times, the only mechanisms determining our behaviour. 


Domain 1: Attention - the window of the mind 
80. We begin by looking at attention   the window of the mind and the crucial capacity that defines the boundaries of conscious thought. Depending on the theoretical lens through which the policymaker looks, the views on attention are treated quite differently.  

81. On the one hand, from the rational perspective, human attention is a relatively inconsequential concept. Economics, law or other discipline traditionally informing public policy rarely discuss the concept of human attention. Here, the assumption is often that human attention is boundless since we assume attentional capacities is devoted to whatever is most important. This follows naturally into the rational model of human behaviour to be that of maximising expected utility. In other words, rationality with regards to attention assumes we are all Spiderman or Wonder Woman. 

82. On the other hand, behavioural science treats human attention in marked contrast. Here, human attention is scarce, easily distracted, quickly overwhelmed and subject to  switching costs . All of these seriously affect our ability to spot what is important, as well as bias our rational processing of whatever is in focus.  

83. These two views present a very different analysis of human behaviour that leads to very different policy advice. From a rational perspective this behaviour appears deliberate; from a behavioural viewpoint, behaviour is influenced in ways that provide a more nuanced understanding of why people act as they do:  

. Forgetting: People require cues to signal that they need to pay attention to a specific action. If there is nothing prompting an action in a given context, then people will tend to forget to carry out this action. As a consequence, people may miss their doctors  appointments, fail to file tax, take their medication, and the like. 

. Overlooking: People require cues to attract attention to alternative tasks. Without these cues, they will tend to overlook the appropriate action. As a result, people may easily overlook speed limits when driving, sanitizers when visiting family at the hospital, and gorillas when they are counting passes of a basketball. 

. Relegating: If an action is cued in a context where more pressing tasks are attended to, people will tend to relegate attention to the action cued. Consequently, people tend to relegate attention to actions, even when cued in an irrelevant context. For example, this happens when cuing people about deadlines for filing taxes while seated in the cinema or warning young people partying about the long-term health consequences of smoking. 

. Multitasking: If people are engaging in multiple tasks simultaneously, their ability to detect relevant information and perform cognitive tasks is influenced significantly. As a consequence, texting while driving leads to decreased performance in traffic, multitasking while working at industrial sites leads workers to ignore potential safety risks, and multitasking in the operating theatre results in surgeons ignore procedures. 

. Distractions: if people are switching back and forth between tasks, performing tasks in rapid succession, or become distracted by irrelevant cues in the context, cognitive performance as well as memory retention and retraction will suffer 


significantly. This is what happens when students switch forth and back between listening to a lecture and surfing the Internet, when office workers work in open plan offices, when employees go from mail to mail, or policymakers switch between emails and important decisions during a meeting. 

84. Addressing these behavioural problems requires policymakers to make the desired choice relevant, seize attention, and plan for inattention (see Stage 3).   


Domain 2: Belief-formation - making sense of the world 
85. The second aspect to look into relative to behavioural problems is the role played by belief-formation - the processes that aim to make sense of the world. In this domain, rationality assumes that everyone carefully searches for and scrutinises all relevant information; seeks new information and updates beliefs accordingly; and adheres to rules of logic and probability theory, even when matters get complex and extended computational power is required. Thus, a perfectly rational human would have the attention of a superhero when it comes to attention, and think like Einstein   or, at least, think like we think he thinks   when it comes to forming our beliefs.     

86. The behavioural model for belief-formation differs in almost every possible way from the model of rationality. Belief-formation is mainly about making sense of the world by consistently creating a coherent worldview that works well enough to make successful predictions and choices, within psychological limits imposed by attention, memory, information, and processing powers. This causes us to:  

. Ignore relevant information: People tend to ignore information that does not fit into their existing worldview or they fear may cause psychological discomfort. Even when searching for new information or better understanding, they tend form beliefs according to the information they have readily available, if sufficient for reaching a conclusion. 

. Erroneous sampling: People tend to seek out and believe more information that confirms their existing worldview. In situations of uncertainty, people are prone to perform sampling errors, such as when we neglect base-rates or use conveniently available information to form beliefs about the likelihood of events.  

. Confusion: People have difficulty distinguishing relevant from irrelevant information. For example, if asked to evaluate the truth of information, they may confuse the confidence and/or the credibility of the messenger with the likelihood of the message being true. Likewise, they be influenced by the availability in memory or recency of past thoughts when passing judgment. 

. Under/over-estimation: People tend to poorly estimate as concepts become more abstract, such as probabilities, money or time. For instance, people overestimate small probabilities and underestimate large ones, which impact our perceptions of chance and risk. Likewise, people underestimate the importance of new information   especially if it is unwelcomed   or how long a task will take to complete. 

. Relying excessively on  rules-of-thumb : People tend to rely on simple rules of thumb (heuristics) to reach conclusions, especially when under conditions of uncertainty. They are easily influenced by what other people do, use simple mental models to understand complex systems, and often fall prey to logical fallacies 

87. As with attention, this has practical policy implications. However, the policy implications arising from the belief formation domain are much more far-reaching. Most 


of the evidence that is usually collected to inform public policy relies on the possibility of successfully tapping into people s beliefs, attitudes and opinions by means of surveys and interviews. However, behavioural science increasingly indicates that people unknowingly construct much of what they say on the spot and, as a result, are significantly influenced by contextual factors.  

88. Hence, considering belief-formation is crucial both for thinking about why people act as they do as well as how we can find out. Stage 3 will explore tools and solutions that support judgment, make inference intuitive and guide searches.  


Domain 3: Choices - making the best of opportunities 
89. The third aspect to consider when analysing a behavioural problem is how preferences are constructed or influenced when making choices. Rationality assumes people make choices based on preferences   or preferences inferred from choices   by assuming people to adhere to a handful of axioms prescribing how to make the best of opportunities in a rational way. Simplified, they do so maximising the expected utility of the outcome of the choice. Thus, if rationality requires us to be Spiderman when it comes to attention and to think like Einstein when it comes to forming our beliefs, the role model of choice is that of Garri Kasparov, the famous Russian chess Grandmaster, or other geniuses portrayed as performing complex calculations before making their next move. 

90. During the last 50 years, behavioural science has repeated shown that human decision making is far away from this rational model. In fact, like belief-formation, choice behaviour is often constructed on the spot, or potentially influenced by a long list of cognitive biases. For instance, materially incentivising choices may crowd out intrinsic motivation; the mere arrangement, formulation and  framing  of choice options may significantly influence choice behaviour; and social aspects, such as social cues, comparisons and meanings, may potentially attract or detract people to particular options, regardless of outcome.  

91. As a consequence, there are a long list of ways in which choices can be unduly influenced by psychological factors, which are not captured by the traditional economic analysis usually underpinning traditional public policy. These include:  

. Doubt, disappointment and regret: Complexity or confusing sets of options may lead people to express doubt ex ante and disappointment or regret ex post choices. As a consequence, people will levy more unwarranted consumer complaints and bad online user reviews, or spend excessive time making decisions (choice overload) and avoid talking about past choices.  

. Sticky status quo: If people own, create, or otherwise invest time, energy or resources in a project, they may excessively stick to the status quo. Decision makers then end up pouring more resources into an investment already lost (the sunk cost fallacy) or reject reasonable offers for things they own (the endowment effect) or have put effort into creating them (the IKEA effect). 

. Sensitivity to framing and arrangements: people s choices are affected by weak preferences or situations of risk or uncertainty. As a result, people make different choices when losses loom larger than gains (loss aversion); avoid risks when outcomes are framed as gains, but become attracted to risks when outcomes are framed as losses (risk aversion for gains and risk attraction for losses); are attracted to goods arranged as lotteries (overvaluation of small probabilities); prefer options that are presented first in a series (the order effect); resort to choosing the middle 


option in a series (compromise effect), but extreme options for more complex choices (extremeness effect) or options arranged as weakly dominant options (the asymmetric dominance effect); and many more. 

. Social motives, meanings and norms: Choices are influenced by social motives, meanings and norms. Here, extrinsic motives (i.e. monetary or punishment) undermine intrinsic motivation (i.e. good will) and lead to the opposite action (crowding out of motives); people may choose a non-preferred choice if it takes on a social meaning (social meaning; reaction) or imitate celebrities (social imitation, status cascades); or are influenced by social norms, such as failing to whistle-blow to avoid being a  snitch  (conformity), choosing the default setting because it is perceived as the socially accepted choice (following the herd), or giving money to strangers (reciprocity; fairness). 

92. Stage 3 will discuss tools and solutions for making desirable choices attractive, framing prospects and tapping into motives to solve biases associated with choice.  


Domain 4: Determination   sticking to choices over time 
93. The fourth aspect of behavioural problems that practitioners may explore is the role played by Determination, i.e. behaviours requiring people to stick to their choices over time but challenged by issues of what is referred to as will power, self-regulation, or self-control. Like attention, determination has not been a core theme in studies of rationality, aside from the simple assumption that when people make long-term goals, they should stick to the plan. When people fail to do this, it is often interpreted as  akrasia  or weakness of will. If rationality portrays people as Spiderman when it comes to attention, Einstein when it comes to belief-formation and Kasparov when it comes to choices, it sees people as cast in the mould of Gandhi when it comes to determination.  

94. Behavioural science has shown this assumption to be illusory and ideal. Studies have shown than fundamental attribution error makes us liable to interpret other people s behaviour in the realm of determination as a result of dispositional factors, rather than situational factors, even though situational factors are often a more likely cause. More precisely, determination is significantly influenced by at least three dimensions: mental taxation affects everyone from those under cognitive pressure to those continually in poor or impoverished living conditions (Mullainathan and Shafir, 2013[17]), learned strategies or competencies (Mischel, 2014[18]) for dealing with temptations, and situational factors, i.e. the choice architecture (Thaler and Sunstein, 2008[8]). As a result, people often do one thing with the genuine feeling that they should be doing something else. The danger then is assuming failures in determination are associated with a personality issue, rather than socio-economic variables that one has little control over.  

95. As such, it is important for practitioners to focus on diagnostic indicators related to:   

. Cognitive dissonance: When people face challenges to their long term goals, they experience mental discomfort or psychological stress. This can trigger increased pulse-rates, anger, and physical sway. Cognitively, people search for ways to reconcile immediate gratification with their long-term goals (motivated reasoning) or may exaggerate the desirability of the long-term goal (effort justification). 

. Mental taxation or exhaustion: Causes people s minds to be less efficient (tunnelling) due to the consumption of  mental bandwidth  (Mullainathan and Shafir, 2013[17]) that would otherwise go to less pressing concerns, planning ahead 


and problem-solving. This may result in cognitive deficits, self-defeating actions and an increased tendency to be distracted by inner and outer interruptions. 

. Inertia and procrastination: The complete (inertia) or temporal (procrastination) avoidance of doing a task that needs to be accomplished through a series of characteristic psychological strategies (coping behaviours). People may use avoidance, denial, distractions, or blame situational factors as reasons preventing their goal achievement.  

. Excessive self-directed blame: When challenges leads to failure, the person may blame themselves and experience regret.  Job-seekers then fail to apply successfully for jobs or people failing a diet or quit smoking due to their self-perception, lower self-esteem, guilt and self-disgust. In extreme cases, this may also lead to clinical depressions and loss of external control. 

96. Know this, practitioners can work with friction, create commitments, and provide plans and feedback to increase determination. Stage 3 will discuss these tools and solutions in more detail. 


Ethical guidelines for understanding why people act as they do (ANALYSIS) 
97. Seeking to understand why people act as they do in a BI perspective may involve a wide range of methods drawn from disciplines as diverse as anthropology, neuroscience and cross-institutional register-based data-analysis. These methods share the following common characteristics: they usually observe or study human behaviour close up and usually take place in their natural habitats, running the risk of affecting participants  personal lives and colliding with people s privacy rights.  

98. It is important to emphasise that the ethical guidelines presented as part of BEHAVIOUR should also be observed when working with analysis, in particular the guideline stating that  all team-members observe existing ethical guidelines and codes-of-conduct of the particular fields that the project involves as well as receives the necessary training to comply with these.  Besides these earlier guidelines, the following 10 guidelines attempt to capture some of the most basic ethical considerations special to BI, when studying behaviour up close as part of ANALYSIS. 


Table 5. Ethical guidelines for Stage 2: ANALYSIS 
1. Always seek ethical approval. For any non-casual study of behaviour the team should always seek approval from the ethical review board associated with the team as well as from the authorities or other organisations within which the behaviour studied unfolds. Also remember that ethical responsibility cannot be transferred. If the team commissions studies from other entities, it is the team s responsibility to ensure that the ethical guidelines for ANALYSIS are properly adhered to. 
 
2. Ensure competence. Always ensure that those conducting observations or any other kind of study or experiment as part of ANALYSIS have received appropriate training and are sufficiently competent to actually safeguard ethical guidelines and knowledge based supervision in practice. 
 
3. Collect and document consent. Remember that no research on a person may be carried out without the prior informed, free, express, specific and documented consent of that person or their guardians. This also includes, in so far as possible, the purpose of the study (see also point 6). 
 
4. Voluntary and anonymous participation. Always ensure that people asked to participate understand that participation is voluntary and that the refusal to participate will not result in any consequences or any loss of benefits that the person is otherwise entitled to receive. In addition, always make sure to anonymise participants to the furthest possible extend, short of consent, and make clear to participants that this is done. 
 
5. Additional safeguards for research with vulnerable populations. Special safeguards need to be in place for research with vulnerable populations. Vulnerable populations include schoolchildren under the age of 18, people with learning or communication difficulties, patients in hospital or people under the care of social services, people in custody or on probation, and people engaged in illegal activities, such as drug abuse. 
 
6. Always refrain from deception if possible. The behavioural sciences have a troubled relationship with deception. The experience of deception in behavioural research may have the potential to cause distress and harm, and can make the recipients cynical about the activities and attitudes of research and the institutions carrying out or sponsoring research. Always refrain from deception if possible, and only make use of deception if absolutely possible, approved by the ethical board as well as participating organisations, and after consulting appropriate resources such as the British Psychological Society s Code of Human Research Ethics (BPS 2018), or the like. 
 
7. Only collect was is necessary and ensure secure handling of data. Studying behaviour up close makes for collecting a wide range of data. Make sure that observational and other data generated as part of ANALYSIS are stored and handled safely as well as that only data that is necessary to collect for the purpose at hand is collected. 
 
8. Always provide contact information. Always provide the name and contact details of the team member leading the study as well as the name and contact details of another person who can receive enquiries about any matters, which cannot be satisfactorily resolved with the member leading the study. 
 
9. Always provide debriefing. After studying behaviour up close as part of ANALYSIS, always make sure that participants are debriefed when the data gathering is completed, especially where any deception or withholding of information has taken place. 
 
10. Always qualify the ANALYSIS. Make sure to collect relevant comments from participant on the results of ANALYSIS whenever possible. Also arrange for an active dialogue and equal representation from relevant citizens, groups and stakeholders when interpreting and reporting results. 
 


Source: Hansen (2018) for the OECD 
Stage 3: STRATEGIES   Effective strategies for behaviour change 
Roadmap 
Stages 1 and 2 focused on creating a BEHAVIOURAL ANALYSIS of the policy problem. Stage 3: STRATEGIES builds on these by providing the practitioners with ways to identify, conceptualise and design behaviourally informed strategies using the ABCD Framework. This section will: 
1. Discuss strategies for applying BI in public policy 

2. Show how to use the ABCD Framework to systematically match behavioural analyses with behavioural strategies 

3. Pose ethical guidelines for consideration in Stage 3: STRATEGIES 


The result is a set of tools and strategies that can be tested in Stage 4: INTERVENTION. 
 


99. This section accomplishes two key important tasks for implementing a behavioural insights project. First, as mentioned in the Introduction, the use of behavioural insights as active components, i.e. nudges, in public policy strategies should be regarded as a core tenet of what is usually referred to as behaviourally-informed public policy. Yet while BI does have a strong focus on the application of behavioural insights as part of nudge strategies (OECD, 2017[1]), it is important to emphasise that BI is not limited to this type of strategy. The development, design and delivery of behaviourally-informed public policy also comprises strategies such as  push ,  curling  and  boost  as well.  

100. Second, strategies and insights are presented for each of the four domains explained in Stage 2: ANALYSIS, including cases to illustrate their uses. Twelve strategies with their respective insights are presented. In this way, the ABCD framework also presents itself as a repository for systematically matching behavioural analyses with behavioural strategies that present themselves as the basis for designing policies likely to effectively and gently influence target behaviours.  


Methods for applying BI in Public Policy 
101. As we move from the more theoretical behavioural analysis to the more practical strategy and intervention testing phases of the behavioural project, it is useful to take a step back and discuss the ways in which behavioural insights can be applied. The most famous is through nudging, popularised by Thaler and Sunstein (2008[8]), and is often seen as the primary application of behavioural insights. However, it is just one of a universe of applications that can be generalised to include: push, boost and curl. These will be discussed below in comparison with traditional public policy.  

102. Traditional public policy analyses target behaviour as the outcome of rational deliberation and decision-making by agents with unbounded attention and willpower. It conceptualises behavioural problems as the result of lack of information, absence of attitudes or lack of sufficient incentives and motivation. At a result, it pursues behaviour change by providing rational reasons for action, such as information (informational campaigns), presenting and arguing the case (persuasion campaigns), providing incentives 


(reliefs, rebates, taxation, fees and fines), and legal regulation (formalised prescriptions and prohibitions sanctioned by law).  

103. Nudging analyses target behaviours as outcomes of limited capabilities for people to exert rational agency. Behavioural problems are seen as the result of cognitive biases and heuristics impeding rational ABCD, thus preventing people from achieving subjectively preferred outcomes. Nudging aims to influence behaviours by intentionally applying behavioural insights, not only in the analysis of behaviours, but also as strategic means to achieve behaviour change. It does this by integrating particular  nudges  into aspects of the choice architectures within which people reason and make their decisions. 

104. Pushing understands target behaviours as either outcomes of rational agency or results of laziness. Behavioural problems are thus seen as the result of cognitive misers and biases due to agents allocating insufficient priority to attention, information search, deliberation, and following through on their intentions. While push politics does recognise a behavioural component in the analysis of behaviour, it pursues behaviour change by emphasizing and strengthening aspects of choice architectures that provides rational reasons for action beyond what ought to be required from a purely traditional approach. The aim is to trump cognitive bias, by having people make meta-decisions about prioritising targeted behaviours so that the problems are resolved through reflective thinking. 

105. Boosting analyses target behaviour as either an outcome of reflective thinking or a result of lack of competences. Behavioural problems are analysed as the result of cognitive bias influencing people when they lack the information, skills and competencies to navigate a complex world. The  boost  aims to make it easier for people to exercise their own agency in making choices by  boosting  individuals  own decision-making competences. It range from strategies that require little time and effort on the individual's part to strategies that require substantial amounts of training, effort and motivation. 

106. Curling analyses target behaviours in light of people s limited motivation and lack of self-control. Behavioural problems are seen as the result of  friction  where people have difficulties following through on their intentions in demanding processes and choice architectures (e.g. as administrative frameworks), or hostile choice environments (e.g. supermarkets). Curling is a paradigm of protection that attempts to weaken, remove and/or counter the psychological mechanisms identified by BI by trying to remove friction in choice architectures or counter illicit  nudges  by e.g. banning certain choice architectural features   e.g. EU s ban of pre-ticked boxes on shopping websites to aid consumers (EC, 2011) or imposing mandatory cool down periods on payday loans. 

107. A savvy behavioural practitioner will keep all strategies for using behavioural insights in mind as they move into the practical stages of BASIC. This includes knowing when a policy problem is not behavioural at all, thus choosing traditional public policy tools to address the problem.  


Using the ABCD Framework to match analyses with strategies 
108. With your behavioural analysis and strategies for behavioural interventions in mind, work through the strategies and insights of the ABCD model to prepare for Stage 4: INTERVENTION. 


1. Attention   Make it relevant, seize attention & plan for inattention 
109. Attention is the window of the mind. However, attention is scarce, easily distracted, quickly overwhelmed and subject to switching costs. Practitioners will often find that attentional issues have been overlooked in the design and implementation of traditional public policies. For this reason, when practitioners find a behavioural problem with attentional issues, it may prove more effective to design policy interventions that are more relevant, seize attention and, if this is not possible, think about how to plan for inattention. 


Make it relevant 
110. A prerequisite for working effectively with attention to create a behavioural effect is that one engages with people in a relevant way   that is, at the right time, at the right place and at the point where people are most willing to enact the behaviour that one aims to promote. This can be done by carefully considering the following insights:  

. State of mind: Ability and motivation is not a constant. If you are hungry, you more likely to eat bad food and make bad decisions. If you are tired, you are more likely to make mistakes, make worse decisions, and eat bad food. Thinking about, and even influencing, people s state of mind and calibrating policy-interventions with this in mind can increase the likelihood that people will behave in accordance with what the policy is trying to promote. However, before even thinking about applying this principle, please consult the ethical guidelines at the end of this chapter, as people s state-of-mind is exclusively their private arena.  

. Timing: It is everything. People feel more positive in the morning than in the afternoon (Pink, 2018[19]). Asking people to commit well in advance to something sensible (e.g. eating fruit rather than cake) make them more likely to commit, asking them the day before makes them less likely to commit (Read, Loewenstein and Kalyanaraman, 1999[20]). Asking people to take out insurance on water damage is more likely after flooding, than before.  

. Placement: Think about the right time, and the right place. Which places are teenagers more likely to buy condoms, at the cash register in the supermarket or from a vending machine outside? Examples like this emphasise the importance placement in policy - some places are public, others private; some places are close to the action to be promoted, others are far away.  

111. In sum  make it relevant  includes, at least, three variables   timing, placement and state-of-mind   which are relevant when designing and implementing policies. Getting  the principle of relevance  right is a precondition to making the best use of people s attention. For some examples, see Box 4.  


Box 4. Examples of state of mind, timing and placement 
1. State of mind 
. Researchers from Cornell University split 120 shoppers into three groups. The first group was given an apple before they arrived at the supermarket and the second group were given a cookie. The third group ate nothing at all before shopping. After analysing the content of their trollies, the researchers concluded that those who ate an apple bought 28% more fruit and vegetables than those given a cookie. The 


 


apple eaters also bought 25% more fruit and vegetables, than the group who ate nothing at all (Tal and Wansink, 2015[21]). 


2. Timing 
. When Kenyan farmers were offered the option of purchasing fertiliser to (a) immediately after harvest or (b) at a self-chosen time, chosen immediately before harvest, participants increased usage of fertilizer by (a) 14 percentage points (season 1) and 18 percentage points (season 2); and (b) 22 percentage points. This was compared with (c) making the same offer at the time of when it is time to apply fertilizer as a top-dressing to the next crop, which found no significant effect in usage and (d) a 50% subsidy at the same time as (c) which led to an increase in usage of 13 percentage point   i.e. a similar effect as that of (a) and (b) (Duflo, Kremer and Robinson, 2011[22]). 


3. Placement 
. Qatar has an estimated prevalence of type 2 diabetes in 13% of its adult population (17% in the Qatari population). Around one-third of the people with diabetes have not been diagnosed and are unaware of their disease. There are two main ways of diagnosing diabetes or pre-diabetes, of which capillary blood glucose (CBG) testing is cheaper and more effective. However, it also requires fasting for some time. Using timing plus placement, the Hamad Medical Corporation and the Action on Diabetes initiative set up 20 screening stations at the State Grand Mosque of Qatar during Ramadan 2014. A total of 2 177 individuals where screened in two days, of which 11.7% already knew they had diabetes while 5.3% were found to have undiagnosed diabetes, and 26.6% were identified as being pre-diabetic (OECD, 2017[1]).  


 


Seize attention 
 Well, you know, one of the things that makes nudges work is just getting peoples  attention   
(Richard Thaler on Tavis Smiley's PBS show, 2008).  
112. The fundamental problem of inattention is, not surprisingly, that people fail to attend to what is important in a given context. Whether because they forget or overlook, and whether this is due to relegating, multitasking or being distracted, focusing on one thing implies by definition that one is not paying attention to something else. Thus, practitioners should carefully consider how to design the details of policy-interventions so that people attend to what is important at that given moment for the intervention to succeed. There are at least three ways to do this using the following insights:  

. Salience: Drawing attention to a certain choice relative to surrounding objects, information, events or options. The aim of salience-based nudges are to guide what people are attending to   as well as not attending to   playing on non-rational psychological features of cognition. The key element of salience is getting people to notice at some decision point that they are being asked to make a choice. There are many ways to do this. Most famously is the engraving of silhouettes of flies into the urinals of Schiphol Airport in Amsterdam (NLD), which purportedly reduced spillage by 80% and cleaning costs by 8% (Evans-Pritchard, 2013[23]).  


. Reminders: This is very similar to salience by making the person notice that they are being asked to take a decision. It distinguishes itself by means of an explicit messenger and triggering an association in memory, making it a bit more complex. It bears similarities to the possibilities for designing reminders (see e.g. Messenger effect and Create commitments) as well as brings up ethical considerations (see Ethical guidelines, at the end of this chapter). Reminders are becoming increasingly relevant due to increased digitisation and especially in Health. 

. Prompts: You can seize attention simply by asking people to pay attention through prompts. This is defined as making someone do something by interrupting their on-going action and forcing them to make a decision before being able to proceed, such as pop-up boxes on digital interfaces. Of course, this is an increasingly relevant principle with increased digitisation. It goes beyond digital platforms, for instance charities using  facers  on the streets asking for donations or hospitals asking patients to fill out a survey while waiting for an appointment. Text messages can serve as both prompts and reminders. However, they only work when they are relevant (see above). Otherwise, people will disregard and reject prompts   making prompts intuitively easy to dislike.  

113. In sum, after making sure to satisfy the principle of relevance, practitioners should consider how to seize the attention of people as a fundamental component of any policy intervention. See Box 5 for examples. However, even the best of people may fail to attend to what is important and that is why researchers and practitioners also need consider how to plan for inattention.  


Box 5. Examples of how to seize attention 
1. Make it salient 
. Making litterbins in Copenhagen salient by using stickers of green footprints was followed by a 46% decrease in street litter (Jespersen, 2011[24]). 


2. Use reminders 
. A meta-review of reminders in health found seven studies of reminders by letters that led to an average reduction in  did not attends  (DNAs) of 7.6%, while 12 studies of reminders by SMS led to an average reduction in DNAs of 8.6% (Stubbs et al., 2012[25]). 

. In Kenya, weekly text messages were sent to remind patients to take their HIV drugs, which led to an improvement in rate of drug adherence from a baseline of 40% to 53% (The World Bank, 2015[5]).  


3. Use prompts 
. The Danish Business Authority used a prompt to try to get 14 000 companies to verify their basic data in the Danish Business Register, with the result that approx. 66% either confirmed or updated their data in the registry (OECD, 2017[1]).  


 


 
 
Box 6. Case study: Making the best use of people s attention - Hand hygiene at a Danish hospital 
Hospital-acquired-infections (HAI s) are a costly affair to patients and society as a whole. Acquiring a hospital infection creates additional suffering for the patient and it may at worst lead to death. Prolonged hospitalisation due to HAI s also represents a massive financial burden to health care systems around the world. Improving hand hygiene behaviour in hospitals is among the most promising ways of preventing such HAI s.  
A field experiment tested two simple nudges aimed at improving hand hygiene amongst hospital visitors: (1) placement of hand sanitizer and (2) placement of hand sanitizer as well as a red sign with normative message. Placement of the hand santiser alone led to a 17 percentage point increase of usage and adding the red sign with a normative message led to more than tripling that effect. 
 
 

Source: (iNudgeyou, 2015[26]) 
 


 
Plan for inattention 
114. If facing an attentional problem, it may also prove effective just to plan for inattention. That is, it may often prove more effective to rely upon people not attending to the issue at hand   either because attention will always fail at some point or because it makes no sense that people need to devote their attention to the issue. Hence examining what happens when attention fails as part of the analysis and then planning and designing for inattention is a central strategy in BI for dealing with attentional problems.  

115. They key way for planning for inattention is through defaults. These are one of the most well-known nudges, which relies on pre-setting the choice. Since people live complex lives, they tend to not devote time or capacity to attend to the vast array of choices and just rely on defaults is a necessary strategy for us to focus on what is really important in our lives. In the most basic form, people may end up choosing the default option simply because they do not notice at the decision point that they are being asked to make a choice (Johnson et al 2002). We refer to this as  inattention-based default effect .  


116. Given this tendency, the consequences of misaligned defaults on individual and societal preferences can be large. As a policymaker, arranging the defaults right and   importantly   preventing misuse of defaults is a core principle of BI. Two examples can be found in Box 7. 


Box 7. Two cases of planning for inattention with default 
1. The European Commission effort to counter the misuse of defaults  
In 2009 and 2011, the European Commission launched a series of steps to protect consumers against an emerging speculation in default effects by, especially, online businesses.  
In 2009, Microsoft was charged with abusing its prolonged market dominance on the market for PCs to tie its online browser  Internet Explorer  as a default browser. As a consequence Microsoft had gained close to a monopoly on the market for browsers (more 90% of PCs on the market had Internet Explorer installed). In 2009, the EC forced Microsoft to install a program that prompted users to make an active choice between the 12 most popular browsers on the market (European Commission, 2009[27]).  
The new program was highly successful. Between March 2010 and November 2010 the new program led to 84 million browsers being downloaded. After that, Microsoft failed to comply with its commitment by not providing the browser choice screen with its Windows 7 Service Pack 1, from February 2011 until July 2012. This led to a historic  561 million fine of Microsoft by the European Commission (2013[28]).  
In 2011, the EC began an effort to protect consumers against the widespread speculation in attention-based default effects carried out by the emerging online industry. Their first target was the widespread misuse of pre-ticked boxes on websites for charging inattentive consumers additional payments (for example when buying plane tickets online). The EC thus decided to ban the use of pre-ticked boxes as part of marketing beginning 2014 (European Commission, 2014[29]). 
2. Rutgers University s paper-saving changes to printer defaults 
A typical illustration of an attention-based default effect for a simple, non-dynamic, decision task with only two alternatives is people s tendency to stick with printers  default setting. They do this even when they have prior information about what the default is, as well as hold preferences aligned with the often recommended course of action, i.e. double-sided printing. Thus, this effect creates a generic behavioural problem causing a vast overconsumption of printing paper.  
To solve this problem, traditional public policymakers have at times resorted to suggesting an environmental tax on paper products. In 2012, for instance, the Swedish Nature Conservation Association (Naturskyddsf rening) suggested a 10% tax on all paper products in Sweden. The projected effect of such a tax was a 2% reduction in paper consumption equalling 12 km2 saved forests and SKK 2 billion in taxes a year (Axelsson and  str m, 2012[30]).  
However, an intervention at Rutgers University (USA) in 2008 illustrates the simple and cheap alternative provided by BI: changing the default from single- to double-sided printing. Doing so on its three university campuses reduced paper consumption by 44%. Over the next three years, the university added further behavioural principles and estimated that they saved approximately 55 million pieces of printing paper equalling saving 4 650 trees (Sunstein and Reisch, 2013[31]), (Cho, 2013[32]).  
 


Conclusion: How to address (in)attention 
117. How to work with the attentional aspects of behavioural problems is rarely at the centre of the development, design and delivery of public policies. Yet, as was seen above with regards to hand hygiene and testing for diabetes, applying BI to the attentional aspect 


of public policy can make the difference between failure and success. However, considering the attentional aspect of behaviour can also inform the very concept of the policy intervention pursued. This was exemplified by the timing of an intervention for offering fertilizers to farmers in Kenya   there, the timing together with commitment to the offer proved just as efficient as a 50% subsidy.  

118. Consequently, considering the attentional aspect of behaviour is not just something to think about at the very end of the policy cycle, but should be done from the outset when attention is part of the problem as well as the solution. Thinking about how to make public policy interventions relevant, seize the attention of those engaging in the target behaviour and making plans for how to deal with inattention is a cornerstone in applying BI to public policy. 


2. Belief formation   Guide search, make inferences intuitive & support judgment 
119. Analysing problems in belief formation and devising strategies relative to this aspect of behaviour comprises a second cornerstone of the BASIC approach to applying BI to public policy. The following examples illustrate how researchers and practitioners may use tools such as guiding search, making inference intuitive and supporting judgment to resolving issues in behaviour formation.  


Guiding search 
120. While there is no such thing as too much information in a traditional public policy perspective, information overload has become a serious problem for the people inhabiting the real world. For that reason, problems in belief-formation usually go hand in hand with the vast amounts of information and possibilities that are put on offer.  

121. In this perspective, it is not surprising to find that some of the biggest companies today are companies build around information search engines and consumer comparison platforms. What is perhaps more surprising is that traditional public policy interventions with regards to problems of belief-formation have been slow in copying what these companies do, but instead often try to approach problems in belief-formation by offering even more information. Policymakers can help guide citizens more effectively when facing vast information sets by using the following insights:  

. Searching by aspects (SBA): Originally described by Amos Tversky (1972[33]), as EBA   elimination by aspects), this model applies when people face too many options to choose from. People then start making decisions by first identifying a single attribute or feature deemed most important, then use this to partition the set of options. Then they apply the second most important aspect until the options become either manageable or only one remains. Digitalisation has made SBA a primary function of search engines. This is a proven and powerful tool that can be used by policymakers to guide citizens through complex sets of information, such as searching for job openings to searching for public services like medical clinics, dentists, etc. In particular, it should be noted that SBA allows for construing sequences of aspects and the  anchors  they induce so as to favour certain searches over others. 

. Question/Decision trees: These are tools that use a branching structure to model sequences of decisions onto their possible consequences so as to allow for analysis. This technique has been implemented extensively in call-centres, and one of its first 


technological implementation was as part of automated telephone-systems ( press 1 for English ). It has also been applied to help guide citizens by their own devices to the kind of information or options needed when interacting with public bodies. 


Box 8. Examples of guiding search 
1. Searching by aspect (SBA) 
. The Danish Agency for Labour Market and Recruitment has worked with sequencing features (e.g. max. distance to job vs. salary level) as well as  presentation (suggesting higher anchors in max. distance to job) to influence job search with the aim of having job-seekers widen the set of jobs they consider at their initial stage of unemployment. (Information provided by the Danish Agency for Labour Market and Recruitment) 


2. Question trees 
. In 2013, the Danish Business Authorities together with iNudgeyou tested the efficiency of a question-tree procedure in getting newly started business-owners to correctly identify the type of company (amongst 148 types) they needed to register to conform to existing rules and regulations. In a small, randomized controlled trial it was found that a question tree reduced the number of business registrations with errors in them by 43% (from 35% to 20%) (The Danish Business Authority and Copenhagen Economics, 2013[34]).  

. The UK government has implemented digital question trees as a tool on a range of sites.  For example, if one wants to check if they have the right to work in the UK, they can access the site https://www.gov.uk/legal-right-work-uk, and press start. After answering a short series of easy questions one is told whether one is entitled to work in the UK, what documents to bring/obtain and/or which authorities to contact. The 1 minute experience of going through the questions makes one baffle at the ease with which one is led through an incredibly complex set of laws and requirements to arrive at the exact information needed. (UK Government,(n.d.)[35]) 


 


Make it intuitive 
122. One thing is being guided to an answer by behavioural insights when navigating vast and complex amounts of information that the modern world presents citizens with, like those involved in registering a business or finding out what documents are needed to obtain a work permit. Another thing is to navigate those complex systems and technologies themselves that a modern world makes available. After all, humans co-evolved for millennia with nature, but the pace at which technological developments occur is too fast for human evolution to keep up with. Still, this leaves humans to struggle with understanding and remembering how the systems, environments and objects that surrounds them at work, in the interaction with public bodies and in the marketplace functions.  

123. To this end, the traditional approach has relied heavily on information, instructions and training. In contrast, BI has from the outset explored areas such as Human Factors (Wickens, Gordon and Liu, 1998[36])and User-centric design (Norman, 1988[37]), though with a stronger emphasis on the psychology and experimental tests than these disciplines usually exercise, in the search for principles to apply in the pursuit of providing better and more effective regulation. Perhaps this area, more than any other area, BI becomes an 


applied approach in the literal sense. To do this, the practitioner may want to use the following insights:  

. Intuitive coding: A broad concept referring to the idea of construing information, environments and objects so that people intuitively form appropriate beliefs using system 1 thinking. For example, a light switch may be designed in a way so that users intuitively form the correct idea of how to use it by, for example, flipping it up and down or turning a knob left or right. The idea of intuitive coding may be crucial for the construal of  user interfaces  in public policy.  

. Mental models: Psychological representations of real, hypothetical, or imaginary situations that help people make sense of the world. In doing so, they cause people to ignore certain pieces of information and fill in missing information where needed by automatically triggering contextual cues. Public policy itself depends upon mental models, such as the debate presented in this toolkit between traditional public policy based on notions of rationality and policy built on behavioural insights that exposes policymakers to alternative ways of thinking. BI can be used to change systems by adjusting information architecture and layout on public websites to the mental models that more accurate represent the way citizens think and interact to improve functionality and experience.  


Box 9. Examples of making it intuitive 
1. Intuitive coding 
. Lake Shore Drive in Chicago has one of the city s most dangerous curves. Trying to limit accidents, in September 2006 the city painted a series of white lines perpendicular to traveling cars such that the lines get progressively narrower as drivers approach the sharpest point of the curve (see Figure 11). This creates the illusion of speeding up, which   by hypothesis   should make drivers lift the foot from the speeder to compensate for possible illusions of control and overconfidence. The result: there were 36 percent fewer crashes in the six months after the lines were painted compared to the same six-month period the year before (September 2006   March 2007 and September 2005   March 2006). (Nudge blog, 2010[38]) 


 


Figure 11. Aerial photo of Lake Shore Drive in Chicago 
 

Source: (Nudge blog, 2010[38]).  
. In the UK, researchers noted a common problem with doctor s handwriting leading to misinterpretation of prescription forms leading to prescription errors. Incorporating BI into the user-centred design of an inpatient prescription chart, researchers added a line for doctors to circle  microgram ,  mg ,  g  or units (see Figure 12). In a simulated context, the chart significantly reduced a number of common prescribing errors including dosing errors and illegibility without education or support, suggesting some common prescription writing errors are potentially rectifiable simply through changes in the content and design of prescription charts (King et al., 2014[39]). 


Figure 12. Intuitively-coded prescription forms 
 

Source: (King et al., 2014[39]) 
2. Mental models 
. The World Bank Report 2015 describes how certain groups of disadvantaged people in Ethiopia have been observed to hold beliefs that they could not change their future, thereby constraining their abilities to see the opportunities they might have. Researchers invited a randomly selected group of villagers to watch inspirational documentaries in which individuals from the region described how they had improved their socioeconomic positions by setting goals. A survey conducted six month later found that viewing the documentaries had increased aspirations and brought about small changes in participants behaviour such as 


 


increased savings and investing more resources in their children s schooling (Tanguy et al., 2014[40]); (The World Bank, 2015[5]) 


 


Supporting judgment 
124. People still need to make judgments. That is, they need to infer new beliefs from pre-existing beliefs. In doing this, people rely on an array of simplifying heuristics that allow them to draw inferences that often, but not always serve as reliable and cost-effective shortcuts for processing information. Tversky and Kahneman (1974[41]) famously identified three heuristics   availability, representativeness, and anchoring and adjustment   influencing human judgment.As the list of such heuristics is becoming increasingly long and varied due to the rapid progress of the behavioural sciences the following exposition is limited to illustrating three out of several possible principles for applying BI to support people in making judgments. This section will explore three ways to support judgement by using the following insights: 

. Utilising heuristics: Practitioners can tap into heuristics so as to promote a particular belief being formed. Needless to say, one should think twice about using this principle on ethical grounds. Yet, considering what heuristics will play a part in forming beliefs in a specific context and designing policy interventions to match, rather than conflict with these is usually only appropriate.  

. Adapting to heuristics: Making sure that information is presented in forms such as natural frequencies that fit cognitive strategies or heuristics, so as to make use of their efficiency in solving problems.  

. Social proof: People look to the behaviour of others in an attempt to make sense of the world. It is triggered by uncertainty about the state-of-the-world in social contexts and driven by the belief that other people possess knowledge about what is going on and how aspects of their surroundings work. By highlighting or emphasising a positive behavioural norm, practitioners may support judgment by  de-biasing  the existing misperception or, potentially, encouraging the misperception that the positive behaviour is more prevalent than it actually is, which may result in people adopting the positive behaviour. This is in contrast to traditional public policy, which tends to emphasise negative or problematic behaviour, which often leads to people making exaggerations about negative or problematic behaviours that could easily lead to a misperception of how widespread the problem is (Berkowitz and Perkins, 1987[42]).  


Box 10. Examples of supporting judgment 
1. Utilising heuristics 
. The messenger effect is a robust effect where people judge the truth or likelihood of a message according to the perceived credibility of the messenger. The UK launched the  Healthy Buddy  scheme, whereby older students received healthy living lessons from their schoolteachers and then acted as peer teachers to deliver these lessons to younger  buddies . Compared with a control group, both the older and younger  buddies  enrolled in the  Healthy Buddy  scheme showed an 


 


increase in healthy living knowledge as well as in their behaviour and weight (The Behavioural Insights Team, 2010[2]). 


2. Adapting to heuristics 
. In a  Boost  experiment, Gigerenzer (1991[43]) taught some 1 000 doctors and 50 US federal judges risk literacy.  

. Drexler et al. (2014[44]) have shown how using some hours of instruction and practice training financial decision making skills by teaching micro-entrepreneurs in the Dominican Republic simple financial and accounting heuristics may produce significant and economically meaningful improvements in business practices and outcomes.  

. Switching from showing fuel efficiency in the context of purchasing a new car in terms of Miles per Gallon to showing Gallon per Miles made the benefits of greater fuel efficiency more transparent (Larrick and Soll, 2008[45]). 


3. Social proof 
. Emphasising the actual behaviour in relation to alcohol consumption amongst youths reduced the misperceptions and actual consumption of alcohol amongst youth (Balgvig and Holmberg, 2014[46]). 

. Emphasising the actual use of seatbelts amongst drivers has been shown not only to  de-bias  the misperception amongst drivers about other people s behaviour, but also show to lead more drivers to perceive the behaviour as positive (Linkenbach and Perkins, 2003[47]).  


 


3. Choice   Make it attractive, frame prospects & make it social 
125. When making a choice is difficult, people are likely to be influenced by biases and heuristics in their decision-making. ABCD suggests that researchers look into making preferable choices more attractive, use framing of prospects and leverage social identities and norms. 


Make it attractive 
126. The fundamental law of choice is that of attraction. In facing a set of choice options people opt for what they find most attractive. But what makes a choice attractive and how may researchers and practitioners use behavioural insights into this area to encourage people to make the best choices? This is an issue that may be treated at length, but here two simple principles are considered: how to connect with intrinsic motives and trigger emotions. This can be done by considering the following insights: 

. Consider intrinsic motivation: Every choice has a motive. This motive can be either intrinsically or extrinsically motivated. Intrinsic motivation to perform an activity comes when one receives no apparent reward except the activity itself; whereas, extrinsic motivation to perform an activity comes from external rewards, such as money, fame, commands, and promises of punishment. Motivational Crowding Theory suggests that providing extrinsic incentives for certain behaviours can undermine the intrinsic motivation for that behaviour. Considering how to connect with intrinsic motives, as well as determine how potential extrinsic incentives will interact with these motives is a crucial exercise for practitioners.  


. Make secondary motives salient: A crucial element for any practitioner wanting to influence choice, as secondary motives are often used as  tiebreakers  to final decisions. Making secondary motives  salient  may provide motive for choosing that option. For example, when buying two seemingly identical bottles of water, the primary motive of quenching thirst will be satisfied. The person may then choose the bottle from a company that gives to charity, servicing their secondary motivation.  

. Trigger emotions: The act of experiencing emotion (affect) is fundamental in influencing our choices. Marketing campaigns may trigger emotions to challenge deeply held beliefs through cognitive dissonance, but usually triggering emotions are more effectively used to attract or repel people from a given choice option. While considering and triggering emotions is a basic strategy in marketing, it is still a highly neglected strategy in public communication. 


 
Box 11. Examples of making it attractive 
1. Considering intrinsic motivation 
. The Texas Department of Transportation (USA) sought to reduce littering on Texas roadways. They launched the  Don t mess with Texas  campaign targeted at 18- to 35-year-old males who were known to be most likely to litter and connected to its slogan with the intrinsic motive of patriotism. The campaign has been credited with reducing litter on Texas highways 72% between 1986 and 1990 (Texas Department of Transportation,(n.d.)[48]); (Texas Times, 2016[49]). 

. Paying for behaviour which previously has been voluntary, such as blood donation, might reduce the willingness to enact that behaviour (Titmuss, 1970[50]).  

. Monetary compensation offered for a nuclear waste repository in Switzerland effected a drop in willingness to accept the locally undesired project from 50.8% to 24.6%. About one quarter of the respondents even seemed to reject the facility simply because of the financial compensation attached to it (Frey and Jegen, 2001[51]). 


2. Make secondary motives salient 
. A Norwegian study found that by making life-time costs of white appliances salient to costumers encouraged them to buy white appliances that where 4,9% more energy efficient (Kallbekken, S len and Hermansen, 2013[52]) 


3. Trigger emotions 
. Bertrand et al. (2010[53]) conducted a field-experiment in financial decision-making, which included experiments on an advertisement. In particular, the study found that a picture of an attractive, smiling female increased demand for the financial product by the same amount as a 25% decrease in the loan s interest rate (see (Bertrand et al., 2010[53]); (The Behavioural Insights Team, 2010[2]). 


 


Framing prospects 
127. The framing and arrangement of prospects is perhaps the most famous, but also most technical area of BI as applied to public policy. In facing a series of choice-options, a person also faces a series of possible futures, i.e. prospects. While making it attractive provides reasons for choosing, the framing of prospects influences people to choose one or another option in subtle ways independent of what is chosen and why. That is, one option may be chosen over another simply due to the way that choices are presented   either as a matter of arrangement or as a matter of formulation.  

128. In particular, the framing of prospects was the cornerstone in the research of Tversky and Kahneman, ultimately leading to the formulation of prospect theory (1979[54]). This model of choice shows how people decide between alternatives that involve risk and uncertainty (See Figure 13). First and foremost, the model asserts that people think in terms of expected utility relative to a reference point rather than absolute terms. Second, the model captures the insight that people are more motivated by the prospect of loss than the prospect of gains popularly expressed, as  losses loom larger than gains  (loss aversion). Finally, the model captures the insight obtained from experiments that people, due to declining marginal utility for gains as well as losses, are risk averse for prospects involving gains, while risk seeking when it comes to prospects involving the risk of losses. 


Figure 13. Prospect theory  
 

Source: (Kahneman and Tversky, 1979[54]) 
129. While prospect theory may initially seem very abstract to policymakers, practitioners may use the theory when deciding how to formulate simple prospects, such as those faced by citizens when making everyday decisions in their interaction with public bodies through the following insights: 

. Arranging choices: This principle simple finds that a person will likely choose a middle option in a set, rather than an extreme option (the compromise effect). This principle is well-known to marketers, who often add more expensive options to the suite of products available as a means to encourage you to buy a more expensive choice than you otherwise would have. For example, consider Figure 14   if just two coffee choices were presented, you will likely choose the smallest. But if three coffee choices are presented, you will likely choose the medium. This shows how the mere arrangement of options influences choice in irrational ways. This is worth considering when developing a policy intervention. 


Figure 14. Arranging choices   which do you prefer? 
                 

Source: Produced by the OECD with images obtained free of copyright from www.pixabay.com.  
. Framing choices: How options are formulated influences choice, independent of its semantic content. For example, you are presented a choice between two cancer treatments: The first gives an 80% chance of survival, the second a 20% chance of death. Semantically they are the same, but you are likely to choose the first treatment only because survival sounds better than death. This is a core tenant of prospect theory. The practitioner should carefully consider how choices are framed when developing public policies revolving around incentives, risk and uncertain 


  
Box 12. Examples of framing prospects 
1. Arranging choices 
. Hansen et al. (2016[55]) found that the trivial arrangement of a conference buffet with coffee, fruit and cake may decrease calorie consumption by 25% - much more than is likely to be achieved through taxation of sugar and fat. 

. Miller & Krosnick (1998[56]) found that the arrangement of choice options when casting a vote significantly influences choice   both with regards to candidates within parties and for parties themselves. This  Ballot order effect  has shown that candidates listed first on a ballot receive, on average, 2.5% more of the vote than those listed after. This has led states like Ohio (USA) to rotate the name order of the candidates on its ballots. 


2. Framing choices 
. In 2016, The Danish Taxation Authority, working with iNudgeyou, increased the percentage of companies filing taxes on time from 65% to 74% (compared to 2015) by adding a reminder line to the original email formulated in terms of loss aversion saying  Remember to report tax on time to avoid a tax surcharge of up to DKR 


 


5 000). This replaced the header reading  Remember to report tax before July 1st  (OECD, 2017[1]) 

. In 2017, Medway Council (GBR) worked with UKBIT on increasing the rate at which council taxpayers signed up for Direct Debit. Testing two new messages   one which drew on loss aversion, and one which drew on social norms   against a business-as-usual control of no message, they found that both new messages significantly increased sign-ups and that the loss aversion arm worked slightly better especially for houses in high tax bands (Sanders, Jackman and Sweeney, 2017[57]). 


 


Make it social 
130. Humans are, first and foremost, social beings. Yet, this is often ignored in public policy, where they are, first and foremost, treated as isolate citizens, consumers and individuals. Connecting with the social identities and norms informally coordinating and regulating human groups and societies is an invaluable strategy in the pursuit of creating a change in behaviour. In this regards, practitioners can make policy social by considering the following insights: 

. Connecting with social identities: Considering the social identity of people as well as the social meanings that choices are embedded within, researchers and practitioners may find ways of connecting the behaviour change sought by public policies to the deeper fabric of the societies they serve. A fundamental mechanism is comparison with its peers. This mechanism is what drives people s sense of status, recognition and identification with a group. Needless to say, practitioners should be extremely careful when using a social identity intervention. Misfires may cause a serious backlash trust in public officials and institutions, as well as damage the social fabric of the society.  

. Leverage social norms: Social norms are the mutual expectations that govern the behaviour of members of groups and societies, and provide strong constraints on what is acceptable behaviour. Some social norms serve a coordinating purpose, like which side of the road to dive on or what kind of economic exchanges are acceptable, while others serve to distribute goods amongst members of society dependent on effort and needs. Behaviours adhering to social norms can be puzzling: experiments show people forego immediate self-serving behaviour to respect fairness, or that norms persist even when someone in the group wishes they do not. Social norms may be incredibly difficult to change. However, in some situations, practitioners may turn to leveraging the power of social norms, especially when promoting pro-social behaviours.  


Box 13. Examples of making it social 
1. Connecting with social identities 
. Opower, a leading US provider of customer engagement and energy efficiency cloud services to utilities, provides households with  Home Energy Reports  that consists of two parts: one containing suggestions on how to reduce energy adapted to the household, and the other using social comparison that compares the household to the 100 nearest houses of similar size. In an analysis of 78 492 


 


households separated into treatment (39 217 households) and control (39 275 households), those receiving the social comparison reduced electricity consumption by 2.0%, on average. Opower estimates that this would result in a reduction of over 450 000 tonnes of CO2-emission equivalent to $75 million in energy savings across the 15 million homes in 6 countries they service (Allcott, 2011[58]). 

. In an experiment with people contributing voluntary work to running Wikipedia, contributors in the treatment group were awarded peer esteem in the form of a  Barnstar    an editing award that was publicly displayed   and their performance compared to that of a control group. When measuring the productivity level of contributors, those in the treatment group turned out to be 60% more productive over a course of the 90 days following the receipt of the award (The World Bank, 2015[5]). 


2. Social norms 
. Famously, the UKBIT working with HM Revenue and Customs (HMRC) changed the letter sent to people who did not pay their taxes with a line that said most people pay their tax on time, and those who had not belonged to the minority group that had failed to do so. This intervention significantly increased payment rates with a 5 percentage point increase in payments and led to  1.2m more being paid in the first month than the control (The Behavioural Insights Team, 2014[4]). 

. In Kenya, an intervention was aimed at passengers in minibuses to reduce traffic deaths. In the experiment, researchers used stickers in buses to remind passengers of their right to a safe ride on public transportation and encouraging them to  heckle and chide  reckless drivers. The intervention was a remarkable success. In the busses randomly assigned to the treatment group, insurance claims involving injury or death fell by half, from 10% to 5% of claims. This was reflected in a survey of drivers, suggesting that passenger heckling played a role in improving safety (Habyarimana and Jack, 2011[59]). 


 


4. Determination   Work with friction, plans and feedback & create commitments 
Work with friction 
 If you want to help people accomplish some goal, make it easy.  
- Richard Thaler 
131. Most people know that it is easy to form an intention of doing something. It is much harder to get it done. However, we do not always anticipate this and tend to systematically overestimate our own ability in taking the small steps to accomplish our goals. Thus, choosing to do something is not the same as succeeding. The world is complex and when any one person has to juggle multiple goals at once, even relatively small obstacles may become a reason for postponing taking action. As a result people tend to procrastinate leading to inertia and staying with the status quo.  

132. In such cases we usually put our faith in increasing the motivation   our own, our employees , or citizens  at large. However, one thing that the behavioural literature has made clear is how it is often far more effective and cheaper to reduce or, if possible, even 


remove those small obstacles referred to as  friction costs .  Make it easy  is thus a mantra, not only of Richard Thaler, but also of any researcher or practitioner working with BI. 

133. On a theoretical level the behavioural insight captured by the mantra  make it easy  may be illustrated below (Figure 15) by pitching motivation against the difficulty of performing and action (the green dot) relative to an action-threshold (curve A). When the action is outside of the threshold inertia and procrastination results. The effect of the standard approach of increasing motivation is captured by curve B. The effect of making an action easier to perform is captured by curve C.  


Figure 15. Making it easy 
 

Source: Hansen (2018) for the OECD  
134. From this, it is also obvious that while making something easy may be a way to get people to get things done, there is also a shadow function of  making it easy . As anyone who has been on a diet knows, making something just a bit more difficult may have a significant effect on inhibiting that action. Taken together, these two sides of the same behavioural insight makes for the strategy of working with friction, which may be categorised as an instance of the policy approach called  curling  above. This can be done by considering the following insights: 

. Changing the default: Changing the default is the most basic way of working with friction. If subscribing people automatically to a programme one removes all obstacles to signing up. Simultaneously, of course, one also makes it more difficult for people to get around to sign off. Some of the most famous examples from BI are about changing the default in the domain of determination.  

. Changing the hassle factor: Another principle is for making something easier or more difficult by reducing or increasing the hassle-factor of taking up a service or performing an action. For years, this has been a standard approach on digital platforms, where reducing the number of clicks it takes to take up a service has been crucial challenge in user experience design.  


 
Box 14. Examples of working with friction 
Changing the default 
. The perhaps most famous use of defaults is that of pension schemes. Automatically enrolling employees in such schemes have been found to be incredibly effective compared to when employees actively have to opt in. In October 2012, UK employers started automatically enrolling their workers into a pension. The scheme started with the largest UK employers (250 or more workers), intending to cover all employers by 2018. Initial results showed that the overall participation rate rose from 61% to 83% leading to 400 000 more people having a pension. (The Behavioural Insights Team, 2014[4]) 

. In Germany, two natural experiments examined how default settings may affect consumer choice in regards to energy consumption   an area in which consumer behaviour is notoriously immobile because of suppliers  use of subscriptions, the lack of urgency in revising subscriptions and the high effort it takes to get an overview of the market and change supplier. First, in Sch nau, Schwartzwald, approximately 2 500 citizens established the green electricity company Elektrizit tswerke Sch nau in the wake of Chernobyl. Being part of this company was the default for all citizens. Recent reports note that opt-outs are marginally above 0% per year. Second, in Southern Germany, Energiedienst GMbH in 1999 substituted the former one-option model with a default system in which Option 1 was a green option that cost 23% more than the original model; Option 2 was the default intermediate green option that was 8% cheaper than the original model; and Option 3 was the least green option that was an additional 8% cheaper than Option 2. As a result 94% of consumers choose the Option 2, that is the intermediate green default option, while only 4.3% choose the cheapest option, Option 3, and the remaining 2% either choose Option 1 or to change energy supplier. (Pichert and Katsikopoulos, 2008[60])   


Changing the hassle factor 
. The UKBIT has run several experiments showing the efficacy of this strategy. In one such experiment, the UK Revenue and Customs authority tax collection rates improved from 19% to 23% by directing letter recipients straight to a specific form they were required to complete, rather than to the web page that included the form. In another experiment, streamlining and automating parts of the process for under-represented low-income groups applying for financial assistance led to an eight percentage point increase in the university attendance of these groups. (The Behavioural Insights Team, 2014[4]) 

. UKBIT further found that deaths from paracetamol poisoning fell by 43% after new legislation required larger portions to be sold in blister packs. As a result 765 fewer people died between 1998 and 2009. (The Behavioural Insights Team, 2014[4]) 

. Conversely, when Denmark introduced an online  direct divorce  solution in 2013, it made getting a divorce within minutes easy and the number of divorces exploded. However, the number of people regretting their divorce shot up as well, as the number of cases were people asked for an annulment of their divorce increased to 


 


more than 1 out of 10. Laws were subsequently passed to make divorce a bit more difficult again. 


Sources: (Pichert and Katsikopoulos, 2008[60]); (Sunstein and Reisch, 2013[31]); (The Behavioural Insights Team, 2014[4]) 
 


 
Provide plans and feedback 
135. In other situations related to determination it is not possible or insufficient to make actions easier by changing the default or reducing/increasing the hassle-factor. In particular, some behaviour changes require that goal-directed behaviours are initiated as well as continuously maintained over time. Besides attentional problems, the mental taxation involved in doing this, plus the balancing of competing goals may easily lead to failure. One may thus intend to stick to a diet, a health plan or taking ones medications, but at some point the continuous inner battles that need to be won may make the temptation of skipping a day or two, too much.  

136. In such situations we often put our faith in our strength of will with only ourselves to blame in case of failure. However, the behavioural science literature suggests that continuously sticking to one s plan to reach long-term goals may be just as much a matter of technique and external feedback as a matter of inner resources. Teaching people with the foundations of these techniques ( boost ), such as the right kinds of plans, as well as arranging for suitable feedback is thus behavioural insights that offer themselves for constructing potential strategies for successful behaviour change. This can be done by considering the following insights: 

. Implementation intentions: A well-known way to succeed with a complex long-term goal is by breaking the complex goal down to simple actionable steps. Behavioural science has found that initiating and maintaining goal-directed behaviour can be approached by the making concrete and specific action-plans, stipulating not only the goal, but a context specific plan for accomplishing that goal of the form:  When C arises, I will perform response A . This type of conditional planning is referred to within the BI literature as implementation intention plans. This  if-then  structure has been shown to result in a higher tendency of succeeding with accomplishing ones goals by predetermining a specific and desired goal-directed behaviour in response to a particular cue or future event (Gollwitzer and Brandst tter, 1997[61]); (Gollwitzer, 1999[62]). Further, ensuing research in implementation has found that when implementations are devised in advance to combat the potential obstacles challenging the pursuit of a long-term goal, implementation intentions are even more effective in supporting behaviour change. Among the many reasons why this works so well is actions get automatically activated, helping one follow the plan. This can be used for a wide variety of public policy relevant interventions from providing people with plans for voting, sticking to one s diet or exercise program, to getting people to perform self-examinations for health purposes. 

. Providing feedback: Any mechanism that returns information about the effect of an activity or process can affect that activity or process in the future. Research has found that feedback improves both learning and motivation, with the caveat that feedback may also decrease motivation if one is doing poorly and has hardly any effects when an individual is already performing at a high level. There are different 


types of feedback, including natural feedback processes (e.g. homeostasis); task-generated feedback (e.g. gardener seeing that she has flooded her plants); feedback of progression (e.g. how long you have run on the treadmill); feedback on results (e.g. how fast you ran 5 kilometers); relative feedback (e.g. your place in a race); social comparison feedback (e.g. how much you earn compared to your colleagues); personal feedback (e.g. your wife telling you that you could do better in all aspects of life). If seeking to help people sticking to a long-term goal, providing them with the suitable kind of feedback in the right situation may help them stay on track. 


Box 15. Examples of providing plans and feedback 
Implementation intentions 
. In an experiment by Orbell, Hodgkins and Sheeran (1997[63]), participants was first asked to indicate how strongly they intended to perform breast-self-examination (BSE) during the next month. To create relevant implementation intentions, participants were then asked to write down where they would perform BSE in the next month and at what time of the day. Of the participants who had reported strong intentions to perform BSE during the next month, 100% did so when they had been induced to form additional implementation intentions. If no additional implementation intentions were formed, however, the strong goal intention alone only produced 53% of goal completion. 


Providing feedback 
. In 2017 The Australian Department of Health identified 6 649 General Practitioners (GPs) whose antibiotic prescribing rates were in the top 30 per cent for their geographic region. Four different letters were prepared to test different behavioural insights, while a control group of 1 338 did not receive a letter. The trial found the biggest impact was on the 1 333 GPs whose letter from the chief medical officer contained a comparison with their peers as shown in a graphic depicting their scripts as a stack of red and white capsules.  I know that antimicrobial resistance is a complex issue that requires concerted efforts across general practice, hospitals, laboratories and animal health professionals,  the chief medical officer wrote.  However, there is clear evidence that reducing unnecessary prescribing can lower the incidence of antimicrobial resistance. The benefits of tackling this problem are relevant to every one of our patients.  The GPs who received that letter reduced their prescribing rate by 12.3 % over the next six months. (Australian Government Department of Health, 2018[64]) 


 
 


 
Create commitments 
137. Sometimes, it takes more than working with friction or providing plans and feedback to help individuals achieve their long-term goals. The challenges and obstacles may just be too numerous or too hard to overcome. But even in such circumstances the behavioural science literature has a trick up its sleeve. One reason that people procrastinate is that in a long-term perspective, everything seems easier if postponed to the future. That 


is why people take up 12 months interests free loans   for surely, in a year, we will be better at handling our finances than now. It is also why you systematically tend to set your alarm clock to 6 am, only to press the snooze button. Behavioural scientists refer to this pattern in behaviour as  present bias . People like to enjoy themselves in the present, while  the future  invites for all the difficult stuff we know we ought to do. 

138. On a theoretical level the present bias refers to the tendency of people to give stronger weight to payoffs that are closer to the present time when considering trade-offs between two future moments (O'Donoghue and Rabin, 1999[65]). Researchers and practitioners may utilise this tendency by planning so that the tasks necessary for accomplishing a long-term goal are in the future when making a decision to pursue them, and then making the put in place a commitment device that a hard to ignore when facing temptations. This can be done by considering the following insights: 

. Personal commitments: making a commitment that is not public is closely connected with the behavioural insight of connecting with social identities (see above). In making a personal commitment, one introduces self-directed expectations and thereby constrains how one is allowed to think about oneself depending on failure or success in accomplishing the goal set. However, a personal commitment is not just about making a pledge to oneself. It is about taking up a commitment device to realign reasons and incentives such that sticking to one s plan becomes more attractive when challenged by temptations or when mentally taxed. 

. Public commitments: Public commitments are similarly connected with social identities. Yet, in making a public commitment, one creates both self-directed expectations as well as expectations in others about ones behaviour and thereby leverages social norms (see above). Taken together, these two aspects of public commitments intertwine so as to substitute for the material incentives introduced by personal commitments   and as the literature has it, are far more effective at achieving its purpose. 


Box 16. Examples of creating commitments 
Personal commitments 
. A particularly well-known form of personal commitment device is an Ulysses contract, where people pre-commit an amount of money that is returned to them only if they meet a prior agreed behavioural change goal. The idea is that Ulysses contracts helps tackle present bias and utilise loss aversion (Oliver, 2017[66]). 

. Volpp et al. (2008[67]) designed at study with three groups: Subjects in Group 1 were assigned a weight-monitoring programme; subjects in Group 2 were also assigned the weight loss programme, plus an Ulysses contract; and subjects in Group 3 were assigned the weight loss programme plus a lottery incentive. After 16 weeks the average weight losses were 3.9lbs, 14lbs and 13.1lbs, respectively. The proportions of those in each group achieving the weight loss target of 16lbs were 10.5%, 47.4% and 52.6%, respectively. Unfortunately, seven months after the initiation of the study the average losses across the three groups had narrowed to 4.4lbs, 6.2lbs and 9.2lbs respectively   a statistically insignificant difference due 


 


to small sample size. In general, there is mixed evidence of the efficacy of Ulysses contracts in public health. 


Public commitments 
. In its most rudimentary form a public commitment is nothing more than a pledge made publicly. The power was illustrated in a 1972 field experiment by Thomas Moriarty (1975[68]) when staging 56 thefts at Jones Beach, New York. In all of them a portable radio was stolen from an unattended blanket. With the aid of two experimental confederates, the theft was staged in full-view of each subject. In each case, the  confederate victim  placed his blanket within five feet of the subject, turned on his portable radio to a local rock station (at a fairly high volume). After reclining for one to two minutes, the Victim left his blanket and spoke briefly to the subject either asking for the subject to watch his things (Group 1) or for a light to lit his cigarette (Group 2). The confederate victim then strolled away out of sight. Two to three minutes after the  confederate thief  came along and stole the radio. Result: in Group 2 only 20% of the subjects responded to the obvious theft compared to 95% in Group 1. 

. Similar results for the efficacy of public commitments have been obtained in a wide range of settings (Goldstein, Martin and Cialdini, 2015[69]). For instance, in a field experiment in the UK, having patients repeat the date of their doctor s appointment led to a 3.5% reduction in  do not attends  (DNAs), while further having them write it down led to a subsequent reduction in DNAs of 18% compared to the previous 6 months average (Martin, Bassi and Dunbar-Rees, 2012[70]). 

. In a field experiment at the beginning of the winter, Pallak and Cummings (1976[71]) asked a group (Group 1) of residents in Iowa to try to conserve energy. They agreed and received some energy-conservation tips. Another group (Group 2) was asked the same and received the same tips, but was also offered to have their names publicised in local newspaper articles as public-spirited, fuel-conserving citizens. After one month, though, group 2 received a letter stating that publicising the names was not possible after all. Looking at the utility meters after one month as well as at the end of the winter showed something remarkable. After the first month as well as after the end of winter, Group 1 had not conserved energy compared to a random sample of their neighbours who had not been part of the experiment. In Group 2, however, participants had managed to save 12.2% energy (while believing their names would be made public), but 15.5% during the rest of the winter (after knowing their names would not be made public). Pallak and colleagues took the first measurement to show the power of making public commitments. The second measurement was interpreted as showing how closely such behaviour interact with self-identity: having saved energy, but without getting their names publicised, participants had to come up with good reasons why they had not only conserved energy due to the public commitment leading to a transformation of self-perception and ensuing behaviour. 


 


Ethical guidelines for designing BI strategies for behaviour change (STRATEGIES) 
139. The stage of STRATEGIES suggests a series of behavioural insights to inform the design of potential public policies to match behavioural problems identified through a preceding BEHAVIOURAL ANALYSIS. However, since many behavioural insights relies on 


mechanisms that are not fully accessible to consciousness or under peoples conscious control, the BI paradigm has continuously been facing criticism and suspicion of serving governmental manipulation with peoples choices. The ethics of applying BI, however, quickly becomes a more complex matter. For one, it involves counter-intuitive and theoretical scientific insights for which our moral intuitions are not well adapted. For another, behavioural insights are not all alike and hence difficult to evaluate as one. Still, several distinctions and observations may be drawn providing some rough guidelines for what to consider when drafting public policies on the basis of the BI paradigm. 


Table 6. Ethical guidelines for Stage 3: STRATEGY 
1. While we are always being behaviourally influenced, this does not exempt BI from ethical evaluation. It is sometimes claimed with reference to Thaler and Sunstein s Nudge (2008[8]) that since we cannot avoid behavioural influences, then ethics is not an issue that need be considered. This is neither true, nor what Thaler and Sunstein assert. More importantly, while it might be true that we are always being behaviourally influenced, when applying BI researchers, practitioners and policymakers intentionally try to intervene to change the behaviour of citizens. With intentional intervention comes ethical responsibility that cannot be evaded by pointing to the fact that citizens otherwise would have been influenced by different factors.  
 
2. Devising strategies for behaviour change is not morally objectionable in and of itself. BI is sometimes criticised for seeking to intervene in the life of citizens in order to influence their behaviour. However, this is not an objection against applying BI in public policy, but rather against public policy in general. After all, the raison d  tre of public policy is intervening in individuals  lives to regulate and influence citizens  behaviour. 
 
3. Public acceptance of a behavioural intervention does not make it ethically permissible. In recent years a long series of survey studies have surfaced inquiring into the public acceptance of applying various kinds of behavioural insights to change human behaviour. While such empirical studies are interesting since they reveal the structure of the moral intuitions relative to BI, any kind of public acceptance of a behavioural intervention does not make that intervention ethically permissible. For one, such surveys do not easily reconcile with the theoretical underpinnings of BI. Second, one cannot deduce from what is currently acceptable to what ought to be acceptable.   
 
4. While people may avoid a behavioural intervention in principle, this does not mean that they can in practice. It is sometimes held that BI interventions neither force individuals to act in a certain way, nor sanction them economically. Hence, it is said, applying BI cannot be morally objectionable. However, it should be noted that the freedom of choice held in this case is often one that only pertains to ideally rational individuals   and since one of the main propositions of BI is that real world individuals are not ideally rational, it is incoherent to hold this position. 
 
5. Not all aspects of applying behavioural insights are inaccessible to consciousness. While it is sometimes held that behavioural insights influences individual behaviour in ways that are inaccessible to consciousness, this is not the case for some types of influences. In particular, the use of insights such as salience, reminders, prompts, questions trees, implementation intentions and the like, are usually transparent to citizens. The application of such insights is referred to as transparent, while influences for which citizens cannot identify (1) whom is trying to influence them by (2) what means and for (3) what purposes, are referred to as non-transparent. 
 
6. Not all aspects of applying behavioural insights are outside people s control, i.e. automatic. It is sometimes held that that behavioural insights influences people s behaviour in ways that render it outside of their conscious control. However, while some insights mediate their effects in ways that people cannot avoid, many applications makes possible or even depends on conscious control. Influences that people cannot control are referred to as unavoidable, while influences that make it possible or depend on conscious control are referred to as avoidable. 
 
7. Transparent avoidable interventions are usually ethically permissible when serving peoples interests. As potential policies based on such influences are transparent and under the conscious control of citizens, citizens are in a situation where they can decide to reject and thus avoid the policy intervention in question. Thus, such policies will usually be permissible as long as they are intended to serve the interest of citizens and thus qualifies for public policy intervention. 
 
8. Transparent unavoidable interventions are usually ethically permissible when serving people interests and routes to objections are made available. Being transparent citizens will be aware of such interventions, but since they are not readily avoidable due to their automatic mediators, policymakers should always take care to make available routes for objecting and complaining about the potential intervention as part of its design. 
 
9. Non-transparent unavoidable interventions are usually ethically permissible only if serving people interests, if clearly communicated, routes to objections are made available. Some behavioural interventions are not readily transparent and may not be unavoidable. Policies designed on such interventions may be ethically permissible if (1) their existence, purpose and their nature as a means is clearly communicated, thereby making them transparent in principle, (2) easy routes to objections and complaints are made available, and (3) the intervention serves peoples interests. 
 
10. Non-transparent avoidable influences are usually not ethically permissible even if serving peoples interests. When a policy intervention is non-transparent and avoidable, this means that it will usually be a matter of intentional manipulation by policy design, while at the same time people will usually be held accountable for their actions. In such cases citizens are treated as a means, rather than an end. Even if such interventions are intended to serve the interests of citizens, they are usually not permissible unless they serve to prevent against harm to others. 
 


Source: Hansen (2018) for the OECD 
Stage 4: INTERVENTION   Testing policy interventions 
Roadmap 
You have conducted a BEHAVIOURAL ANALYSIS, and identified possible STRATEGIES to address the policy problem. Now comes Step 4: INTERVENTION, where policy solutions are tested to see what works, and what does not in affecting real behaviour change. In this section, you will learn how to think your way through carrying out a behavioural intervention in regards to: 
1. Identifying the features and concepts of the experimental approach 

2. Learning  what works  (and what does not) from experiments 

3. The main steps for carrying out a behavioural insights experiment, using this knowledge 

4. Pose ethical guidelines for consideration in Stage 4: INTERVENTION 


 


140. At the heart of the behavioural insights paradigm lays the ambition to evaluate the effectiveness of suggested interventions according to the methodological standards of the behavioural sciences. This stands in marked contrast to many other innovative policymaking methods, who may employ piloting and testing but in a more design-led perspective that is not based on rigorous experimental methods. It is important to note that one is not better than the other; they work in different ways, and can be combined to have a staged approach. Stage 4 of BASIC however focuses on the experimental approach that is fundamental to BI, based on a systematic and iterative process of positing hypotheses about human nature, and then designing and evaluating interventions based on these hypotheses to arrive at the best possible solution for the policy problem. 


General features and concepts of the experimental approach 
141. To  experiment  or, to  carry out an experiment , is a word that has penetrated everyday language in a sense where it means to  try out new things  or  do things differently than usual  to see if some change might have an effect on something else. Yet, in the sciences testing through experimentation means something much more precise. 

142. In the sciences, the point of an experiment is to demonstrate the causal relationship between an intervention and its outcome. Said differently, the reason you conduct an experiment is to find out whether making some intervention (i.e. the manipulation of an independent variable) will cause an effect (i.e. a measurable difference in one or more dependent variables). In addition, an experiment may also aim to determine through which mechanism (mediator) a cause produces its effect, under what conditions (context), what may moderate it (moderators) and what kind of relationship between cause and effect obtains (relationship). 

143. An experiment does this by  cloning the world in two , then simulating what happens in the cloned world (the counterfactual) where the only difference is that the intervention occurs, and finally comparing the resulting state of the cloned world with the original one to determine the difference (the status quo). In so far as the only difference 


between the two worlds is the prior occurrence of the intervention in the counterfactual world with a following change in the state of that world, the difference may be asserted to result from the intervention. That is, the cause of the effect can be attributed to the intervention. 

144. So how does one conduct experiments that actually teach us something about relationships between causes and effects in the real world; specifically lessons about the effects of policy interventions? And when can we trust findings to apply to people, contexts and times beyond those conditions within which an experiment is conducted? The sciences have developed methods for this. Most prominent amongst these is the randomised controlled trial (RCT). 


Experimental methods 
1. The Gold Standard: Randomised Controlled Trials 
145. Randomised controlled trials (RCTs) have been at the core of the evidence-based movement over the last two decades in public policy. It is considered the  gold standard  because it represents the best scientific method available for assessing whether an interventions is effective, as well as the nature of the causal relationship involved. This attitude is especially prevalent within the BI community where many hold RCTs to be the best way of determining whether a policy intervention is effective. 

146. In its simplest form (see Figure 16), an RCT randomly allocates participants to one of two groups: a group that receives the intervention (the treatment group, or counterfactual) and a control group who does not (the control group, or status quo). The treatment is then applied, and the differences between the groups is observed and measured in terms of differences between the dependent variable for the two groups via a post-test. The random allocation is critical in ensuring that the two groups are statistically equivalent in known as well as unknown traits. For more details on why this is important, see the compendium.  


Figure 16. Basic RCT design 
 

Source: Hansen (2018) for the OECD 
147. Provided that the participants are allocated randomly to each group, an RCT comes as close as possible to creating a counterfactual world to the status quo   the only difference 


between the groups involved in the experiment is the intervention received. If no other variable could have influenced the outcome, any subsequent difference between the groups can be attributed as a causal effect of the intervention (see Box 17 for threats to internal validity). 


Box 17. Threats to internal validity 
Internal validity refers to the extent to which a study demonstrates the causal relationship between intervention and outcome. That is, did the intervention actually cause the outcome? In determining this there is a wide range of possibilities for confusion and error. There are two ways to deal with such threats to the internal validity of an experiment: (1) Use randomisation to offset known as well as unknown factors that might lead to non-equivalent groups; or (2) take specific steps to deal with known threats by constructing a suitable experimental design. If following the second path, the following list of threats to internal validity may serve well as a checklist: 
1. History. 
2. Testing.  
3. Instrumentation. 
4. Regression.  
5. Mortality. 
6. Maturation. 
7. Selection. 
8. Selection by maturation interaction. 
9. Ambiguity about causal direction.  
10. Diffusion of treatments. 
11. Compensatory equalisation of treatments. 
12. Compensatory rivalry.   
If you can plausibly rule out these threats, you have established internal validity. 
Source: (Cook and Campbell, 1979[72]) 
 


 
148. There are many ways to organise an RCT. Below, you will find four of the most usual RCT designs, which will be elaborated on more in the compendium for your reference. 

1. Post-test-only RCT: The minimal design for an RCT. Participants are randomly assigned to treatment and control groups, receive the treatment and effects are measured through a post-test to compare the differences.  

2. Post-test-only two treatment RCT: A variation on the above, but with two treatment groups instead of a treatment and control group.  

149. The latter is becoming increasingly popular in the BI world, but comparison between groups should be treated with care as it represents a  false control . Any 


differences could be from (1) quickly and poorly assembling the intervention or (2) both treatments may be an improvement on the status quo. For this reason, practitioners should always retain a control group in the experimental design unless an existing policy intervention is already in place and working.  

150. Moreover, if sample sizes are small, the two post-test experimental designs just mentioned may become problematic as a low number of participants may allow for statistical differences between groups to creep in (i.e. risking an unrepresentative sample), thereby undermining the equivalence of groups. In such cases introducing a pre-test into the experimental designs above may offset some of the uncertainty resulting from a small sample size. This provides us with the following two experimental designs:  

3. Pre-test post-test RCT: Participants are subjected to a pre-test and then randomly allocated to control and treatment groups (independent of the result). Treatment is administered and a post-test is conducted. Results from the two groups are then compared, including pre-test post-test changes of individuals in the groups. 

4. The pre-test and post-test comparison trial: Same as above, but both groups receive a treatment (i.e., no control). 

151. These experimental designs are aimed at testing a single factor intervention at a time. This is completely in line with how some researchers think about doing BI experiments in the real world: only test one factor at a time so we may truly isolate the causal relationship. Too many BI practitioners tend to repeat this mantra, taking it to mean that one can only test one factor in any given experiment.  

152. Fortunately this is not quite so. Granted that one knows ones way around experimental design, more than one factor may be tested in one and the same experiment  almost for free . 


2. Factorial designs 
153. A factorial design tests two (or more) independent variables and their potential interaction effect at the same time by combining the  levels  (including the binary one of the  absence  and  presence  of an intervention) with the levels of another factor. For instance, imagine you want to test  intervention A: Salient deadline  and  intervention B: Social proof . Now, you may either do two RCTs or pursue a 2x2 factorial design like the one in Figure 17. 


Figure 17. 2x2 factorial design 
Type the subtitle here. If you do not need a subtitle, please delete this line. 
 

Source: Hansen (2018) for the OECD.  
154. A 2x2 factorial design like this implies that four groups cover all possible combinations of the two interventions and assumes that participants randomly allocated to these. Benefits of factorial designs include: 

. Allows for the analysis of an additional factor at little additional cost compared with two separate RCTs. While group 1 + 2 act as the control for Intervention A; groups 1 + 3 act as the control group for Intervention B. 

. Provides more information than two RCTs because it allows you to study the effect of an intervention relative to the level (e.g. presence/absence) of a second principle (3 compared to 4), the combined effect relative to the control (1 compared to 4) as well as any potential interaction effect of the two interventions tested (3+2 compared to 4). 

155. While factorial designs allow practitioners to gather more information from a single experiment they may quickly grow out of hand relative to the sample size available. For instance, if you have three insights you want to test (absent/present), say formulations integrating loss aversion, salient deadline and social proof, respectively, you will need 8 groups.  

156. In this case, one may opt for a  fractional factorial design . This design offers additional possibilities, but should be used with some care. In such a design only some of the possible combinations are tested.  

157. A particular use of the fractional factorial design in BI may be illustrated using the 2x2 factorial design above. Assuming that budgets, available sample size, institutional cautiousness, or some other constraint, only allows for three groups, rather than four groups, the fractional factorial design may omit testing a group, e.g. as here the group testing combination 3, such that only combinations 1, 2, and 4 are tested. This allows for an experimental design sometimes informally referred to as a  multi-layered experiment  because the test builds up by adding layer after layer of interventions for the experiment to test (see Figure 18). 


Figure 18. Fractional factorial design 
 

Source: Hansen (2018) for the OECD 
158. While a fractional factorial design allows one to create layer-by-layer interventions it also presents a standard pitfall when applying BI to real world public policy. That is, the stakeholder ordering the experiment may see no reason to waste resources on Group 1, where the control is established, and rather focus on Groups 2 and 4. This can happen in the public policy space, where legal obligations of the stakeholder institution could apply or a moral imperative to provide the best public services could be argued. 

159. Going with this amended design would be a mistake. It is possible that the difference between Groups 2 and 4 is small and insignificant, but the difference between the Groups 1 and 2 is large and significant. Without Group 1 as a control, the practitioner would not be able to determine the relative significance and magnitude of the findings, and inaction on the policy problem is likely to follow.  


3. The Realistic Standard: Quasi-experiments 
160. There can be little doubt that the RCT represent the gold standard of scientific enquiry. When conducted correctly, a RCT has the potential of demonstrating actual causal relationships obtaining between interventions and outcomes in the real world. The only problem is that the real world does not easily allow for the random allocation of people to experimental groups without so seriously distorting the target behaviour that the experiment no longer is about the causal relationship intended. As a result the quasi-experiment has become a widespread alternative to RCTs in social experimentation.  

161. The quasi-experiment is a research design involving an experimental approach more or less identical to an RCT, but where random allocation to treatment and control group has not been used (Campbell and Stanley, 1963[73]). As a result the equivalence between groups cannot be guaranteed, resulting in a series of threats to the internal validity of the experiment (see Box 17). As a consequence, quasi-experiments are often portrayed as a second-best choice to be considered when the behavioural intervention studied does not allow for the random allocation to groups.  

162. As some of the most relevant and interesting real world behaviours, especially when it comes to public policy, do not allow for randomisation, quasi-experiments should perhaps be treated as the realistic standard, rather than the alternative. If not, the very method of experimentation may end up biasing what is studied experimentally   a bias, which is already clearly detectable in BI, where experiments on conformity to messages sent by letters and similar behaviours conducive to randomisation are massively overrepresented.  


163. In addition, as the pioneers of experimental design, Cook and Campbell ( (1979[72]), argued, even randomised controlled trials should be planned such as to be interpretable as quasi-experiments, in case something goes wrong with the randomised design, as it often does in the real world. On the negative side, this means that a series of precautionary measures should always be taken relative to the design of the experiment as well as the analysis planned. On the positive side, it usually means that additional information is collected e.g. about the background of participants, allowing for more interesting analysis.  

164. Quasi experiments are thus a natural starting point challenging practitioners to think creatively about how to approximate random allocation into the real world, rather than create a randomised sample that is easily yet artificially created, and may introduce other problems into the experiment just to satisfy a scientific ideal.  

165. This conclusion is important for policymakers to observe as they are usually the ones deciding what BI work to fund and accept. The growing tendency amongst some researchers and practitioners to portray RCTs, as the only way of working scientifically with BI with the potential privileging of RCTs that may follow is a serious distortion of the nature of how behavioural science actually works. Not only with regards to testing interventions with actual relevance for public policy, but also as we turn to next, at the possible expense of the work carried out in exploratory stages such as BEHAVIOURAL, ANALYSIS and STRATEGIES without which there is little meaning in the activity of testing INTERVENTIONS through experimentation.   


Learning  what works  from experiments 
166. There is no doubt that experiments, whether carried out as RCTs or quasi-experiments, represent the best scientific method available for assessing whether an intervention is effective as well as the nature of the causal relationship involved. However, while testing BI interventions through experimentation may be a necessary component in any BI project, it is not sufficient by itself for generating lessons about  what works  in the sense of knowing what policy interventions work.  

167. To understand what is at issue here, one needs to understand that the BI movement is widely perceived, as closely tied to the iterative use of field RCTs, where multiple behavioural insights may be tested quickly and cheap as long as the experimental designs and the institutional setting allows for a sufficient number of groups. Through such a process of iteration, it is thought that better and more effective public policies may be developed through an incremental process of learning what works through direct field-testing. In its most simple form the underlying idea is that practitioners can just test a range of BI interventions in a field RCT to learn  what works,  while effectively treating the behaviour, including the mental processes and causal relationship involved, as a black box that need not to be opened. However, there are important shortcomings with this idea that needs to be corrected. 


Learning  what works in the real world   
168. For one, it is important to notice that to the extent that we want to learn anything from experiments, they need to be inherently theory driven (Robson & McCartan 2016). The only way researchers and practitioners can properly design an experiment is if they can specify in advance the variables to be included and the experimental protocols to be followed. For this to be possible researchers and practitioners must already have a substantial conceptual grasp of the behaviour which the BI intervention tested is to be 


applied to. In following a diagnostic method like BASIC, part of this conceptual grasp should be in place. However, if developing experiments without a conceptual grasp of the behaviour achieved through some sort of diagnostic effort experimentation might easily prove a risky strategy, where precious resources may be wasted and citizens used as participants in haphazard experiments.  

169. More importantly in this connection, without such a conceptual grasp of the target behaviour, researchers and practitioners will end up learning nothing about what works from testing BI interventions through experimentation   they will only be able to say what worked in the particular experiment carried out. This is because an experiment in and by itself only shows that a particular intervention caused a certain outcome (causal description), but reveals nothing about the actual mechanisms by which it did so (causal explanation)   except in so far the experiment is deliberately designed to control for possible alternative mechanisms (Robson and McCartan, 2016[74]); (Shadish, Cook and Campbell, 2002[75]). If this is not the case, researchers and practitioners will be in the blind as to how to generalise their findings from  what worked  into those principles of  what works  that is to behaviourally inform public policy. This is not a point to be dismissed as merely of  theoretical and academic interest . Carrying out fans of experiments without a close eye to this issue undermines the whole point of experimentation as well as the very possibility of behaviourally informed public policy   to know  what works  means to know how it works, for whom and under what conditions. 

170. What was written in the beginning of the chapter thus takes on a new nuance. The reason you conduct an experiment might be to find out whether making some intervention (i.e. the manipulation of an independent variable) will cause an effect (i.e. a measurable difference in one or more dependent variables). However, the reason why you experiment is to find out how that knowledge can be used to inform future decisions. For this to be possible, one also needs to determine through which mechanism a cause produces its effect (mediator), under what conditions (context), what may moderate it (moderators) and what kind of relationship between cause and effect obtains (relationship). This latter  addition  is crucial. It is what allows researchers and practitioner to generalize the findings of the experiment. 


Generalising experimental findings 
171. One way to approach the whole issue of generalizability is by looking at a question about sample size. Non-researchers sometimes think that the sample recruited for an experiment needs to be representative of a population, and thus ideally comprise 1 000+ participants selected randomly from the wider population. This is due to their familiarity with traditional methodologies such as representative surveys. However, while such vast and representative samples would obviously be nice in an experiment, it s not necessary.  

172. As just discussed the point of an experiment is to test the causal effect of an intervention. For this it is not necessary to consider the sampled participants representativeness relative to a larger population. Given the random allocation to groups as in a RCT as well as strict control over the experimental setting, such that the groups differ only in the intervention introduced to the treatment group, any subsequent difference between the two groups must be an effect of the intervention. The necessary sample size for proving such an effect ultimately depends on the size of the effect and can be calculated by a statistical method known as  power analysis  (see Box 18). Some of the cases mentioned in Stage 3 have been based on this method and feature as little as 90 participants (see Box 6 on hand sanitizers).  


Box 18. Power analysis 
The necessary sample size for proving an effect ultimately depends on the size of the effect and can be calculated by a statistical method known as  power analysis . Power analysis allows one to perform a backwards calculation from the size of the effect to the sample size needed to show this effect to be significant. A power analysis allows researchers and practitioners to determine the sample size required to detect an effect of a given size with the required degree of confidence. This means that how many participants are needed for an experiment may be derived from knowledge of the effect and the confidence level wanted. Of course, this creates something of a catch 22, as the eventual estimated size of the effect can never be known until it has been shown. To some extent the mapping of a behavioural pattern done as part of BEHAVIOUR as well as piloting the experiment (see step 7 below) may give some clues about what to expect. However, a better approach when applying BI to public policy may be to assume what effect size will be acceptable for developing a larger policy intervention upon and then derive the number of participants needed to detect such an effect with an acceptable probability.  
 


173. Yet, one should still pay notice to the composition of the sample featuring in an experiment. This because experimentation is concerned with drawing lessons that may be generalized and the composition of the sample constrains the conclusions that may be drawn from the measured effect of the intervention relative to the participants (what worked), to the likely effect of the intervention on other people in real world (what works).  

174. Importantly, similar points also holds true with regards to the context within which the experiment took place, the conditions under which the causal relation was produced, the mechanism that mediated cause and effect, and the potential moderators. This is what was alluded to in Chapter 1 when writing that BI is about behavioural insights. One need to identify the behavioural insights at work as defined there to provide behaviourally informed policy advice. While issues about generalizability, such as representativeness, is not a fundamental issue when designing experiments for understanding  what worked , it is a fundamental issue when designing experiments to inform public policy about  what works . 

175. In general, generalizability is a complex area in scientific research. Two core strategies for working with generalizability may however be mentioned here (Robson & McCartan 2016):  

1. Direct demonstration is a strategy where researchers and practitioners tries to replicate an experiment, carry out further experiments with other types of participants or conducts the experiment in a different context. 

2. Making a case is a strategy where researchers and practitioners tries to argue that it is reasonable to expect the results will generalise due to the sample, setting or mechanisms studied in the experiment is representative of the cases the experiment is sought generalised to.  

176. The ABCD framework is in a sense an example of making a case by asserting that systematic relationship between certain aspects of behavioural problems   Attention, Belief-formation, Choice and Determination   and particular solutions that are so robust that they may be generalized. Still, when it comes to informing the design and development of particular public policies, BASIC holds that making a case is mainly a strategy for 


identifying potential strategies to integrate into a policy intervention that need to be tested at several levels in order to inform public policy in terms of a general behavioural policy principle. 


Proving theory, practice, and policy principles 
177. Most of the experiments inspiring BI have traditionally taken place in laboratory settings. A laboratory is an artificial place constructed with the sole purpose for researchers and practitioners to control for almost all factors. This allows researchers and practitioners to test very precisely the effect of a cause, support claims of mediators, and manipulate moderators in order to assess their impact of the effect. As such a laboratory is the perfect place to test for the existence and nature of a behavioural insight. In this way, laboratories provide proofs of theory.  


Proof of theory 
178. However, the necessary artificiality of laboratories challenges the generalizability of their findings in two ways (Aronson, Brewer and Carlsmith, 1985[76]). First, laboratory experiments may lack experimental realism. This is the case if an experiment fails to put participants in a real situation, such that it does not engage the participants properly or has no real impact on them. Second, laboratory experiments may lack mundane realism. This is the case if the participants encounter events in the laboratory, which are very unlikely to occur in the real world. Besides this, laboratories also invites for certain biases in their findings. The two most important of these are demand characteristics, which bias the behaviour observed in the lab because participants know they are part of an experiment that they are being observed, and know that the behaviour they exhibit will be objects of interpretation. Consequently, the behaviour observed will not only be influenced by the intervention, but also the participants  interpretation of what effect the intervention is supposed to have on them. The other one is, expectancy effects, which bias results through the researcher or practitioner s (usually unwittingly) expectations about finding support for the experimental hypothesis. 

179. Taken in sum, these problems inherent in laboratory experiments may be argued to undermine the proofs of theory as potential sources for informing public policies directly. Instead a more fitting role for them may be argued to be that of informing the field experiments, which in turn may inform public policies by providing proofs of practice. 


Proof of practice 
180. Policies are supposed to work in the real world   not the artificial world of the laboratory. In moving experiments out of the laboratory and into natural settings one minimises certain issues pertaining to the generalizability of findings. If something works in a field experiment, it works in the real world   at least for the specific intervention tested. Likewise some of the biases liable to affect laboratory studies are also avoided. For instance, in field experiments participants will often not know that they are participating in an experiment. Hence demand characteristics are minimised as well. Finally, while laboratory experiments usually recruit participants amongst students, field experiments tend to observe participants from groups that usually engage in the target behaviour. As such, field experiments are the perfect setting to test the real world effect of a BI intervention. In this way, field experiments provide proofs-of-practice. 

181. However, field experiments also present certain drawbacks. First and foremost, it will often be very difficult to allocate participants randomly such as to establish equivalent 


experimental groups without essentially just moving the laboratory into the field. If randomisation is not possible, quasi-experiments need to be designed so as to counter threats to internal validity (see Box 17, above). Also, interactions between participants in a field experiment is not as rare as one would expect   when participants interaction within experimental groups as well as across experimental groups, it vitiates their random assignment as well as violates their assumed independence. That said, the perhaps most important problem of field experiments is that the loss of control relative to the laboratory setting makes it difficult to get a sufficient conceptual grasp on details to allow for causal explanations to be tested (see discussion above). Consequently, field experiments are not ideal for providing proofs-of-policy-principles. 


Box 19. Real world situations conducive to randomised experiments 
1. When lotteries are expected 

2. When demand outstrips supply 

3. When an innovation cannot be introduced to everyone simultaneously 

4. When participants are isolated from each other 

5. When a tie can be broken 

6. When people express no preference among alternatives 


Source: Adapted from (Cook and Campbell, 1979[72]); Robson & McCartan 2016) 
 


182. What then constitutes proof of a policy-principle, if neither laboratory experiments nor field experiments may do this in and by themselves? A possible answer may be gathered from Levitt and List (2005[77]) who looked at the two approaches   lab and field   and concluded that:  the sharp dichotomy sometimes drawn between lab experiments and data generated in natural settings is a false one. Each approach has strengths and weaknesses, and a combination of the two is likely to provide deeper insights than either in isolation .  

183. If this is the case, one may argue that proofs of generalizable policy principles are not to be found in any single experiment, whether laboratory or field. A laboratory finding may fail to generalise into the field, and a field experiment may fail to generalise across what may seem similar contexts. Yet, by combining the two strategies, laboratory experiments may deliver insights into the causal relationships needed to generalise successfully across real world settings (what works); and field experiments may deliver the generalisation from the laboratory to the field to show what of what works, also works in the real world. 


 
The main steps for carrying out a BI-experiment 
1. Integrating strategies into a prototype policy intervention 
184. Integrate the principles you identified as potential STRATEGIES (stage 3) for influencing the target behaviour into a prototype intervention that could realistically be implemented as part of public policy. 


2. Collecting feedback for improving your prototype intervention 
185. Consider whom to involve how, including people from the target group of the intervention, to get valuable input and feedback on the proto-type intervention. When done, make revisions and iterate the process starting from (1) until you feel ready to proceed to (3). 


3. Determining the variables of the experiment 
186. Determine what variables potentially, realistically and ethically may be manipulated and measured, including background variables, independent, dependent and proxy variables.  


4. Selecting experimental setting and design 
187. Determine which kind of experiment (field or laboratory) and which kind of experimental design is feasible for testing the effect of the proto-type intervention given the constraints set by the project, the involved institutions and the real world. In particular, against this background, also determine what sample-size is necessary for detecting an effect-size sufficiently large to justifying running an experiment. 


5. Developing experimental protocols for testing interventions 
188. Develop an experimental protocol for testing the intervention, including procedures for sampling, data-collection and data-analysis and share this with relevant people   researchers as well as BI- and policy practitioners   to get feedback and input for making necessary revisions. When done, make revisions to the protocol and iterate this step until you feel ready to proceed to (6). 


6. Obtaining approval and pre-registering your experiment 
189. Consider pre-registering the study and make sure to obtain approval from the ethical review board associated with the project as well as legal resources attached to the institutions involved in the project. Consider also whether to involve people from the target group of the intervention in getting input and feedback on the ethical aspects of the intervention. In particular, define potential  ABORT  conditions. 


7. Conducting a pilot-experiment 
190. Conduct a pilot- or pre-test of the prototype as well as important aspects of the protocol, so as to examine (a) whether institutional, technical and systemic aspects work out as expected, (b) what challenges to time schedules and other unforeseen factors might reveal themselves in the process, (c) potential indicators of what effect-size of the intervention to expect, (d) the feasibility of the planned data-analysis, and (e) whether revisions to the proto-type and the protocol are needed   thus returning the process to (5)   before continuing to (8). 


8. Carrying out the experiment 
9. Analysing the result 
191. Follow the planned analysis as described in the protocol and discuss any possible changes to this with relevant researchers, the ethical review board as well as the advisory board.  


10. Writing up the experiment: procedure, results and perspective 
192. Write up a report on the experiment independent of the result and register this in the relevant databases.  


Ethical guidelines for testing behaviourally-informed policies (INTERVENTION) 
193. The stage of Intervention is unavoidably one that intervenes in people s lives by manipulating independent variables to observe how this systematically affects the behaviour of participants. In addition experimentation invariably involves treating groups of people differentially, often treating some groups of people with a treatment that one has reason to believe will positively affect their lives, while withholding this treatment from at least one other group. Hence, it is not surprising that ethical issues need to be considered from the very beginning of designing an experiment over implementing this to wrapping it up and reporting on results.  

194. Considering ethics relative to intervention is usually done by consulting three sources for help (Shadish, Cook and Campbell, 2002[75]):  

. Ethical codes of conduct,  

. Informed consent, and  

. Institutional review boards (IRBs).  

195. The behavioural literature and associations refer to experimental disciplines that for years have devised important resources for addressing these three points. However, it is important to notice that particular ethical codes of conduct, guidelines and procedures are not always uniformly applicable to all types of experimental research. They have mostly been developed to serve in medical research and other areas, such as BI, have different needs and requirements. Hence, researchers and practitioners need to orient themselves within standard ethical guidelines and codes as well as fit these to the special circumstances they are working under. 

196. Of the three sources of ethics relative to the stage of Intervention, the latter two sources were already addressed by the ethical guidelines sketched at the end of Analysis (chapter 4). Thus, new experimenters need to consult those guidelines carefully before embarking on running experiments. The following guidelines relate to some key ethical and legal issues that one needs to consider special to running experiments as part of applying BI as part of developing public policies. 


Table 7. Ethical guidelines for Stage 4: INTERVENTION 
1. Acquire legal permissions for experimentation. Even though law in some countries view experimentation as a legitimate means of exploring public policy issues, practitioners should pay close attention to the legal issues prompted by experimentation. For instance, most countries embrace the principle of equality of treatment requiring that individuals who are similar in relevant ways should be treated similarly. Yet, experiments often require that individuals who are similar in relevant ways should be treated differently. Thus, experimentation in public policy will usually require researchers and practitioners to acquire the right legal permissions in this as well as other aspects. 
 
2. Demonstrate the necessity of experimentation. Also, it should be noted that even if the right legal permissions are acquired, large differential effects between citizens cannot be justified by appeals to some larger benefit to those who might receive improved policy in the future as a result (Shadish, Cook and Campbell, 2002[75]). Thus, before an experiment is conducted, it should be demonstrated that (Federal Judicial Center, 1981[78]):  
  The current policy situation need improvement;  
  The effect of the proposed intervention for improvement is of unclear value; 
  Only an experiment could provide the necessary data to clarify the question; 
  The result of the experiment will be used to inform existing practices or policies; and 
  The right of individuals will be protected in the experiment. 
 
3. Always consult experience. Make sure that new experimenters always consult people with experience in experimental design, intervention and reporting to help generate suitable protocols for experimental designs, pre-tests and experimental tests, including protocols for informed consent, debriefing, and reporting. This is especially important to do with regards to any deviation from customary practices for existing codes-of-conduct within the field in which the BI-intervention is tested. 
 
4. Consider justice, fairness and other ethical aspects when sampling. Interventions often treat people differentially by withholding experimental treatments: treating some groups of people with a treatment that should positively affect their lives, while withholding this treatment from at least one other group. Before considering how to deal with this kind of differential treatment, just being part of the experimental sample means that one receives differential treatment relative to those people not part of the sample frame. Practitioners need to consider and address the potential ethical issues arising from this kind of differential treatment relative to sampling. 
 
5. Deploy compensatory experimental designs if possible. While interventions often treat participants differentially, certain features of experimental designs may compensate or offset some of those ethical issues that arise. The procedure of randomisation may itself be regarded as such a feature, as participants by definition have equal chances for ending up in each of the experimental groups. However, other features of experimental designs may also compensate or offset unequal treatment. For instance, if suitable conditions obtain, practitioners may opt for a crossover design, such that experimental groups switch places as control and treatment groups. Another strategy is to opt for within-group designs such as pre-test post-test designs, where the behavioural effect of a treatment on a group of participants is compared to the same group s behaviour before the treatment was devised. 
 
6. Compensate or offset differential effects between groups. It is not always possible to deploy an experimental design that compensates or offsets potential differential effects between groups, which raises ethical issues. In such cases, practitioners may consider whether post-experimental measures for compensating or offsetting such effects are available. For instance, participants in a group subject to negative differential effect relative to other groups may receive an extended deadline or an additional reminder for complying with existing regulation. In other cases, participants may receive compensatory benefits, such as educational advice, special options or first treatments to offset such effects. What makes up compensatory or offsetting measures will depend on the specific purpose of an experiment. 
 
7. Deploy safety valves for discontinuing experiments for ethical reasons. Plan in advance for on-going experiments to be halted if negative side effects unexpectedly occur or if one experimental group experiences dramatically better results than another. This also requires that preliminary analyses at fixed intervals be planned for that allows for prematurely discontinuing the experiment for ethical reasons. While standard in medical research, this practice is just as important when devising experiments for behavioural informed policies. 
 
8. Protect confidentiality. As mentioned In Stage 1: BEHAVIOUR, BI projects often collect and connect data in ways not usually done in public policy development and design. In addition, testing BI interventions may involve further collection of data from participants who have agreed to be part of an experiment or study. It is important to observe that the confidentially of research data is not necessarily protected by law   especially not when interventions are tested by public authorities themselves. However, this does not permit practitioners to plan experiments, including when obtaining consent, where participants are not guaranteed the kind of confidentiality guaranteed by the stated consent or expected by citizens who decide to participate. For this reason, even when being employed within public organisations, practitioners should carefully consider using procedures and protocols that ensures the confidentiality of participants, e.g. by using randomised response methods or determining not to collect or connect any data about potential identifiers. 
 
9. Ensure ethical data analysis. Statistical analysis may easily be tweaked to misrepresent findings in ways that misdirect laymen, who tend to perceive numbers and statistics as objective facts. Practitioners are responsible for doing their best to avoid misrepresentations, especially in BI where one cannot be excused by assuming that people ought to know better. This guideline not only concerns the representation of data, but also its analysis. It is thus important that researchers and practitioners comply with principles for the ethical production and analysis in all aspects of handling data   from pre-registering studies, over accounting for data outliers and truthfully reporting on attrition, to strictly follow standards of statistics and their representation.   
 
10. Preventing misrepresentation as best as possible. Even if all the guidelines above are followed, it is still part of the scientific social responsibility of practitioners to do their best to prevent misrepresentations and overstretch of results. BI has seen its fair share of misrepresentations and overstretches; simplifying mechanisms too much and overstretching lab findings to explain almost any real world phenomenon. For this reason, practitioners should not only make clear results and conclusions, but also the limits of these relative to the interpretation of real world phenomena and what needs to be studied further before drawing appealing conclusions. 
 


Source: Hansen (2018) for the OECD 
Stage 5: CHANGE   Implementing behavioural insights 
Roadmap 
You have completed your intervention testing, and arrived at the best solution for your policy problem. Now what? Stage 5: CHANGE gives some advice for how to scale up and implement your solution, as well as develop broader impact in your government. The main areas to be discussed will be: 
1. Revisiting the political context and project level 

2. Important steps for implementation and creating broader impact 

3. Ethical considerations  


 


197. The past chapters have covered the first four stages of a BI project as carried out according to BASIC. This chapter covers the Stage 5: CHANGE and is about how to implement behaviourally informed public policy interventions. 

198. When a BI project enters this stage, significant effort has been put into the BEHAVIOURAL ANALYSIS, which seeks to understand why people act as they do; identified STRATEGIES that matches the problem diagnosis to effective and responsible solutions, and tested a proto-type policy INTERVENTION. The practitioner enters into Stage 5: CHANGE WHEN tests have produced promising results that can be developed into a full policy intervention   or when repeated failure brings the project to an end and the community can learn from what did not work, so that the field can advance.  

199. In one sense, this stage is straightforward for the BI project to fulfil its mission. Obviously, without an effective implementation of the successfully-tested behaviourally-informed policy, there will be little, if any effect of the work done. Yet, in another sense, the stage where a BI-project transition into promoting CHANGE is all but trivial. 

200. This is the stage where the temporary communion of mutual interests of all those involved in the BI-project may dissolve with the potential result that nothing gets implemented, or what gets implemented is very different from what was intended. This means that somewhat surprisingly to practitioners, though not necessarily to policy-makers, even successful behavioural insights projects and trials may never be properly implemented or, alternatively, may be undermined or just forgotten by subsequent policy efforts.   

201. To prevent this from happening, Stage 5: CHANGE includes a series of tools and considerations relative to the effective and successful implementation of behaviourally informed policy. 


Revisiting the political context and project level 
202. The first step is to come full circle and revisit the policy context or policy challenge that originally motivated the project, as well as the project brief that defined the approach and scope of the project. In public policy situations, interests changes all the time and it needs to be ensured that interventions as well as the process of implementation is aligned with the current situation, rather than the past. 


203. Even though the priority filter in BEHAVIOUR tries to take precautionary measures for such changes, a series of factors that can potentially affect the initial context needs to be taken into consideration. These include: 

. Digitisation: Digital platforms and technologies develop at an ever-increasing pace. Practitioners will often find that the program software and digital systems involved in a project may have changed and offer new constraints or possibilities that need to be taken into account when developing a plan for implementation. Examples of this problem are abound in BI, where many original projects have delivered behavioural insights into letters send from public bodies, only to find that those organisations transitioned into digitising their communication at the same time. The same is currently the case in consumer research, where projects about certain markets or consumer conditions are overtaken by the development of digital markets. 

. Policy interests: Political and policy interests sometimes change at an even faster pace than technological development. Factors external as well as internal to the project might have caused priorities to flip. New and pressing policy challenges may have crowded out interest in the current project, or the policy problem might have developed into a more pressing concern and called for more immediate action. Internally, the implementation of a BI project might suddenly be top of a minister s agenda, if e.g. the results are very promising; or interest may have waned, if e.g. the results were too meagre or too technical to promote a public agenda.  

. Regulatory context: Regulation might have been passed that have rendered the intervention superfluous or out of pace with the rules. The former is represented by interventions designed for a behavioural problem, which since then have become subject to legislative push (e.g. the problem at stake has been regulated through traditional means) or legislative rollback (e.g. when a law is abrogated so that the intervention is no longer relevant). The latter is even more important as changes in the legal landscape might call for revisions in the design of the intervention (e.g. when new data-protection rules requires for changes in a digital implementation).   

. Institutional structure: The period where BI has emerged has also been one where institutional reforms have been popular, both in terms of creating new institutions applying BI but also changes to the institutions wherein the practitioner may be working. Thus, it is crucial that practitioners take institutional reforms, changes to structure and dynamics into account before embarking on implementing a behaviourally-informed policy intervention. 

. Public opinion: Last, but certainly not least, any plan for implementing a behaviourally-informed policy intervention needs to take changes in public attitudes and sentiments into account. Cases with relevancy to the policy challenge or policy problem addressed by the project may have received considerable public attention during the execution of the BI-project, which means that the policy intervention suggested by the project needs to be implemented with an eye to this. Thus, the practitioner should consider consulting on the proposed intervention with citizens, businesses, non-profit organisations, and other affected groups to get a view into how the policy intervention might be received and, equally important, perceived, comments on the proposed intervention, as well as to gain further support up front from these stakeholders. 


204. Besides looking into the potential factors with a potential relevance for the behaviourally-informed intervention and their implementation, researchers and practitioners also needs to revisit the ambitions and scope of the original project brief. Although all changes that have been made to the original project brief during its execution might have been acknowledge by all relevant parties throughout the project, the implementation plan still needs to take the original brief into account to make sure how what is to be done next connects with the original idea behind the project. In particular, the implementation and next steps should revisit the ambitions, which pertained to the project relative to its level (see Determining the policy level of the project above): 

. Institutional level projects aimed to apply BI to a wider institutionalised domain to provide an understanding of how this approach may help to transform public policy development and/or delivery. The ambition is thus to explore the  institutional fit  of BI, so to speak, by (1) providing knowledge about the institutional potential and relevant processes and methods involved when working with BI, (2) carrying out interventions that may serve as proof-of-concept, and (3) identifying the possible institutional obstacles that working with BI presents to the particular institution and its domain. 

. Strategic level projects aimed to apply BI to one or more issues from a defined list of existing policy problems that challenge a particular institutional domain or sector. The ambitions is thus to deliver viable and effective policy insights and solutions which are cost-effective compared to alternative policy measures by (1) extending existing knowledge about BI and building capacity for this within the institution, (2) applying the lessons learned from former institutional projects to strategic level problems to test for their robustness, and (3) providing scalable long-term solutions to one or more existing policy issues. 

. Behavioural Level Projects aimed is to apply BI directly to a specific behavioural problem in the institutional domain or sector. Policy-makers, stakeholders and collaborators usually assume that the tools and methods for applying BI in public policy design and delivery are more or less fully developed. Thus, behavioural level projects are expected to fully integrate into the everyday decisions and processes of institutional work. The success criteria of projects at this level will usually be: (1) Smooth integration of process, (2)  problem solved , not  lesson learned , and (3) easily communicable results. 

205. It is important that the stage of implementation begins by revisiting these aspects of the project, so as to ensure that the implementation of any ensuing behaviourally-informed policy intervention is adapted to the current policy context as well as aimed at delivering on those ambitions that originated the project. 


Important considerations for implementation and creating broader impact 
206. Revisiting the policy cycle presented above (see Figure 1), working your way through the five stages of BASIC has left you on the doorstep of the implementation phase. You have spent significant time analysing the problem and determining through evidence what is the best design for your policy intervention. This section of Stage 5: CHANGE is meant to give the practitioner some important considerations for taking their intervention through the rest of the policy cycle by moving to full implementation and then evaluating results. The eventual goal is to feed this information back into Stage 1: BEHAVIOUR, but 


with ideas for new interventions that can go even further to achieving the intended policy goal.  

207. For policymakers, this is not new, while for those new to policy making this may not be obvious. Either way, it is worth the reminder to consider what needs to be done, as well as take note of any BI-specific tasks should be thought of when moving through the policy cycle. Consider then these items when moving from design to implementation and evaluation: 


1. Implementing and scaling behaviourally-informed policies 
208. Consider good regulatory practices. The intervention being developed could be a new programme or something with much broader impacts, such as a change to a law, regulation or regulatory regime. For instance, the OECD worked with the Colombian Communications Regulator to re-designed their consumer protection regime with the help of behavioural insights (OECD, 2016[79]). In these situations, the practitioner should consider good regulator practices, such as Regulatory Impact Assessments (RIAs) and stakeholder engagement, as a means of measuring the potential impact of the proposed intervention and offering citizens, businesses, and other affected parties a chance to provide their inputs (OECD, 2014[80]); (OECD, 2018[12]).  

209. Actively use behavioural insights to inform implementation and scaling. In drafting plans for implementing, scaling and evaluating a policy solution, one should actively use behavioural insights to inform these plans. For one, the ABCD framework suggests that aspects of attention, belief-formation, choice and determination should be carefully considered relative to change itself as implementing the behaviourally informed policy is itself to be considered as an intervention. Thus, considering strategies such as  make it relevant  or  devise plans and feedback  relative to this stage is only natural. Also, plans should carefully consider whether the implementation is based on work that generalises to the currently considered policy. A behaviourally informed policy will always have been tested in a more specific or limited area than that to be covered by the policy. Thus considering how the results might fail to generalise when scaled, e.g. through a  post-mortem , and then devise plans to take results into account would also be a natural strategy when implementing behaviourally informed policies. These are but two of many ways that researchers and practitioners may consider applying BI to inform the stage of CHANGE.  

210. Implement experimentally and scale incrementally. Besides actively using behavioural insights to inform the implementation, scaling and evaluation, to actively use BI as part of CHANGE, researchers and practitioners should also devise plans in accordance with methodological underpinnings. Traditionally policies are rolled out across the board when implemented. But adopting a BI approach to CHANGE means adopting an experimental approach to the implementation and an incremental approach when scaling up behaviourally informed policies. This also requires keeping track of the dependent measures used for the experimental evaluation as part of INTERVENTION as well as adding additional measures made possible by the policy being scaled up. This allows keeping close track of various moderating variables as part of implementation. Thus, through the implementation and scaling up of a behaviourally informed policy, practitioners may study whether certain groups are more or less affected than what was suggested by tests as part of INTERVENTION. This in turn may lead to further iterations and tweaks in the design of the policy in question. 

211. Avoid watering-down behavioural policies by carefully monitoring implementation. A recurring problem experienced in the stage of CHANGE is that 


behavioural policies may become watered-down. This occurs because of the often counter-intuitive nature of behavioural interventions. To third parties usually working in a rationality-based policy perspective, crucial contextual features and other aspects of a behaviourally informed policy, might not seem important or be perceived as in conflict with a traditional approach to policy making. In an illustrating case of such watering down, a Danish distributor of public communication cancelled the use of pink paper for a letter, as it seemed unimportant   a behavioural informed intervention that when trialled in Singapore was found to have a positive effect on how many people complied with the message. Another common situation is when public servants or staff decide that it is not necessary to follow the procedures devised as part of a behavioural intervention as this is not perceived to be important, e.g. (Martin, Bassi and Dunbar-Rees, 2012[70]). To avoid such a situation, it is important to plan and follow the BI project all the way through the policy cycle. 


2. Monitoring long-term and potential side effects 
212. Experiments that test the potential effects of behaviourally-informed policies will always be limited in time and scope. In particular, most of experiments in the BI literature have been one-shot or very limited in time span. Thus, the long-term effects and potential side effects of such experiments are rarely known when entering the stage of CHANGE.  

213. As mentioned above, implementing and scaling a behaviourally-informed policy offers an opportunity for practitioners to keep a close track of various moderating variables as part of implementation. However, when drafting plans for CHANGE, researchers and practitioners should also put a special emphasis on the necessity of establishing measures for and then monitoring potential long-term effects and side effects.  

214. Likewise it is important to monitor for unexpected side effects. This is illustrated by an experiment by UKBIT conducted in the US. In a letter trial with  [name] you need to open this  handwritten on the envelope return rates for failed deliveries were higher (not large enough though to determine if significantly so) for envelopes with handwriting on.  

215. For these reasons, plans for implementing, scaling and evaluating the policies resulting from a BI project should always include specific plans for monitoring long-term as well as potential side effects. This may be done by integrating an ex post evaluation or review of a given policy as a required step of the policy-making process. In this way, evaluations or reviews will help ensure the quality of policy over time as well as help to generate new data that can highlight deficiencies, which can be addressed by new behaviourally informed policy initiatives.  

216. Thus, when constructing the policy, researchers and practitioners should consider including provisions that require evaluations or reviews to take place. For example,  programmed review  can be included that imposes a sunset requirement as a failsafe mechanism to ensure the policy remains fit-for-purpose over time or a post-implementation review that requires an evaluation after a given time. In the BI space, there could be an additional moral imperative for including such provisions, as arguments about the contentious nature of using psychology in policy making may be limited by assurances that the given policy will be reviewed to mitigate potential negative long-term effects. 


Box 20. Examples of monitoring behaviourally-informed policy solutions 
 


. UKBIT found that employees, whom successfully had been prompted to charitable giving the previous year, had reverted to the original level of giving when receiving the same treatment the following year (The Behavioural Insights Team, 2015[81]).  

. An experiment to nudge travellers in an airport to smoke in designate smoking zones, showed no decrease in effect for well-maintained interventions when doing a follow up study three years after the intervention was put in place (Schmidt, Schuldt-Jensen and Hansen, 2017[82]). 


 


3. Maintaining the policy initiative 
217. Different from efforts directed at changing public attitudes or cultural perceptions, but similar to traffic signs and data systems, behaviourally-informed policies are usually only effective as long as the intervention is maintained. The study of behaviourally designed smoking zones just mentioned above also showed that for those zones, which had not been properly maintained behavioural effects, had decrease relative to their decline (Schmidt, Schuldt-Jensen and Hansen, 2017[82]). Such lack of maintenance   whether physical or systemic   is common for BI interventions for the same reasons that BI interventions are in risk of being watered out during implementation: maintenance of BI interventions may be neglected because features may appear as unimportant or may be in conflict with what seems necessary from a more rational perspective.  

218. As part of securing the continued maintenance of behaviourally informed policies and interventions, plans for implementing and scaling should therefore include instructions for the proper maintenance   physical or systemic   of the policy. To avoid problems with maintaining a policy initiative over time, practitioners should consider what audiences need to be involved in the maintenance and produce material and instructions that fits these audiences and the situations in which his material is to be used. 


Box 21. Examples of maintaining the policy initiative 
An intervention in Norway successfully nudged consumers to buy more energy efficient white appliances by showing the lifetime costs of these next to sales price. In this experiment the behavioural effects returned to normal, as new staff was not being trained in the role intended for the showing of lifetime costs as part of the sales situation (Kallbekken, S len and Hermansen, 2013[52]).  
 


4. Disseminating knowledge  
219. It has only been a decade since BI became popular in policy making. Thus, it is not surprising that it is only recently that outlets and standards for reporting on BI projects have begun to emerge. While the idea of disseminated results widely is expected in the behavioural sciences, it is still not a widespread practice in most public institutions   not even those where the idea of evidence-based policy have existed for a while. As a result, often many early BI projects were not reported at all or only for internal use. In particular, null-results have not been widely publicised leading to publication bias. Also, the lack of standards have led to non-transparent reporting; reporting without moderators; reporting only in local languages; overstatement of effects, savings and revenues; and understatement of true costs, see e.g. (OECD, 2017[1]); (Osman et al., 2018[83]). 


220. For this reason, it is crucial that researchers and practitioners participate, support and systematically share and report their work in national as well as international networks of other researchers and practitioners. Stage 5: CHANGE should include allocating resources for writing up work and publishing this in academic journals or other approved outlets. Finally, practitioners working within BI should also make an effort at supplying info and transparency in data to the various current efforts at providing publicly available databases of BI projects.  

221. Relative to the policy side it should also be remembered that BI is an evidence-generating approach that seeks to de-bias future decisions by policymakers. Thus, it is just as important to share results with the community of policymakers to facilitate peer learning and better decision-making throughout government. This also includes communicating upwards to the political leadership to gain support for future interventions or further institutionalisation of BI in government. 


Ethical guidelines for implementing behaviourally-informed policy (CHANGE) 
222. Like for the other four stages in BASIC, researchers and practitioners should also observe a series of ethical guidelines in the stage of CHANGE. Some key ethical guidelines when working with CHANGE are listed here. 


Table 8. Ethical guidelines for Stage 5: CHANGE 
1. Involve stakeholders in CHANGE. Good regulatory practice calls for active stakeholder engagement when implementing and scaling behaviourally informed policies. Make sure to involve public bodies, staff, citizens, businesses and other affected parties of the proposed policy. Policies should always serve and respect the citizens, and the extended trust they put in government should never be assumed or taken for granted. 
 
2. Adhere to principles of transparency and accountability: Transparency in behavioural insights is an important discussion in the behavioural community (see Hansen & Jespersen, 2013). Researchers and practitioners need to consider the appropriate procedures and requirements for transparency and accountability to the executive and legislative branches of government, as well as the broader society. 
 
3. Pay credits were credits are due. A lot of work in BI is commissioned work carried out or supported by smaller governmental agencies or non-governmental units. If wanting to buy into the ethos of behavioural science, this means that policymakers and governmental agencies should pay credits where credits are due. 
 
3. Always report on null-results and unexpected effects. To learn, one not only needs to know what works and why, but also what did not work. While agreement about and resources devoted to publish null-results as well as unexpected effects should be secured already as part of Behaviour, it is at this point that those obligations need to be adhered to. Thus, always report on null-results and unexpected effects to avoid exposing citizens to interventions that have already been shown to fail. 
 
4. Monitor for long-term and side effects. While we have already mentioned that monitoring for long-term and side effects is part of good practice in the stage of CHANGE, this should also be done for ethical reasons. In implementing behaviourally informed interventions, researchers and practitioners also have the responsibility for devising plans for monitoring long-term and side effects to protect citizens from the potential negative consequences of these. 
 
5. Carefully examine individual and social moderators. BI has become famous for reporting on significant behavioural effects caused by implementing minor and seemingly insignificant changes into public policy. Less attention has been paid to individual and social moderators causing variance in these effects. While an increase in a positive behaviour should always be welcomed, it is just as important to ensure that specific individuals and groups do not pay a negative price for the average improvement. Hence, researchers and practitioners should always carefully examine individual and social moderators as part of implementing and scaling behaviourally informed policy. 
 


Source: Hansen (2018) for the OECD 
 
References 
 
Allcott, H. (2011),  Social norms and energy conservation , Journal of Public Economics, Vol. 95/9-10, pp. 1082-1095, http://dx.doi.org/10.1016/J.JPUBECO.2011.03.003. 
 [58] 
 
Aronson, E., M. Brewer and J. Carlsmith (1985),  Experimentation in social psychology , in Lindzey Gardner & Elliot Aronson (ed.), Handbook of social psychology, Random House, New York. 
 [76] 
 
Australian Government Department of Health (2018),  Nudge vs Superbugs: a behavioural economics trial to reduce the overprescribing of antibiotics June 2018 , http://www.health.gov.au/internet/main/publishing.nsf/Content/Nudge-vs-Superbugs-behavioural-economics-trial-to-reduce-overprescribing-antibiotics-June-2018 (accessed on 07 November 2018). 
 [64] 
 
Axelsson, S. and K.  str m (2012), Everyone earns a paper fee, https://www.naturskyddsforeningen.se/nyheter/alla-tjanar-pa-en-pappersavgift (accessed on 07 November 2018). 
 [30] 
 
Balgvig, F. and L. Holmberg (2014),  Flamingoeffekten: Sociale misforst elser og social pejling , Dj f Forlag. 
 [46] 
 
BEAR (2018), How Should Organizations Best Embed and Harness Behavioural Insights? A Playbook, http://www.rotman.utoronto.ca/-/media/Files/Programs-and-Areas/BEAR/White-Papers/BEAR_BIinOrgs.pdf?la=en (accessed on 06 November 2018). 
 [7] 
 
Berkowitz, A. and H. Perkins (1987),  Current Issues in Effective Alcohol Education Programming , in Joan Sherwood (ed.), Alcohol Policies and Practices on College and University Campuses, National Association of Student Personnel Administrators Monograph Series, Columbus, OH. 
 [42] 
 
Bertrand, M. et al. (2010),  What's Advertising Content Worth? Evidence from a Consumer Credit Marketing Field Experiment , Quarterly Journal of Economics, Vol. 125/1, pp. 263-305, http://dx.doi.org/10.1162/qjec.2010.125.1.263. 
 [53] 
 
Bridgman, P. and G. Davis (2004), The Australian policy handbook, Allen & Unwin. 
 [10] 
 
Campbell, D. and J. Stanley (1963), Experimental and quasi-experimental design for research, Rand McNally & Company, Chicago. 
 [73] 
 
Chater, N. (2018), The mind is flat : the illusion of mental depth and the improvised mind. 
 [16] 
 
Chater, N.((n.d.)), The mind is flat : the illusion of mental depth and the improvised mind. 
 [88] 
 
Cho, R. (2013), Making Green Behavior Automatic, Climate, General Earth Institute, Colombia University, https://blogs.ei.columbia.edu/2013/05/23/making-green-behavior-automatic/ (accessed on 07 November 2018). 
 [32] 
 


Cook, T. and D. Campbell (1979), Quasi-Experimentation: Design and Analysis Issues for Field Settings, Houghton Mifflin, https://www.scholars.northwestern.edu/en/publications/quasi-experimentation-design-and-analysis-issues-for-field-settin (accessed on 07 November 2018). 
 [72] 
 
Drexler, A., G. Fischer and A. Schoar (2014),  Keeping It Simple: Financial Literacy and Rules of Thumb , American Economic Journal: Applied Economics, Vol. 6/2, pp. 1-31, http://dx.doi.org/10.1257/app.6.2.1. 
 [44] 
 
Duflo, E., M. Kremer and J. Robinson (2011),  Nudging Farmers to Use Fertilizer: Theory and Experimental Evidence from Kenya , American Economic Review, Vol. 101/6, pp. 2350-2390, http://dx.doi.org/10.1257/aer.101.6.2350. 
 [22] 
 
European Commission (2014), Taking consumer rights into the digital age: over 507 million citizens will benefit as of today (Press Release), http://europa.eu/rapid/press-release_IP-14-655_en.htm (accessed on 07 November 2018). 
 [29] 
 
European Commission (2013), Antitrust: Commission fines Microsoft for non-compliance with browser choice commitments (Press Release), http://europa.eu/rapid/press-release_IP-13-196_en.htm (accessed on 07 November 2018). 
 [28] 
 
European Commission (2009), Antitrust: Commission accepts Microsoft commitments to give users browser choice (Press Release), http://europa.eu/rapid/press-release_IP-09-1941_en.htm (accessed on 07 November 2018). 
 [27] 
 
European Commission((n.d.)), Antitrust: Commission fines Microsoft for non-compliance with browser choice commitments (Press Release), 2013, http://europa.eu/rapid/press-release_IP-13-196_en.htm (accessed on 07 November 2018). 
 [89] 
 
Evans-Pritchard, B. (2013), Aiming To Reduce Cleaning Costs by Blake Evans-Pritchard (Works That Work magazine), https://worksthatwork.com/1/urinal-fly (accessed on 07 November 2018). 
 [23] 
 
Federal Judicial Center (1981), Experimentation in the Law: Report of the Federal Judicial Center Advisory Committee on Experimentation in the Law, Federal Judicial Center, Washington, DC, https://www.fjc.gov/sites/default/files/2012/ExperLaw.pdf (accessed on 07 November 2018). 
 [78] 
 
Frey, B. and R. Jegen (2001),  Motivation Crowding Theory , Journal of Economic Surveys, Vol. 15/5, pp. 589-611, http://dx.doi.org/10.1111/1467-6419.00150. 
 [51] 
 
Gigerenzer, G. (1991),  From Tools to Theories: A Heuristic of Discovery in Cognitive Psychology , Psychological Review, Vol. 98/2, pp. 254-267, https://www.mpib-berlin.mpg.de/volltexte/institut/dok/full/gg/fromtool/fromtool.pdf (accessed on 07 November 2018). 
 [43] 
 
Goldstein, N., S. Martin and R. Cialdini (2015), Yes! : 60 secrets from the science of persuasion., Profile Books. 
 [69] 
 
Gollwitzer, P. (1999),  Implementation intentions: Strong effects of simple plans , American Psychologist, Vol. 54/7, pp. 493-503. 
 [62] 
 


Gollwitzer, P. and V. Brandst tter (1997),  Implementation intentions and effective goal pursuit , Journal of Personality and Social Psychology, Vol. 73/1, pp. 186-199. 
 [61] 
 
Habyarimana, J. and W. Jack (2011),  Heckle and Chide: Results of a randomized road safety intervention in Kenya , Journal of Public Economics, Vol. 95/11-12, pp. 1438-1446, http://dx.doi.org/10.1016/J.JPUBECO.2011.06.008. 
 [59] 
 
Halpern, D. (2015), Inside the nudge unit: how small changes can make a big difference, Penguin Random House UK, London. 
 [9] 
 
Hansen, P. and A. Jespersen (2013),  Nudge and the Manipulation of Choice , European Journal of Risk Regulation, Vol. 4/01, pp. 3-28, http://dx.doi.org/10.1017/S1867299X00002762. 
 [85] 
 
Hansen, P. et al. (2016),  Apples versus brownies: A field experiment in rearranging conference snacking buffets to reduce short-term energy intake , Journal of Foodservice Business Research, Vol. 19/1, pp. 122-130, http://dx.doi.org/10.1080/15378020.2016.1129227. 
 [55] 
 
ideas42 (2017), Define, Diagnose, Design, Test, http://www.ideas42.org/blog/first-step-towards-solution-beta-project/ (accessed on 06 November 2018). 
 [6] 
 
iNudgeyou (2015), Nudging Hospital Visitors' Hand Hygiene Compliance, https://inudgeyou.com/en/nudging-hospital-visitors-hand-hygiene-compliance/ (accessed on 07 November 2018). 
 [26] 
 
Jespersen, S. (2011), Green nudge: Nudging litter into the bin, https://inudgeyou.com/en/green-nudge-nudging-litter-into-the-bin/ (accessed on 07 November 2018). 
 [24] 
 
Kahneman, D. and A. Tversky (1979),  Prospect Theory: An Analysis of Decision under Risk , Econometrica, Vol. 47/2, p. 263, http://dx.doi.org/10.2307/1914185. 
 [54] 
 
Kallbekken, S., H. S len and E. Hermansen (2013),  Bridging the Energy Efficiency Gap: A Field Experiment on Lifetime Energy Costs and Household Appliances , Journal of Consumer Policy, Vol. 36/1, pp. 1-16, http://dx.doi.org/10.1007/s10603-012-9211-z. 
 [52] 
 
King, D. et al. (2014),  Redesigning the 'choice architecture' of hospital prescription charts: a mixed methods study incorporating in situ simulation testing. , BMJ open, Vol. 4/12, p. e005473, http://dx.doi.org/10.1136/bmjopen-2014-005473. 
 [39] 
 
Larrick, R. and J. Soll (2008),  ECONOMICS: The MPG Illusion , Science, Vol. 320/5883, pp. 1593-1594, http://dx.doi.org/10.1126/science.1154983. 
 [45] 
 
Levitt, S. and J. List (2005),  What Do Laboratory Experiments Tell Us About the Real World? , Journal of Economic Perspectives , Vol. 21, https://www.researchgate.net/publication/248419698_What_Do_Laboratory_Experiments_Tell_Us_About_the_Real_World (accessed on 07 November 2018). 
 [77] 
 
Linkenbach, J. and H. Perkins (2003),  Misperceptions of peer alcohol norms in a statewide survey of young adults , in HW Perkins (ed.), The social norms approach to preventing school and college age substance abuse, Jossey-Bass, San Francisco. 
 [47] 
 


Lunn, P. (2014), Regulatory Policy and Behavioural Economics, OECD Publishing, Paris, http://dx.doi.org/10.1787/9789264207851-en. 
 [84] 
 
Martin, S., S. Bassi and R. Dunbar-Rees (2012),  Commitments, norms and custard creams   a social influence approach to reducing did not attends (DNAs) , Journal of the Royal Society of Medicine, Vol. 105/3, pp. 101-104, http://dx.doi.org/10.1258/jrsm.2011.110250. 
 [70] 
 
Miller, J. and J. Krosnick (1998), The Impact of Candidate Name Order on Election Outcomes, Oxford University PressAmerican Association for Public Opinion Research, http://dx.doi.org/10.2307/2749662. 
 [56] 
 
Mischel, W. (2014), The marshmallow test : understanding self-control and how to master it, Random House, https://books.google.fr/books?id=Pg2rAwAAQBAJ&dq=Mischel+2014&lr=&source=gbs_navlinks_s (accessed on 07 November 2018). 
 [18] 
 
Moriarty, T. (1975),  Crime, commitment, and the responsive bystander: Two field experiments. , Journal of Personality and Social Psychology, Vol. 31/2, pp. 370-376, http://dx.doi.org/10.1037/h0076288. 
 [68] 
 
Mullainathan, S. and E. Shafir (2013), Scarcity: Why Having Too Little Means So Much, Times Book, New York, https://www.hks.harvard.edu/centers/cid/publications/books/scarcity-why-having-too-little-means-so-much (accessed on 06 November 2018). 
 [17] 
 
Norman, D. (1988), The psychology of everyday things, Basic Books. 
 [37] 
 
Nudge blog (2010), Measuring the LSD effect: 36 percent improvement, http://nudges.org/?s=lake+shore+drive (accessed on 07 November 2018). 
 [38] 
 
O'Donoghue, T. and M. Rabin (1999),  Doing It Now or Later , American Economic Review, Vol. 89/1, pp. 103-124, http://dx.doi.org/10.1257/aer.89.1.103. 
 [65] 
 
OECD (2018), OECD Regulatory Policy Outlook 2018, OECD Publishing, Paris, http://dx.doi.org/10.1787/9789264303072-en. 
 [12] 
 
OECD (2017), Behavioural Insights and Public Policy: Lessons from Around the World, OECD Publishing, Paris, http://dx.doi.org/10.1787/9789264270480-en. 
 [1] 
 
OECD (2016), Protecting Consumers through Behavioural Insights: Regulating the Communications Market in Colombia, OECD Publishing, Paris, http://dx.doi.org/10.1787/9789264255463-en. 
 [79] 
 
OECD (2014), The Governance of Regulators, OECD Best Practice Principles for Regulatory Policy, OECD Publishing, Paris, http://dx.doi.org/10.1787/9789264209015-en. 
 [80] 
 
Oliver, A. (2017), The Origins of Behavioural Public Policy, Cambridge University Press, Cambridge, http://dx.doi.org/10.1017/9781108225120. 
 [66] 
 


Orbell, S., S. Hodgkins and P. Sheeran (1997),  Implementation Intentions and the Theory of Planned Behavior , Personality and Social Psychology Bulletin, Vol. 23/9, pp. 945-954, http://dx.doi.org/10.1177/0146167297239004. 
 [63] 
 
Osman, M. et al. (2018),  Learning lessons: how to practice nudging around the world , Journal of Risk Research, pp. 1-9, http://dx.doi.org/10.1080/13669877.2018.1517127. 
 [83] 
 
Pallak, M. and W. Cummings (1976),  Commitment and Voluntary Energy Conservation , Personality and Social Psychology Bulletin, Vol. 2/1, pp. 27-30, http://dx.doi.org/10.1177/014616727600200105. 
 [71] 
 
Patel, N. (2018), How a Little Nudge Increased Email Subscribership 500%, https://neilpatel.com/blog/a-little-nudge/ (accessed on 06 November 2018). 
 [87] 
 
Payne, J., J. Bettman and E. Johnson (1993), The adaptive decision maker, https://books.google.fr/books?hl=en&lr=&id=QzXFqwrPLXkC&oi=fnd&pg=PR11&dq=Payne+et+al+1993&ots=12OJ4hEw9n&sig=IoPa2VNZ9Adb98YypU4t84bwXuM#v=onepage&q=Payne%20et%20al%201993&f=false (accessed on 07 November 2018). 
 [14] 
 
Pichert, D. and K. Katsikopoulos (2008),  Green defaults: Information presentation and pro-environmental behaviour , Journal of Environmental Psychology, Vol. 28/1, pp. 63-73, http://dx.doi.org/10.1016/J.JENVP.2007.09.004. 
 [60] 
 
Pink, D. (2018), When : the scientific secrets of perfect timing, Penguin Publishing Group. 
 [19] 
 
Read, D., G. Loewenstein and S. Kalyanaraman (1999),  Mixing virtue and vice: combining the immediacy effect and the diversification heuristic , Journal of Behavioral Decision Making, Vol. 12/4, pp. 257-273, http://dx.doi.org/10.1002/(SICI)1099-0771(199912)12:4<257::AID-BDM327>3.0.CO;2-6. 
 [20] 
 
Robson, A. (2001),  The Biological Basis of Economic Behavior , Journal of Economic Literature, Vol. 39/1, pp. 11-33, http://dx.doi.org/10.1257/jel.39.1.11. 
 [15] 
 
Robson, C. and K. McCartan (2016), Real world research, Wiley, https://www.wiley.com/en-us/Real+World+Research%2C+4th+Edition-p-9781118745236 (accessed on 07 November 2018). 
 [74] 
 
Sanders, M., M. Jackman and M. Sweeney (2017), Introducing Test+Build   a BI Venture | The Behavioural Insights Team, https://www.behaviouralinsights.co.uk/uncategorized/introducing-testbuild-a-bi-venture/ (accessed on 06 November 2018). 
 [57] 
 
SANDERS, M., V. SNIJDERS and M. HALLSWORTH (2018),  Behavioural science and policy: where are we now and where are we going? , Behavioural Public Policy, Vol. 2/2, pp. 144-167, http://dx.doi.org/10.1017/bpp.2018.17. 
 [86] 
 
Sanders, M., V. Snijders and M. Hallsworth (2018),  Behavioural science and policy: where are we now and where are we going? , Behavioural Public Policy, Vol. 2/2, pp. 144-167, http://dx.doi.org/10.1017/bpp.2018.17. 
 [11] 
 


Schmidt, K., J. Schuldt-Jensen and P. Hansen (2017),  Rygeadf rd i BASICperspektiv: En case fra K benhavns Lufthavne om adf rdsdiagnosticering og langtidsvirkning af adf rdsinterventioner ,  konomi og Politik, Vol. 90/4, pp. 54-65. 
 [82] 
 
Shadish, W., T. Cook and D. Campbell (2002), Experimental and quasi-experimental designs for generalized causal inference, Houghton, Mifflin and Company, http://psycnet.apa.org/record/2002-17373-000 (accessed on 07 November 2018). 
 [75] 
 
Soman, D. (2015), The last mile : creating social and economic value from behavioral insights, University of Toronto Press, Toronto, https://books.google.fr/books?hl=en&lr=&id=dH1kCgAAQBAJ&oi=fnd&pg=PP1&dq=Dilip+Soman+2015&ots=U4xy2vWq1s&sig=hxrJMN4sebSloaNbIRDI6yBMHP4#v=onepage&q=Dilip%20Soman%202015&f=false (accessed on 07 November 2018). 
 [13] 
 
Stubbs, N. et al. (2012),  Methods to Reduce Outpatient Non-attendance , The American Journal of the Medical Sciences, Vol. 344/3, pp. 211-219, http://dx.doi.org/10.1097/MAJ.0b013e31824997c6. 
 [25] 
 
Sunstein, C. and L. Reisch (2013),  Green by Default , Kyklos, Vol. 66/3, pp. 398-402, http://dx.doi.org/10.1111/kykl.12028. 
 [31] 
 
Tal, A. and B. Wansink (2015),  An Apple a Day Brings More Apples Your Way: Healthy Samples Prime Healthier Choices , Psychology & Marketing, Vol. 32/5, pp. 575-584, http://dx.doi.org/10.1002/mar.20801. 
 [21] 
 
Tanguy, B. et al. (2014),  The Future in Mind: Aspirations and Forward-Looking Behaviour in Rural Ethiopia , https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2526352 (accessed on 07 November 2018). 
 [40] 
 
Texas Department of Transportation((n.d.)), Don't Mess With Texas, https://www.txdot.gov/inside-txdot/media-center/psas/litter-pollution/dont-mess-with-texas.html (accessed on 07 November 2018). 
 [48] 
 
Texas Times (2016),  Don't Mess with Texas , http://www.cbclandman.com/uploads/images/PDFs/2016%20-%20Don,t%20Mess%20With%20Texas,%20The%20Real%20Story.pdf (accessed on 07 November 2018). 
 [49] 
 
Thaler, R. and C. Sunstein (2008), Nudge : improving decisions about health, wealth, and happiness, Yale University Press. 
 [8] 
 
The Behavioural Insights Team (2015), The Behavioural Insights Team: Update report 2013-2015, The Behavioural Insights Team, London, http://38r8om2xjhhl25mw24492dir-wpengine.netdna-ssl.com/wp-content/uploads/2015/08/BIT_Update-Report-Final-2013-2015.pdf (accessed on 07 November 2018). 
 [81] 
 
The Behavioural Insights Team (2014), EAST Four simple ways to apply behavioural insights, The Behavioural Insights Team, https://38r8om2xjhhl25mw24492dir-wpengine.netdna-ssl.com/wp-content/uploads/2015/07/BIT-Publication-EAST_FA_WEB.pdf (accessed on 06 November 2018). 
 [4] 
 


The Behavioural Insights Team (2013), Test, Learn, Adapt: Developing Public Policy with Randomised Controlled Trials, The Behavioural Insights Team, https://38r8om2xjhhl25mw24492dir-wpengine.netdna-ssl.com/wp-content/uploads/2015/07/TLA-1906126.pdf (accessed on 06 November 2018). 
 [3] 
 
The Behavioural Insights Team (2010), MINDSPACE, The Behavioural Insights Team, https://www.behaviouralinsights.co.uk/publications/mindspace/ (accessed on 06 November 2018). 
 [2] 
 
The Danish Business Authority and Copenhagen Economics (2013), Nudging business policy: Making it easy to do the right thing, https://erhvervsstyrelsen.dk/sites/default/files/media/nudging-business-policy.pdf (accessed on 07 November 2018). 
 [34] 
 
The World Bank (2015), The World Development Report 2015: Mind, Society and Behaviour, The World Bank, Washington, http://www.worldbank.org/content/dam/Worldbank/Publications/WDR/WDR%202015/WDR-2015-Full-Report.pdf (accessed on 06 November 2018). 
 [5] 
 
Titmuss, R. (1970), The Gift Relationship: from Human Blood to Social Policy, Allen & Unwin, London. 
 [50] 
 
Tversky, A. (1972),  Elimination by aspects: A theory of choice. , Psychological Review, Vol. 79/4, pp. 281-299, http://dx.doi.org/10.1037/h0032955. 
 [33] 
 
Tversky, A. and D. Kahneman (1974), Judgment under Uncertainty: Heuristics and Biases, http://psiexp.ss.uci.edu/research/teaching/Tversky_Kahneman_1974.pdf (accessed on 06 November 2018). 
 [41] 
 
UK Government((n.d.)), Check if a document allows someone to work in the UK - GOV.UK, https://www.gov.uk/legal-right-work-uk (accessed on 07 November 2018). 
 [35] 
 
Volpp, K. et al. (2008),  Financial Incentive Based Approaches for Weight Loss , JAMA, Vol. 300/22, p. 2631, http://dx.doi.org/10.1001/jama.2008.804. 
 [67] 
 
Wickens, C., S. Gordon and Y. Liu (1998), An introduction to human factors engineering, Longman. 
 [36] 
 


 
 
 

